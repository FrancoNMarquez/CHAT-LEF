 Titulo: Clase16 (parte 2) Curso Inteligencia Artificial 
 URL https://youtu.be/qgoA7M8msSs  
 1734 segundos de duracion 
 Bienvenidos a la segunda parte de esta clase Los invito a empezar con [Música] ella bien seguimos con la segunda parte de la clase 16 ahora vamos a implementar nuestra segunda red neuronal un poco más compleja que la anterior y en este caso vamos a hacerlo usando el dataset Fashion mnist el nombre les va a sonar familiar porque justamente el dataset mnist lo usamos eh mucho en el módulo de Machine learning dado que teníamos allí bueno algunos los primeros ejemplos de lo que era visión computacional con números escritos a mano y digitalizados en matrices de 28x 28 bien acá Este dataset es algo Bastante parecido solamente que en lugar de tener variantes de número de 0 al 9 tiene variantes de prendas de vestir o calzados que están codificados de 0 al 9 según esta tabla que aquí les muestro cero camiseta uno pantalón bueno etcétera etcétera hasta llegar a bota que es la número nueve la estructura del conjunto de datos es similar es decir tiene 70,000 observaciones como era el emnis eh las matrices son de 28 por 28 y tiene dentro de las 70,000 10,000 para conjunto de Test o sea 60,000 para entrenamiento y 10,000 para test Exactamente igual al modelo mmis obviamente aquí tenemos alguna referencia gráfica Para que vean el contenido eh obviamente Estos no son todos los elementos pero sí para que tengan un pantallazo del contenido de de este conjunto de datos ven que tenemos tres filas por cada tipo de prenda sí las primeras dijimos que eran camisetas segundo pantalón pulover Bueno aquí tenemos tres filas de camisetas tres filas de pantalones tres filas de pullovers y así hasta llegar a las botas que era el último producto bien eh evidentemente estas imágenes se ven aquí muy pequeñas pero cuando las agrem van a poder comprobar que una imagen de 28x 28 es poca calidad no esto es obvio no pero bueno está bueno referenciarlo así que vamos a trabajar entonces una Inteligencia artificial de tipo reial con este conjunto de datos antes vamos a ir a esto que está aquí que es importar las librerías vamos a usar tensor Flow map lip y esto que puse Aquí es importante para que puedan constatar la versión de tensor flow que están usando el tema de las versiones es un tema muy importante y que vamos a empezar a a observar mucho en todas las prácticas que vamos a llevar adelante ahora en más dado que bueno conforme pasa el tiempo aparecen nuevas versiones de de todas las librerías que vamos a usar y Bueno hay librerías que cuando cambia la versión desafectan algunas cosas o las cambian por lo tanto puede que alguna práctica que con una versión funcione con otra No lo haga y simplemente habrá que hacer algún cambio para poder adaptarlo a la nueva versión bien Así que aclarado esto vamos concretamente al primer paso que es poder dividir el conjunto de test y de entrenamiento Recuerden que ya lo habíamos hecho esto porque así como el conjunto de datos mnist venía ya con el conjunto de entrenamiento y el conjunto de Test preparado De antemano Bueno aquí va a pasar exactamente lo mismo solamente que lo vamos a obtener cargando el conjunto de datos de esta mod sí tfas dataset Fashion en nist este ya es un conjunto de datos que al igual que en nist ven Tena ya preparado dentro de una librería en este caso dentro de la librería dataset de queras de tensor Flow y creo aquí la variable FM nombre que se me ocurre Como siempre digo puede ser el que ustedes quieran bien creo ahí y ahora sí lo que hago es separar los conjuntos de Test y entrenamiento De qué modo bueno con el método lo datata sobre fnis es lo que Acabo de crear aquí arriba bueno tomo image training o training image training labels test image y test l qu corresponde si tomo El ejemplo de aquí arriba a lo que era antes la variable que había creado como xtrain como itrain como XT y como it sea he puesto este comentario aquí arriba para tratar de hacer algún tipo de de de correlatividad entre lo que hacíamos antes y lo que hacemos ahora concretamente es exactamente lo mismo solamente que al cargarlo lo a Data lo hago de este modo y no como lo hacía antes que como lo expuesto aquí arriba bien cargamos los conjuntos y vamos a visualizar para aprender un poquito más de cómo se cargan esta información Dentro de este conjunto de datos que tiene una matriz de 28 por 28 vamos a hacer un print de train images sub cero es decir la primera observación Ya lo hemos hecho antes sí así que hacemos un print y vemos que acá aparecen todas las filas de 28 por 28 es decir 28 filas por 28 elementos cada uno vamos a hacer lo propio ahora con la etiqueta training Level sub cero también y me dice que el resultado es nu Qué quiere decir nu que corresponde con una etiqueta de tipo nu9 que justamente representa bota sí es decir alguno de estos elementos que que está aquí debajo bien al tener esa información también vamos a imprimir justamente Esa esa bota justamente con image trining subcero y con semap grade lo que le digo es que me imprima esto en tonos de grises que es realmente cómo está cargada la información sí en este este conjunto de datos bien hago esto y obtengo esta imagen sí ven es una bota de muy baja definición como imagen pero nos va a permitir mirar algo muy interesante fíjense la primer fila de este conjunto de valores le dirá las tres primeras filas tienen todos ceros los ceros representan el color negro si ustedes ven la imagen vamos aquí abajo van a poder ver que las tres primeras filas son todas negras Por eso cada uno de los valores que tienen estas tres primeras filas son Cero en la medida que vamos bajando en la imagen obviamente van apareciendo otro tipo de píxeles que no tienen color cero no tienen color negro bueno Y esto Si miran Aquí van a ver que los ceros en la medida que van bajando van desapareciendo van dando lugares a otros valores numéricos no cero y que representan distintos tonos de gris sí y así hasta llegar al final donde al final fíjense que tengo una dos tres dos líneas completamente de ceros y la tercera eh empezando de abajo hacia arriba por supuesto con este otro valor ven que aquí hay algunos tonos que son oscuros pero ya no son el negro puro HM esta en la tercer fila empezando y si trabajo hacia arriba es algo que veo reflejado aquí bien Esto simplemente a título de curiosidad Me parece que ha algo interesante para que puedan entender este tema de los valores y los colores que representa lo próximo que vamos a hacer es un proceso de normalización ya tenemos en claro ese concepto es tratar de que los valores vayan entre 0 y 1 y en este caso en particular como los valores van entre 0 y 255 la manera de normalizar que vamos a utilizar Es simplemente una expresión matemática que es esta que está aquí que es dividir Al conjunto de entrenamiento de imágenes por 255 y el conjunto de test de imágenes también por 255 con lo cual de esa manera he logrado normalizar el conjunto de entrenamiento y de test de imágen o sea los valores de entrada del conjunto de entrenamiento los valores de entrada del conjunto no los valores Label sí los valores de entrada una vez que hacemos esto pasamos a diseñar el modelo bien aquí tenemos alguna particularidad respecto a lo que habos hecho antes por qué bueno porque acá ya no tenemos una estructura de una sola capa y una sola neurona por eso le hemos dado como nombre a este modelo model 2 para diferenciarlo del model que habíamos utilizado antes no obstante seguimos usando sequential de models de queras Por qué Porque justamente es una red de tipo secuencial múltiples capas tenemos en este caso Cuántas capas tres capas la primera es de tipo flatten esto es muy común si cuando este entra al modelo una imagen o cualquier estructura que sea de 28 por 28 sea que sea una matriz No importa De cuánto sea Perdón en este caso 28 por 28 yo tengo que transformar esa matriz en un vector unidimensional es decir que lo que tengo que hacer de alguna manera como dice aquí flat es aplanar esa matriz para que cada una de esas o filas si conformen una única fila de 784 valores bien Esto es lo que hace flaten y siempre va a ser en este caso este lo que deba hacer si yo recibo insisto una matriz y necesito como entrada un vector luego viene la primer capa densa por eso hago keras layers dens y esta capa densa tiene dos cosas interesantes primero ya le digo Cuántas neuronas quiero que tenga 128 y le digo la famosa función de activación de la que hablamos en la teoría qué tipo quiero y es la que mencionamos se acuerdan como que dijimos que la que más íbamos a usar Perdón es relu h y finalmente la otra capa es una capa densa de 10 neuronas y tiene otra función de activación que es sofm por qué porque esta capa Es la capa de salida y esa capa de salida lo que tiene que darme son tantas neuronas como posibles valores de salida pueda tener esta en este caso 10 porque son 10 tipos distintos de de prendas de vestir y la función de activación es softmax se acuerdan que dijimos en la clase teórica que en la capa de salida voy a tener dos opciones mayoritariamente de tipo de funciones de activación si la salida es binaria yo voy a usar la sigmoide y si es de tres o más variantes la z qué es lo que hecho aquí concretamente repasando Este modelo esta capa es la capa de entrada esta capa es la única capa oculta pueden haber más en este caso es la capa oculta de este modelo y esta capa Es la capa de salida o sea que ya tenemos un modelo completo más parecido a lo que hablamos en la teoría capa de entrada capa oculta y capa de salida bien avanzamos con el próximo paso ahora con la compilación del modelo donde van a aparecer dos elementos nuevos y que respaldan de alguna manera lo que dijimos en la primera parte de esta clase porque digo esto Aquí está el optimizador como habíamos usado hoy solamente que no vamos a usar el sgd como usamos recién sino el Adam porque es más propio más conveniente y más rápido para este tipo de eh modelos que trabajan con imágenes esto por qué digo respalda lo que dijimos antes porque yo antes dije que cuando pusimos cgd no era el único tipo de optimizador sino que había otras variantes Bueno aquí hay otra variante y dije lo mismo con la función de pérdida usamos el método de mínimos cuadrados aquí usamos spars categorical Cross entropy que en realidad es más propio para cuando tenemos valores de tipo categórico es decir que en este caso voy a usar esta función de pérdida sí no es binario acd que no tengo un problema binario como antes Tengo un problema de distintos tipos de categoría que son las las 10 tipos de prendas que hay de de vestir o o de calzado y el acur lo dejamos tal cual estaba pero fundamentalmente quiero que presten atención y que en este caso usé otra función de pérdida y usé otro optimizador con esto que después ya más adelante vamos a ver cuando nos conviene uno u otro que no es el tema de este momento sí lo importante que quiero que vean aquí es que hay más de un optimizador y aquí está el ejemplo y hay más de una función de pérdida y aquí está el ejemplo ahora vamos a entrenar el modelo Sí aquí tenemos model 2. fit y le pongo la variable de entrada o los valores de entrada que son los eh la definición de cada uno de los píxeles de la variable de entrada son todas las x que entran y la variable de salida que sería ahí que venimos trabajando habitualmente que es el Label y le voy a poner nada más que un entrenamiento de cinco epoch sí Y esto a diferencia de antes que yo no había puesto est objeto aquí o sea eh entrenaba el modelo pero no asignaba el resultado de ese entrenamiento una variable lo voy a asignar Ahora sí una variable ya vamos a ver para qué sí entrenamos el modelo y después vemos eso Bueno ahí terminó el entrenamiento como habrán visto son solamente cinco entrenamientos y tardó mucho Sí ya estamos trabajando insisto con un conjunto de datos mucho más grande que el caso anterior que dan solamente seis valores y eh lo que tenemos aquí es el descenso de la función de pérdida de 04 997 a 02944 Obviamente que si tengo más entrenamientos va a bajar mucho más y el acuras que va de 08241 a 0899 queé es lo que no habíamos visto en el ejemplo anterior porque no teníamos separado conjunto de entrenamiento y test y ahora sí Por lo tanto Ahora sí vemos los datos de ambas cosas sí Entonces con esto puedo ver de que tengo bueno una queas del orden del 89 con solamente cinco entrenamientos eso en cuanto al conjunto de entrenamiento Qué pasará con el conjunto de Test acuérdense que al igual Perdón que Machine learning tengo que evaluar para el conjunto de entrenamiento y para el conjunto de Test lo hago con el método evaluate de model dos si y le mando la x de Test y la y de Test si las viejas x e de Test es decir test images aquí y test levels para este caso lo ejecutamos y comprobamos que en este caso la el accuracy para el conjunto de Test obviamente es un poco menor que el conjunto de entrenamiento Y es de 0877 o sea 8707 por. bien Ahora vamos a desvelar eh Por qué hablábamos recién de que cuando entrenábamos el modelo lo igualamos a una variable a esta variable que le hemos dado en Llamar histórico lo que voy a destinar lo que a poner dentro de ella es todos y cada uno de los valores de las pérdidas y de los acuras con lo cual voy a tener la posibilidad de como vemos aquí poder acceder a crear una Ray de acasis y una Ray de pérdidas y con ello lo que voy a hacer es y todo lo que está aquí abajo graficar ambas curvas lo ejecuto y fíjense lo que obtengo lo voy a reducir un poquito en tamaño para que se vea mejor un poco más bien Ahí está tengo la precisión del entrenamiento que desde el principio y hasta el último epoch va de 0 a cu obviamente Este es el epoch número uno fíjense va creciendo creciendo creciendo creciendo pasando De nada al 083 que era el primer caso al 089 que es el último y la pérdida tiene un efecto completamente contrario arranca arriba y termina o bajando conforme van pasando los entrenamientos Bueno este tipo de gráfica de una precisión y de la pérdida tienen que siempre tener esta figura si no tenemos estas figuras sí es decir que la precisión no sube y la pérdida no baja bueno es evidentemente o será evidentemente un mal modelo Pero qué pasaría si el entrenamiento fuese no de solamente cinco épocas fuera de 50 épocas sí obviamente la primera respuesta virtud del tiempo va a tardar mucho más obviamente pero qué va a pasar con la precisión va a mejorar mucho poco no va a mejorar Bueno vamos hacia atrás a simular porque a este modelo ya lo entrenamos al modelo donde al punto Perdón donde creamos el modelo nuevamente lo compilamos nuevamente y nos salteamos el entrenamiento de cinco épocas y vamos directamente al entrenamiento de 50 épocas bueno acá no lo igual un histórico podría haber hecho eso y para poder ver los gráficos como recién y hubiera visto gráficos con en lugar de cinco entrenamientos con 50 Pero bueno vamos a ejecutarlo Entonces ahora Este modelo con insisto 50 Bueno ahora vemos Que bueno finalizado este largo proceso me dio una curiosi muy bueno de 0.96 96,52 por. ahora vamos a hacer como antes la medición con el conjunto de Test y vemos que el resultado que me arroja Es muy inferior 88,55 por. Esto me puede llevar a presumir que se ha hecho probablemente un sobreajuste Bueno no importa no obstante vamos a ver otro tema importante que es el tema de la deducción O la visualización del resultado de manera probabilística O sea no quiero que me diga que la el resultado de eh Este modelo digamos de de evaluar una predicción con este modelo sea un nueve como en el caso anterior se acuerdan que habíamos probado que la predicción del primer caso me daba que era un nueve que representaba la la bota digamos no sí esta bota que estaba aquí arriba sino que lo que quiero hacer en todo caso es ver probabilísticamente cómo me da el resultado de la primera observación Entonces vamos a imprimir este código que está acá qu lo que hace es imprimir la clasificación sí de la primera observación como con predict hago un predict de todo el conjunto de Test y los resultados de las predicciones las pongo en una variable que se llama classification es como antes le poníamos el ipred se acuerdan Bueno es lo mismo ahora le cambiamos el nombre podríamos Haber puesto ipred también no bueno y después imprimo la la etiqueta sí original de eh de esa observación veo que la etiqueta original es nueve es la bota obviamente como dijimos el primer elemento pero vamos a mirar el resultado demostrado de manera probabilística como ya lo hemos hecho alguna vez en alguna práctica de Machine learning fíjense que acá tengo una probabilidad de cada uno de los elementos de que ese sea en este caso el elemento predecido correcto bueno evidentemente eh la predicción es nu porque de todos estos 10 valores el más alto es el último y como va de 0 a 9 el más alto es el noveno perdón el décimo en la ubicación pero el número de índice número nue por qué Porque evidentemente ya fíjense con las expresiones menos tanto que quiere decir 10 elevado a la menos tanto el el valor que tiene ese coeficiente menor es este que es 10 a la men1 sería 9,99 10 a la men1 que quiere decir 99 99% Sí 99,999% así que hay una altísima probabilidad de que sea la bota y de hecho es la bota bien y para terminar la clase vamos a usar el mismo modelo que utilizamos hasta ahora pero vamos a ponerles algunas pequeñas variantes Para que vean justamente bueno como ese modelo puede tener distintas versiones con distintas opciones lo primero que nos proponemos aquí es cambiar significativamente el número de neuronas de la capa oculta cambiando los las 128 neuronas que teníamos en el modelo anterior por esta que tiene ahora 1024 neuronas Cómo se hace simplemente yendo al lugar donde yo ponía la cantidad de neuronas de la capa oculta 128 y cambiándolo por 1024 el resto del ejercicio está todo en una celda pero es Exactamente igual que el caso anterior donde se termina midiendo el acuras del conjunto de entrenamiento el acuris del conjunto de Test vemos aquí 89,6 6% y 87 51 y haciendo una predicción probabilística y luego comparándola con el resultado final que siempre es la bota que siempre decimos aquí lo que tenemos que observar es que con este nuevo modelo también tenemos una predicción certera dado que el valor ubicado en la décima posición de índice número nu es el que finalmente tiene la mejor probabilidad y Por ende es el valor que ha sido designado como valor siguiente que tenemos aquí es la posibilidad de no tener una capa oculta sino tener dos capas ocultas donde la primera es de 512 y la segunda es 256 esto es muy común que la cantidad de neuronas vaya decreciendo hacia la salida eh como parte de lo que es la estructura clásica de una red neuronal artificial bueno no hay mucho más cambio que ese simplemente poner dos capas en lugar de la que teníamos antes de 128 o la última de 1024 tenemos una de 512 y una de 256 ambas capas obviamente densas luego insisto como recién el resto de los ejercicio es Exactamente igual que en el caso anterior y los casos precedentes y el último ejemplo que quizás sea el más interesante es de la aplicación o utilización del método callback para detener el entrenamiento de qué se trata esto Nosotros sabemos que cuando hemos podido comprar justamente porque hicimos un ejemplo con cinco os y otro con 50 epods en la medida que haya más entrenamientos obviamente va a haber una mayor posibilidad de tener un mayor score un mayor aquí H Sí con lo cual puede hacernos llevar a pensar que yo cuando tengo que llevar a desarrollar un modelo y quiero que sea exitoso voy a poner un número muy alto altísimo de cantidad de entrenamientos porque de esa manera me voy a asegurar tener un buen score un buen acac bien obviamente como siempre decimos todas estas decisiones grandilocuentes o exageradas son innecesarias muchas veces con menos se puede lograr el mismo objetivo y seguir persistiendo en un accionar de ese tipo buscando un mejor score cuando ya tengo un muy buen score es algo que seguramente puede ser que crezca digamos ese accuracy pero no va a ser significativo con lo cual no es no se justifica hacer ese esfuerzo con este método lo que vamos a hacer es decirle al método sí que va a ser una clase como Tenemos aquí y una función que vaya cuando va terminando cada entrenamiento verificando Cuál es el accuracy Y si el accuracy es eh o llega a los niveles que yo quiero automáticamente el entrenamiento se va a detener Aquí voy a poner un una que s un objetivo bastante bajo no que es del 90 por nada más Pero más que nada para que se vea el efecto y luego lo que hacemos el resto es Exactamente igual volvemos a un modelo de una sola capa Comparado con el ejercicio que hicimos recién y el resto de este el ejercicio Exactamente igual solamente que qué va a pasar aquí aquí va a pasar que cuando yo ejecute esto se va a parar no en los 100 que le he puesto aquí fíjense que puse un número muy alto sino que se va a parar cuando la el acuras llegue a ser mayor al 90 por lo ejecuto y veo que justamente tengo en el epos 1 083 087 088 088 85 089 53 09021 en el sexto entrenamiento por lo tanto no se llega al séptimo entrenamiento porque que bueno evidentemente esto ya ha llegado a 09021 y con eso es suficiente como dijimos recién el proceso se cancela en el epoch número 6 y eh vamos a ver aquí que eh podemos que no lo hemos hecho aquí arriba medir la evaluación del conjunto de Test y vemos que nos arroja un 088 30% bueno habiendo hecho tantos modelos y habiendo obtenido tantos scores lo que vamos a hacer para terminar esta clase es hacer una tabla viendo todos y cada uno de los modelos con las variantes que hemos tenido y cuáles son los valores de act Así que hemos tenido en cada caso para el conjunto de Test y para el conjunto de entrenamiento y sacar algunas conclusiones bueno Y aquí finalmente como dijimos recién una tabla con las cinco variantes de modelos que trabajamos más la columna donde tengo todos los acacy train y todos los acacy test sobre el conjunto de entrenamiento sobre el conjunto de test bueno eh 128 neuronas con 5 ort 198 neuronas con 50 1024 neuronas con 5 ort la que tenía dos capas 502 y 256 con c epoch y la última con el colb que se cortó automáticamente con el sexto epoch porque le pusimos que a los 090 de acur train se cortara si lo hubiésemos puesto a tumbral bueno quizás hubiese llegado más lejos eh una conclusión que podemos tener aquí Más allá de la cantidad de capas y más allá de la cantidad de neurones que es muy significativa la diferencia cuando entreno muchas más veces sí con lo cual los invito a que por su cuenta con paciencia eh utilizando digamos la opción que nosotros no hemos utilizado aquí pero que justamente al finalizar esta clase les quiero mostrar que es alterar el entorno de ejecución yo voy aquí a la opción entorno de ejecución y le pongo cambiar el tipo de entorno de ejecución y activo la opción gpu eso van a acelerar bastante este los procesos de entrenamiento de los modelos h en algunos casos hasta puede ser que tarde tres veces menos sí eh Lo que pasa que esta opción está puesta de manera como todo cola de manera gratuita o de pago con lo cual obviamente la gratuita Tiene ciertas limitaciones depende del momento que nos conectemos hay veces que por ahí nos vamos a conectar y no nos va a dar el servicio eh o a veces este nos lo va a cortar utamente bueno obviamente es algo grao Hay que tomarlo de este modo pero hagan el intento de entrenar los otros modelos que los entrenamos con pocos epod con esta herramienta de gpu simplemente pones gpu y ahí me me dice Bueno obviamente yo estoy conectado sin gpu me propone volver a conectarme con gpu no se puede cambiar sin cortar la conexión eso es importante que lo sepan con lo cual si cambian el entorno tienen que volver a ejecutar todo lo que anteriormente no se ejecutaron porque pierden la conexión y Es como empezar nuevamente todo ese bien aquí se lo voy a poner Cancelar y eh digo de esta manera pueden probar que todos los modelos que solo usamos cinco o se epoch como en el último caso Bueno aquí pasar de 5 a 50 Aquí también Aquí también y en este caso que usa el callback ponerle más que la cantidad de poch más alta el umbral más alto pongámosle por ejemplo como este 094 095 096 lo que ustedes quieran digamos porque justamente Esto está puesto como referencia para que ustedes puedan probar próximos modelos Y a partir de esta tabla puedan darse cuenta si la cantidad de superior hizo que esos valores mejoraran teedo que sí pero bueno cuánto má Cuanto más y por eso si se justifica hacer ese cambio Bueno hasta aquí llegamos con esta clase terminado toda esta práctica de la clase número 16 en la parte un y la parte dos nos vemos en la próxima clase hasta entonces aquí termina esta clase los espero en la próxima clase nos vemos