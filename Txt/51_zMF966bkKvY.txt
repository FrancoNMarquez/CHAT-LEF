 Titulo: Clase 26 (parte  2) Curso de inteligencia Artificial 
 URL https://youtu.be/zMF966bkKvY  
 1070 segundos de duracion 
 Esta es la segunda parte de la clase número 26 te invito a empezar con [Música] ella [Música] otro concepto del nlp es la similitud entre vectores en realidad esto de alguna manera Ya lo hablamos cuando decíamos de que cada palabra o cada documento depende el caso estaba representado por un vector y la cercanía entre esos vectores me daba la idea de que eso podría ser similar si Estaban cerca o no tan similar si no Estaban cerca por lo tanto esto que tenemos aquí este gráfico lo vamos a recordar justamente porque tengo la idea de tres vectores en este caso A B y C y justamente puedo ver si A B y C son o no similares en virtud de su cercanía la cercanía en realidad se calcula en base al coseno del ángulo entre esos vectores es decir por ejemplo en este caso entre a y b la cercanía se me diría calculando el coseno de este ángulo que está aquí dibujado con esta línea roja o de a con c con esta línea verde det trazos bien en el caso que yo calcule el coseno de 0 y me de un es cuando literalmente un vector está encima del otro es virtualmente la misma palabra con lo cual la similitud sería máxima en La Virtud que eso no pasa hae bueno Obviamente que describirá un ángulo que en la medida que sea más chico va a describirme una situación de un texto o una palabra más similar y lo contrario sucede justamente que el ángulo fuera mucho más lejano o más grande tenemos que recordar como siempre venimos diciendo que justamente el vector en nlp representa una tokenización de los textos los textos están representados o las palabras de los textos ya vamos a ver más adelante depende que tomemos como unidad de tokenización están representados por vectores Y nuevamente la cercanía o la lejanía de ellos me habla de la similitud vamos a ejemplos de la aplicación de la similitud dees una de las aplicaciones prácticas es la similitud de documentos Sí ya que se usa mucho por ejemplo para si tenemos una biblioteca de datos muy grande que queremos clasificar podemos usar la similitud de vectores para juntar los documentos que son más parecidos y clasificarlos otra aplicación es el spinning de artículos y seo seo es el search engine optimization optimización en motores de búsqueda esto es muy importante porque muchas veces por ejemplo Google hace un seo de la página web que es cómo va a posicionar la página concretamente en base a la riqueza del documento determina esa ese posicionamiento perdón y hay muchas personas que piensan que copiando un documento y pegándolo en su página web van a lograr posicionarse mejor en Google pero Google tiene sistema de similitud de vectores justamente que hacen que descubran cuando hay muchas copias de los textos para evitar eso justamente también la aa nos propone una solución a través del spinning de artículos que se trata de tomar un artículo y variarlo tal que no diga Exactamente lo mismo pero conceptualmente el artículo diga o se trate de lo mismo otra aplicación son las recomendaciones por ejemplo de Netflix esto ya lo vemos aplicado en varias de las cosas que hemos visto hasta ahora Quién trabaja también usando el tema de la vectorización para ver en base a la review de las películas y buscar coincidencias con las películas que ya hayamos visto antes finalmente otra aplicación son los chatbot que también usan mucho la similitud de vectores ya que cuando hacemos una pregunta al Bot lo que hace este es vectorizar dicha pregunta y buscar en su base de datos vectorizada a cuál vector se parece más la pregunta que estamos haciendo Y nos manda la respuesta en base a ese concepto de similitud de vectores el siguiente concepto que vamos a ver aquí es el concepto de tf idf a ver de qué se trata este concepto básicamente tf significa frecuencia del término e idf significa frecuencia inversa del documento En qué se basa este método o Esta técnica Esta técnica es utilizada para reflejar Cómo o cuán importante es una palabra en el contexto de un conjunto de documentos en este caso no se toma en cuenta la relevancia o la importancia o el peso de las palabras sino por el contrario reduce ese peso y aumenta el peso de las palabras menos frecuentes dicho de otra manera las palabras que aparecen con más frecuencia en un documento pero muy poco o nada en otros documentos son consideradas las más importantes para este método Cómo se aplica este método tfidf se aplica aplicando valga la redundancia esta fórmula que tenemos aquí tf de TD por idf de TD para entender bien esta fórmula vamos a ir viéndola paso a paso primero el primer término Qué es tf de TD es el número de veces que un término aparece en el documento d dividido el total de términos en el documento d por ejemplo supongamos que el término stemen que vimos la clase pasada aparece 10 veces en un documento que tiene 1000 palabras Entonces el tf de ese término sería 0,01 porque sería literalmente 10 di 1000 paso Seguido el idf de TD significa el logaritmo base e del total de documentos del grupo denominado d mayúscula en este caso dividido el número de documentos en donde aparece el término t volvamos al ejemplo de recién supongamos que el total de documentos que tenemos es 10 Sí donde uno de los documentos el que referenciamos recién y solamente en un documento aparece el término steaming es el primero el que vimos recién en el caso anterior Entonces digamos que si tenemos 10 documentos y en un solo documento aparece el término stemin entonces la fórmula sería logaritmo e de 10 di 1 lo cual nos daría 2.3 Finalmente y habiendo logrado el cálculo de los dos términos de esta fórmula como lo vimos recién en el ejemplo tendríamos que tdf DF serí igual a 0 01 que es la primer parte de la Fórmula por 2.3 que es la segunda parte de la Fórmula lo cual nos daría como resultado 0.023 pensemos en lo primero que vimos si stemin aparece 10 veces en un documento de 1000 quiere decir que su pie sería 0.01 Pero aplicando este concepto de tf y DF donde le da más importancia a las palabras que menos aparecen el peso de esa palabra sería 0.023 es decir mayor a que hubiera tenido de manera natural como dijimos al principio de esta clase vamos a profundizar este concepto poniéndolo en práctica justamente a través del lab pnl 4 que es uno de los lab que ustedes tienen a través del campus virtual un lab de colab y vamos a aplicarlo a un ejemplo de un sistema de recomendación de películas vamos con ello bien estamos ahora entonces en el apn l4 dentro del entorno de cola donde el Ob objetivo como ya lo dijimos antes es crear un sistema de recomendación de películas aplicando el método tfidf es importante que tengamos en claro que para hacer un sistema de este tipo lo que tenemos que ver es la similitud entre una película y otra es decir para recomendar una película tengo que ver películas parecidas a una determinada cuando hablo de esto hablo de justamente en este tipo de técnicas transformar cada una de estas películas en un vector y para saber si una película es parecida a otra o no lo que tengo que hacer es justamente ver si esos vectores están cerca o están lejos para eso justamente lo que tengo que hacer es utilizar el cálculo del coseno para que me dé justamente el ángulo que existe entre esos vectores Y si están cerca estaré hablando de películas similares y si están lejos estaré hablando de lo contrario bien teniendo en claro esto vamos a pasar a ver las librerías que vamos a incorporar para este lab que en principio es pandas tf DF vectorizer que justamente el que va a ha ser la tarea de vectorización que referenciamos recién y también la librería para el cálculo del coseno y el ángulo justamente para ver lo que también referenciamos recién bien incorporamos estas librerías y luego vamos a ir justamente a montar el Drive donde tenemos este archivo de películas que como dijimos este recién también bajamos del sitio kagel vamos a ver justamente En qué sitio cag o qué página del sitio kagel bajo esta recomendación Aquí está justamente el link donde está este archivo movi metadata.csv que es el que vamos a utilizar para este lado bien habiendo aclarado eso justamente estamos con la idea de que ese archivo yo lo voy a poner obviamente en el campus virtual ustedes lo van a bajar y lo van a colocar en un Drive Drive que al montarlo como yo he hecho aquí en este caso lo vamos a usar para crear justamente un dataframe con esa información como estoy haciendo aquí luego vamos a ver el dataframe no con un Head vamos a ver todo el dataframe para ver que justamente tengo el título de la película aquí y tengo algunas características que me van a servir para poder comparar una con otra el género y un plot kw que son algunas referencias adicionales al género que son importantes para elocidad si una película es o no similar a otra lo que vamos a hacer aquí son dos cosas en principio tratar de buscar una característica que aune a estas dos pero antes que eso tengo que limpiar los datos de ambas características porque en ambos casos justamente está separado un concepto de otro a través de una barra vertical con lo cual voy a tener que reemplazar esa barra vertical por un espacio en blanco antes de ello vamos a estudiar Si este dataframe tiene valores nulos con lo cual ejecuto esto y veo que justamente género no tiene valores nulos pero plot keyw sí es más si yo miro Aquí rápidamente el dataframe con esta visualización rápida que hicimos ya veo que aquí en el cuarto elemento tengo en plot kw un valor nulo bien lo que tengo que hacer con ello como siempre es limpiar esos valores nulos y en realidad voy a reemplazar todos los valores nulos con espacios en blanco sea de esa característica pl divos u otra con lo cual si si Ahora vuelvo a ejecutar El Comando de Recién veo que en este momento ya no tengo más ningún carácter nulo paso Seguido lo que voy a hacer es reemplazar como dijimos recién estas barras verticales que veíamos Si volvemos aquí estas barras verticales que aparecen en género y en plot keywords por espacios en blanco justamente a través de esto género y con replace voy a reemplazar la barra por espacios en blanco y lo mismo para pl ejecutamos y hacemos una verificación de Data frame por las dudas y vemos que realmente ha hecho el cambio como corresponde ahora lo que tengo que hacer como dije antes es lograr una característica juntando estas dos Bueno vamos para ello con lo cual esta línea responde a esa idea texto igual a género más pl keyw con un espacio en el medio lo ejecutamos y vamos a ver rápidamente las cinco primeras observaciones para hacer un chequeo a ver si lo hizo bien efectivamente podemos ver justamente mostrando género y pl keywords y y la resultante de la Unión de ambos que le hemos puesto texto bien luego lo que tenemos que hacer es empezar a vectorizar Pero antes de vectorizar tengo que decirle esos vectores de qué dimensión van a ser y lo hago justamente especificando Max feature en 2000 con lo cual cada película va a ser representada por un vector de 2000 posiciones ahora teniendo claro esto lo que voy a hacer justamente es la transformación con lo cual voy a tomar toda la todo el Data frame completo sobre la característica texto y justamente transformar Esa esa nueva característica texto que recuerden la logramos uniendo género y plot keywords a vectores bien estamos aquí lo ejecutamos y ahora voy a ver qué tengo en x tengo una estructura de 55043 observaciones como el Data FR original pero no como el dataframe original 29 características sino que tengo ahora 2000 características porque justamente es lo que yo le dije que era el tamaño del vector que yo quería bien teniendo claro esto lo que vamos a hacer es tomar un caso testigo para hacer este este ejercicio de la comparación de una película con otra y vamos a tomar eh el vector de Piratas del Caribe Piratas del Caribe Recuerden que es la segunda película sí tenemos la primera sabat la segunda es O sea la que está indicada como número uno porque sabemos que el número ordinal empieza siempre de cero es la segunda película es piratas del carbe bien Entonces vamos a tomar aquí la segunda película con x1 tu array es decir voy a convertir Piratas del Caribe a una estructura de tipo array y aquí veo justamente cómo está conformado el vector de 2000 posiciones perdón de Piratas del Caribe lo que voy a hacer ahora justamente es con esta librería de similitud a través del coseno poniéndole como parámetro en principio la película que quio tomar como testigo la película a comparar a buscarle su par y luego todo el dataframe completo toda la x del dataframe completo para ver bueno compararme esta película con todas y decirme a Cuáles es parecida o qué Mejor dicho no va a decir a cuál es parecida va a dar el número o el porcentaje de similitud con cada una de ellas con todas las 543 en este caso con las 5042 otras películas que están en el dataframe Así que ejecutamos eso y ya tenemos dentro de similitud todas las comparaciones con cada una de las películas de El dataframe y Si vemos el contenido de similitud vamos a observar por ejemplo que tiene una similitud de 0.10 con la primer película que era Avatar como recordarán y tiene una similitud de uno es dec del 100% con la segunda película Por qué Porque se está comparando consigo misma Sí así del mismo modo veo que con la siguiente película tiene una similitud inferior a con Avatar fíjense que aquí tengo 0.05 y con Avatar era 010 si me fijo en la segunda película voy a ver que la segunda película es espectro no conozco la película pero sí vemos aquí que en caso de Avatar y pirata del Caribe tienen la Fantasía como un elemento en común y aquí esto es más un Thriller con lo cual está claro de Por qué es más parecida a Avatar que esta otra película bien Esto es para que tengan una aproximación numérica Y en este ejemplo de cómo maneja esta cuestión de la similitud en este caso si yo quiero ver la similitud la primer similitud por separado bueno pongo similitud 0,0 Por qué Porque si bien Esto está como una Ray digamos desde lo que vemos si esto que vemos aquí es una Ray es una Ray bidimensional Más allá de que a los fines de la cantidad de números es unidimensional con lo cual si yo quiero ver solamente el primer elemento podría transformar ese vector bidimensional en un vector unidimensional Cómo a través del método flatten que es lo que vamos a hacer a continuación y ahora fíjense que yo voy a Acceder al primer elemento pero no como 0 cer sino directamente como cero lo ejecuto y ven el mismo resultado pero lo tengo aplastado acuérdate que flat es un concepto de cuando quiero una matriz que está conformada como de dos dimensiones pero tiene en realidad una sola dimensión aplastarla en una única dimensión con la cual la transforma literalmente en un vector bien lo que voy a hacer ahora con esta instrucción es justamente ver Cómo ordenar las películas de más parecida a menos parecida justamente voy a crear una variable similitud ord y con el menos similitud le voy a decir que la quiero en orden inverso y con ord justamente las voy a ordenar bien lo ejecutamos y ahora con similitud gu B voy a tomar las 10 películas más parecidas de la 1 a la 11 como sabemos que se numera esto las 10 películas más parecidas en este caso a Piratas del Caribe ejecuto y veo los números de las películas más parecidas pero lo que voy a hacer es tratar de traerme el nombre de esas películas para que sea más claro entonces lo que hago justamente Es sobre el título de la película y a través del método ilock justamente con similitud gu or que es esto que tenemos aquí traer los valores 1 a 11 para que me traiga los nombres de cada uno de estos números de películas ejecuto y veo que las 10 películas más parecidas a piratas de Caribe son estas que están tituladas aquí justamente la última es otra versión de Piratas del Caribe bueno con esto ustedes pueden justamente cambiar en lugar de tomar Piratas del Caribe pueden tomar otras y justamente ver qué resultados les da y poder bueno entretenerse con este tema de la comparación a ver cuá reales a la percepción que ustedes tienen bueno con esto terminamos esta práctica y con esto terminamos la clase de hoy Hemos llegado al final de esta clase nos vemos en la próxima [Música] clase