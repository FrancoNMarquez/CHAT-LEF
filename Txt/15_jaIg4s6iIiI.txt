 Titulo: Clase8 (parte 2) Curso Inteligencia Artificial 
 URL https://youtu.be/jaIg4s6iIiI  
 2046 segundos de duracion 
 Hola bienvenidos Esta es la segunda parte de la clase número 8 del curso de Inteligencia artificial de ifes es hora de poner en práctica lo que aprendimos en la primera parte vamos por ello [Música] Hola Bienvenidos a todos a la segunda parte de esta clase número 8 donde vamos a continuar la teoría de árboles de decisión ahora en el marco de la práctica en esta clase vamos a ver tres temas lo vamos a poner en claro desde ahora y después vamos a verlo ordenadamente en el Notebook en principio lo que vamos a hacer es implementar un árbol de decisión pero ustedes como vimos en la teoría tienen Claro que este árbol de decisión sirve tanto para problemas de clasificación como de regresión vamos a ver primero un ejemplo de un árbol de clasificación y al final yo le voy a dejar una práctica que no la vamos a desarrollar en el contexto de la clase que la vamos a dejar para que ustedes después la hagan en su casa de un árbol de decisión de tipo de regresión luego vamos a ver una nueva forma de medición de la precisión del algoritmo Ya vimos en score vimos la matriz de confusión y vamos a agregar una nueva forma de validación que se llama método de validación Cruzada y finalmente uno de los temas principales que desarrollamos en la clase teórica es el tuneo de hiper parámetros sí que lo vimos claramente con el ejemplo de comparación con el caso del auto bien Esto lo vamos a seguir viendo sí de manera manual como de alguna manera lo hicimos con los algoritmos de regresión logística pero vamos a ver un método a partir del cual podemos llegar a hacerlo de manera automática que también lo comentamos en la clase teórica es decir que yo pueda tunear algoritmo a partir de un sistema automático con lo cual yo voy a obtener los mejores valores de los hiper parámetros pero no de manera manual sino a partir de la deducción que hace ese algoritmo por nosotros bien ya estamos aquí en el Notebook y dentro del tema obviamente de la clase de árboles de decisión vamos a ver el primero de los temas es decir el algoritmo de clasificación como siempre lo primero que vamos a hacer es importar las librerías hay muchas librerías en este caso y hay muchas que son nuevas con lo cual vamos a irlas comentando aquí para que ustedes tengan una idea de qué se trata cada una de esas entradas Pero la idea es verlas bien bien claramente y hacer referencias a ellas cuando lo usemos en el contexto del código y así las van a poder entender mejor luego vamos a importar a la sesión de collage el Data set que vamos a usar para esta práctica que se llama Iris csv y lo vamos a buscar ejecutando como siempre este código vamos a buscarlo dentro de la carpeta Data sets y a su vez dentro de la carpeta Iris el archivo Iris csv luego de ello y como siempre creamos una variable Data que va a contener todo ese conjunto de datos y hacemos un Head para ver justamente ese contenido ya tenemos una primera precisión aquí pero les voy a contar un poquito más de este conjunto de datos el mismo contiene 50 muestras de cada una de tres especies de Iris que son tipos de flores hay Iris de tipo cetosa y de tipo virginica y de tipo versicolor en este caso se me dieron cuatro rasgos de cada una de estas muestras midiendo el largo y el ancho del sépalo que es una característica de la flor y el largo y el ancho del pétalo que es otra característica en todos los casos en la medición se hizo en centímetros lo comentado lo vemos en detalle aquí tenemos el largo del sépalo el ancho del sépalo el largo del Pétalo y el ancho del Pétalo y finalmente la especie que es la variable Target u objetivo al menos las mismas tenemos una Clara situación a partir la cual podemos Buscar un algoritmo que en base a estos cuatro rasgos puede determinar A cuál de las tres especies pertenece cada una de estas observaciones para indagar un poquito más sobre este conjunto de datos vamos a hacer como siempre un Data shape y con ello podemos constatar que tenemos las 150 observaciones que mencionamos al principio cuando les conté de qué se trataba este Data set y las cinco columnas que referenciamos recién dijimos que hay 50 especies o 50 observaciones de cada especie Perdón eso lo podemos constatar justamente con esto que escribimos aquí agrupar por especies y contar Cuántas hay de cada especie lo ejecutamos y podemos constatar que tenemos efectivamente 50 observaciones de cada una de esas especies ahora que ya estamos seguros de los datos que tenemos vamos a armar los conjuntos de entrenamiento y de test para crear el modelo luego entrenarlo y finalmente medir su score o precisión para ello vamos a separar primero las variables de entrada y la variable objetivo o de salida por eso que estoy poniendo un código a partir del cual generó la x con todos los datos de entrada y la i con el dato objetivo o dato de salida lo ejecutamos como dato complementario les pongo una alternativa a este código en el cual puedo lograr el mismo objetivo pero en este caso buscando referenciar las columnas es decir los nombres de cada una de las características en lugar de por su nombre por su número de índice esto es interesante porque a veces cuando tenemos muchas características este tipo de código que he puesto como ejemplo aquí abajo evita que Cometa el error de escribir mal el nombre de una característica y Por ende que el procedimiento salga mal Así que les dejo ese código para que lo puedan usar también en este caso y reemplazar esto que he puesto aquí por estas cinco líneas que están aquí debajo y finalmente hago lo que venimos haciendo anteriormente que es separar el conjunto de entrenamiento y el conjunto de Test Así que lo ejecuto a modo de verificación puedo ver cuántos quedaron Cuántas observaciones quedaron en un conjunto Y cuántas oraciones quedaron en el otro Así que ejecutó este código y a través del end puedo medir en largo del conjunto de entrenamiento que aquí veo que son 112 observaciones y el largo del conjunto de Test que tiene 38 con lo cual la suma de ambas llega a las 150 de el conjunto de datos original estos pasos que hemos hecho guardan alguna diferencia respecto a lo que hicimos en las dos prácticas anteriores evidentemente No eso es importante que lo tengan presente porque si bien vamos a ir viendo distintos algoritmos es Claro que hay muchos procedimientos que van a ser los mismos Más allá del algoritmo que se trate la diferencia empieza Ahora cuando voy a crear el modelo porque voy a usar un algoritmo diferente a los que usamos en la clase anteriores por eso usamos ahora el decision Trick clasifit al mismo modo que en su momento usamos un método para la reelección lineal y luego un método para la región logística Esta es una de las librerías que importamos que como dijimos en el principio de la clase la vamos a ir destacando en la medida que lo vamos usando ver aquí de sidekit import decision que es justamente esto que ahora voy a empezar a usar para crear justamente mi primer algoritmo de árbol de decisión pero como dijimos en la teoría de esta clase vamos a hacerlo también teniendo en cuenta el tuneo de sus hiper parámetros Y en este caso particular vamos a utilizar dos simples parámetros criterium y 1000 sapes split el primero tiene dos opciones entropy o shini como dice el texto que aquí yo le he puesto para que tenga más claro este concepto determina el criterio para la división de los nodos de un árbol como vimos en la teoría los nodos hay que dividirlos con algunos criterios bien Los criterios pueden funcionar de un modo de otro con estas dos alternativas de El tuneo del hiper parámetro epitelio el criterio de shini es mucho más rápido porque es menos costoso computacionalmente pero los resultados obtenidos en el criterio de entropía entropía son ligeramente mejores datos a tener en cuenta para probar con una opción a otra y mil SAP split es la cantidad mínima de valores para seguir con ramas desde un nodo Qué quiere decir esto es decir yo voy a llegar un momento que voy a tener supongamos 50 observaciones y lo que voy a determinar es si esas 50 observaciones ameritan que siga abriendo ramas o ese es el nodo último que voy a ir a considerar Cómo se estipula esa cantidad mínima de valores para seguir con ramas de un nuevo justamente con el hiper parámetro 1000 samples que en este caso que voy a crear Este modelo de árbol de decisión lo voy a estipular en el valor 20 bien en el caso particular insisto de esto que voy a hacer aquí entonces elegí en tropit para el hiper criterium y 20 para el hiper parámetro mini samples Speed lo ejecutamos y ya tenemos ahora nuestro modelo a partir de lo cual vamos a hacer las predicciones como hacemos Siempre sobre el conjunto de Test y vamos a ver ahora a través de la matriz de confusión empezar a medir la precisión del modelo veo que la presión es bastante buena por lo que veo aquí dado que no tengo ningún error en el caso de la primera especie tengo un solo error en el caso de la segunda especie y no tengo ningún error en el caso de la tercera especie lo podemos ver más fácilmente a través del score con lo cual voy a medir como siempre el conjunto de entrenamiento del conjunto de Test y veo que son muy buenos indicadores tanto para un caso como para el otro más allá de que en el caso de Test siempre es deseable que sea un poco superior al caso de el modelo de entrenamiento bueno la diferencia como en algunos casos hemos visto no es tan grande con lo cual pude considerarse que este es un buen modelo para este caso bien Ahora vamos a ver otro recurso nuevo que nos permite ver el modelo de árbol de decisión creado de una forma muy detallada muy clara con sus nodos sus ramas y los elementos que forman el criterio para cada uno de los nodos para ello vamos a usar la librería plot Tree tal cual lo vemos aquí que es una de las librerías que seleccionamos al principio dijimos que vamos a ir comentando en la medida que vamos avanzando justamente depende de sideking lane.3 que es la misma librería que nos permitió Acceder al precisión triple líneas precedentes al gráfico que estamos viendo ahora volvemos al gráfico y vamos a hacer así vamos a ejecutar Primero este código vamos a ver el gráfico y después vamos a aplicar cada uno de estos códigos que están aquí Qué significa o qué impacto o incidencia han tenido sobre el gráfico que vamos a ver a continuación Así que ejecutamos este código y ahora vemos el árbol bueno fíjense que esto es parecido a lo que vimos en la teoría donde cada nodo en este caso es esta cajita que está acá obviamente diferencia en colores de acuerdo a la especie la especie la clasificó con letras psy no es exactamente el nombre de la especie original sino que lo clasifica con una letra pero importante la información que tienen aquí fíjense lo primero que tiene de ese criterio en este caso el primer criterio el primer rasgo que tomó es la longitud del Pétalo y empezó a tener como criterio primero importante si es menor igual que 2.45 Qué información más tenemos aquí la cantidad de samples la cantidad de observaciones acuérdense que este es el conjunto de entrenamiento que tenía 112 y lo que me muestra aquí es que de la 112 hay 35 que pertenecen a primera especie 39 de la segunda y 38 a la tercera de allí empieza toda la lógica similar a lo que vimos en la teoría hasta llegar a este nodo último que es el nodo de decisión este no sigue para este lado sigue para este lado termino un nuevo decisión y así hasta llegar al último nivel este árbol tiene como dice el texto aquí una profundidad de Qué quiere decir profundidad la cantidad de niveles que tiene el árbol sacando el nodo raíz fíjense que tenemos uno dos tres Y cuatro Y el otro dato importante es la cantidad de nodos de decisión nodos finales Tenemos uno acá tenemos dos acá tenemos tres cuatro y cinco vamos al código bien lo primero que tengo que tener en cuenta aquí es que he usado una estrategia de graficación de subplots se acuerdan que sub plots lo usamos para cuando quiero usar gráficos que estén como si fuese una estructura matricial de filas y columnas con lo cual acá yo le indico que voy a hacer un gráfico de tipo suplos y que cada una de esas Cuadrilla que tiene que ver o esa celda eso supuesta matriz tiene un site de 12 por 10 luego hago una impresión por eso antes del gráfico aparecen estos dos textos de referencia justamente a través de dos prints donde lo que recurro esa parámetros que se desprenden del objeto creado es decir en Tri que crea aquí arriba como modelo Cuáles son esos elementos getdef que es el que Dime la profundidad del árbol y con get en el ists Deme la cantidad de no de decisión por eso esos dos parámetros que los invoco de este modo los imprimo y me dan estos dos textos que están aquí arriba bueno ahora sí vamos al plot Tree lo primero que tengo que ponerle es cuál es el árbol que quiero dibujar obviamente El Tri Cuáles son las características de entrada las que ya hemos manejado Cuál es la característica de salida la especie que también hemos manejado con filder que quiere decir rellenar tú le digo que quiero que rellene con colores Sí cada uno de los tránsitos ven que va siguiendo justamente rellenando con colores me permite diferenciarlos más claramente false es para ver si quiero poner la impureza como dato aquí no lo voy a hacer en este caso phone 6 10 es el tamaño de la letra digamos de aquí dentro precisión 2 es la cantidad de decimales que quiero que aparezcan en el caso de cada uno de estos elementos de decisión fíjense que todos los casos salen dos decimales y finalmente a x le indicó justamente que de qué cuadrícula va a tomar o que qué estrategia de cuadrícula justamente de esta que he definido acá arriba como fic AX con todos esos elementos yo lo que obtengo es este gráfico que es muy importante para poder tener una visualización Clara del árbol que Se generó justamente a partir de la creación de este modelo de seacesion ahora vamos a ver el segundo punto de esta clase tal cual lo anunciamos al principio de la misma que es el tema de el método de validación Cruzada como una forma más de la medición de la precisión de nuestro algoritmo vamos a ver el siguiente gráfico para explicarlo bien y vamos a detallar los puntos que ustedes tienen aquí de alguna manera explicados dentro del texto que continúa a Este título que acabamos de mencionar recién es decir en este caso lo primero que tenemos que hacer es elegir un número de pliegues es decir En cuántas partes voy a subdividir este conjunto de datos a ese número lo llamamos K por eso el nombre de este método de evaluación Cruzada se llama key folk o kfall bien luego lo que tenemos que hacer es dividir el conjunto de datos en esas partes supongamos en 10 partes eso se llaman pliegues por eso el nombre de fold sí es doble ceses en este caso lo que voy a hacer en principio es elegir K menos un pliegues como conjunto de entrenamiento Así que si hice 10 subdivisiones elegiría 9 pliegues para entrenar al modelo luego entreno el modelo justamente con ese conjunto de entrenamiento y calculo el score esas tres últimas acciones las vuelvo a repetir cuantas veces cada vez Es decir si elegí 10 10 veces y por cada una de ellas vuelvo a repetir lo mismo redistribuyo tomo un nuevo conjunto de entrenamiento el score y pasa el siguiente cuando llego al final voy a tener cuantos voy a tener 10k score Por decirlo de alguna manera se toma como ejemplo que tome el número 10 tendría 10 scores con lo cual el score final va a ser el promedio de todos ellos a continuación vamos a crear un nuevo modelo para empezar a probar este nuevo método de validación Cruzada donde voy a usar los mismos hiper parámetros los mismos valores de parámetros para criterium y para minsamble Speed pero voy a agregar un nuevo hiper parámetro que se llama Max de qué es lo que vimos recién en el gráfico la profundidad Max Def lo que le indica no es la profundidad que tiene que tener el árbol sino la máxima profundidad a la cual tiene que llegar en árbol bien Vamos a hacer entonces aquí Perdón la ejecución del código para crear el modelo entrenarlo y crearlo como siempre y ahora sí vamos a implementar el método de validación Cruzada de kyfall justamente con un cap igual a 10 como lo decíamos recién en el Cómo se hace primero tener una variable a través del método kyfall método Que vuelvo a las librerías aquí arriba habíamos importado al principio sí aquí lo tenemos de cycle Modern selection import Y también vamos a usar Cross Ball score que va a ser justamente la forma de medir el score de ese método de validación así que ya nos adelantamos a ese hecho que lo vamos a utilizar justamente en esta parte que estamos viendo ahora Bueno estamos aquí y volvemos keyfall lo primero que le digo En cuántos splits En cuántas partes quiero dividir ese Ese Conjunto este de datos yo filtro Recuerden que era remover los datos si este rey de alguna manera redistribuir los datos permanentemente y randomstein 1 acuérdense que también es un argumento que usamos justamente para cuando hay algún modelo o algún conjunto o alguna acción que nos gusta bueno poder volver a invocarla justamente a través de ese número luego lo que voy a hacer es obtener los scores ahora ya tengo sí el método de validación cruzado implementada lo que tengo que hacer ahora es obtener los scores de ese método de variación Cruzada Por eso ahora sí uso el crosscore que recién referenciamos dentro de la librería que estamos importando Y de paso el árbol los valores de entrada los valores de salida Le digo qué tipo de scoring Quiero el que usamos siempre el de presión aquí ahora sí y le digo justamente de dónde quiero que saquen información de la cantidad pliegues que tiene el conjunto que acabo de subdividir y justamente de cb que se ve esto que está aquí arriba y esto que está acá arriba salió de la implementación del método de evaluación usada una vez que hago eso lo vamos a ejecutar voy a obtener a través de sendos Prince Sí en principio scorcean no es un valor es una matriz que tiene Cuántos valores 10 porque elegir justamente un keyfall 10 y finalmente lo que voy a hacer con todos esos scores es hacer un minimin Recuerden que era promedio con lo cual veo que tengo 1093 1 093 tengo una variedad de scores que en promedio todos me dan un 0 96 que es un muy buen score ahora bien como siempre decimos que un modelo nos dé un score bueno no quiere decir que no pueda ser mejorable y Aquí vamos a ver algo de el tema de tuneo de parámetros nuevamente pero desde un punto de vista diferente ya que antes lo de manera manual es decir pusimos un valor nosotros que estimamos que podía ser 5 ahora vamos a hacer un algoritmo sin llegar todavía a la automaticidad que hablamos al principio de la clase simplemente un algoritmo a partir del cual lo que yo voy a hacer va a ser cambiar este valor de aquí de la profundidad del árbol de 1 a 7 a través de una estructura Ford es decir foreing rage 1 8 quiere decir de 1 a 7 va a ser que este algoritmo se ejecute siete veces partiendo de un Max 1 2 3 hasta llegar a 7 con esto vamos a crear un modelo tal cual lo hicimos antes y luego le aplicamos un método de validación Cruzada y observamos cuál es el score que tenemos e imprimimos a continuación el score Esto no es muy diferente lo que hicimos aquí arriba donde creamos el modelo y aplicamos el método de validación Cruzada solamente que está en el contexto de un Ford y Por ende va a pasar siete veces sin que yo lo haga siete veces manualmente cambiándole manualmente insisto el valor de la máxima profundidad de el árbol luego tenemos otro Ford Porque otro Ford también vamos a incorporar un tema nuevo por eso es interesante este tema Dentro de este Ford yo voy a poner otro Ford que vaya de 0 a 4 es decir que va a ejecutarse cuatro veces en el cual yo voy a recorrer cada una de las variables de entrada esas variables de entrada que las identificó con data.colums subj entendiendo que J va de 0 a 3 me va a permitir ver aquí el nombre y al lado a través de el método feature importars que es filtro de la característica es el nombre de la variable de entrada importas en la importancia de esa característica de entrada subj porque porque justamente me va a mostrar la importancia de cada una de las cuatro características con esto también vamos a poder ver luego de ejecutar este código la importancia que tiene en ese momento digamos para esa profundidad del árbol cada una de las cuatro variables de entrada lo ejecutamos como vemos aquí los resultados Sale primero el título que dice score paradef 1 es de 0,667 es decir este texto que está codificado aquí arriba Así que está programado aquí arriba es el resultado lo que se ve aquí luego está este Ford que hablábamos recién y fíjese lo que me muestra el nombre de cada una de las variables de entrada y el nivel de importancia que tiene en el contexto de ese algoritmo para la profundidad 1 justamente 0 0 1 y 0 es decir que para este algoritmo para la profundidad 1 el 1 la única variable de entrada Perdón importante es el largo del pétalo Yo podría en este algoritmo reprogramarlo prescindiendo de las otras tres variables de entrada miremos un poquito hacia abajo vemos que en el caso de la profundidad 2 ha mejorado y mucho el score ahora fíjense que el nivel de importancia se distribuye entre el largo del Pétalo y el ancho del pétalo todavía sigue siendo un poco más importante el largo pero el ancho del pétalo también va teniendo su importancia si mira un poquito más abajo el score mejora ya no tanto como en el caso de 2 a 1 pero Mejora y también el grado de importancia cambia vuelve a ser un poquito más importante el largo del pétalo que el ancho del pétalo si sigo mirando hacia abajo voy a poder comprobar que ya de 4 hasta 7 profundidades me refiero al índice de profundidad el score no va a cambiar siempre va a ser 096 bien en el resto de los casos y del mismo modo la importancia de largo del Pétalo y del ancho del pétalo va a ser exactamente la misma a pesar de que cambia de 3 a 4 ya entre 4 5 6 7 es exactamente lo mismo con lo cual podemos concluir que la profundidad sería tres o cuatro podríamos llegar hasta 5 y justamente con la importancia de las características podríamos concluir que para este algoritmo podríamos prescindir de las variables de entrada del largo del sépalo y de ancho del sépalo y ahora vamos a ver el tercer y último punto de esta clase grid ser cb que es Ni más ni menos que el tuneo automático de panel recién variamos los valores de la profundidad del árbol de manera dinámica pero los valores los fijamos nosotros Nosotros dijimos a través del Ford de Qué valor queríamos que fuera hasta Qué valor y solamente uno de los hiper parámetros fue el que fue objeto de este trabajo para a través del Ford en realidad existe una opción automática que es el uso justamente del método glitch ser se ve que vamos arriba es una de las librerías que seleccionamos al principio de esta práctica vamos a buscarla sí ven que aquí tenemos justamente en model selection donde habíamos seleccionado keyfall y validación Cruzada también está grid se ve bien volvemos al código y vamos a explicar un poquito de qué se trata este método para que se utiliza se ve en realidad es una técnica para encontrar los valores de parámetros óptimos de un conjunto dado de parámetros en formato de cuadrícula por eso lo de grid concretamente es una técnica de validación Cruzada similar a la que hemos recién para la validación del algoritmo pero ahora para determinar no solamente eso sino el mejor o las mejores combinaciones de parámetros de valores de parámetros para lograr el mejor escort en concreto lo que hay que hacer es ingresar en ese modelo un conjunto de opciones de parámetros y el algoritmo se va a encargar de determinar para cada uno de esos parámetros Cuál es el mejor valor o valor o estimador óptimo en Post como decimos siempre de lograr el mejor score bien en la práctica de grids ser cb lo que vamos a hacer es dar dos ejemplos uno a través del hiper parámetro ccp- bajo Alfa y otro tuneando 4 hiper parámetros en conjunto Por qué usamos ccp guión bajo Alfa bueno nosotros vimos en la teoría de esta clase que una de los problemas que tenía este modelo o este algoritmo de árboles de decisión es el sobre ajuste y una de las maneras de caer en ese problema es dejar que el árbol crezca indefinidamente este hiper parámetro ejecuta una tarea que se llama poda del árbol que justamente evita ese problema Por lo tanto este hiper parámetro yo lo voy a configurar con valores 10 valores que vayan entre 0 y 5 cómo lo voy a hacer A través de el método Line space de nampai y voy a poner el valor mínimo el valor máximo y cuántos valores quiero que aleatoriamente genere este método entre 0 y 5 eso lo pongo dentro de una variable que se llama parangred pero tengo que etiquetar esto que está aquí porque tengo que hacer referencia después de que esta distribución de valores tiene que ver con el hiper parámetro ccp guion bajo Alfa paso seguido uso el método y pongo el contenido de lo que va a generar dentro una variable que se llama el grid como insisto le puedo poner Cualquier nombre la primera información que tengo que poner aquí es relativa al algoritmo sí es decir un árbol de decisión para un problema de clasificación pongo en principio la profundidad máxima no nada la cantidad de samples split 2 y samples League 1 y Random State lo voy a dejar en un número como siempre yo lo pongo para que después me quede como referencia que son estos 12 parámetros Ya lo habíamos explicado dijimos que es la cantidad mínima de muestras de observaciones que tiene que haber para que sea meritorio poder generar dos ramas evidentemente si no no tengo más de dos elementos no voy a poder generar dos ramas y Miss uppers Live es la cantidad de elementos que como Mínimo debería quedar en alguna de las dos ramas si esto se configura por defecto en uno Obviamente que si yo de nuevo tengo dos ramas no puedo tener todas las muestras En una rama y ninguna muestra en otra rama entonces digo como mínimo en una de las dos ramas tiene que haber una muestra obviamente esto se puede configurar Y variando estos valores obviamente resultado va a ser diferente luego lo que pongo es justamente en el argumento parangred la variable o el contenido de la variable que puse acá arriba que son justamente los valores de El hiper parámetro ccp guión bajo Alfa luego defino que quiero un scoring deacura así como ven usando siempre una cantidad de dobleces sí de el método de validación Cruzada de 10 y le digo que quiero un refrito un reentrenamiento y que también quiero que justamente me muestre o me regrese me retorne el score de ese entrenamiento y luego finalmente hago el fit que justamente lo hago con grid bien grid poniéndole lo que venimos usando siempre el conjunto de entrenamiento x y el conjunto de entrenamiento ahí con esto vamos a tener un nuevo modelo a partir del cual podemos tener los resultados de los parámetros de los valores de los parámetros de los siete parámetros perdón de una manera automática lo ejecutamos ahí tenemos el resultado y ahora vamos a poder obtener justamente Cuáles son los best params Cuáles son los mejores parámetros Sí para el ccp- bajo Alfa Recuerden que habíamos generado valores que iban entre 0 y 5 Cuál será el mejor lo veremos aquí luego voy a crear el árbol que le voy a poner como antes llamado que la tengo la mejor solución por eso le puse ese nombre a través de el método pese estimator de encript y que es el grid el grid es la resultante de aplicar el método sí bien y finalmente bueno Esto que estoy poniendo lo importante Obviamente que es esto todos los primos son simplemente formas de conocer información que es importante de todo lo que haya generado por eso también voy a mostrar como antes la profundidad del árbol y la cantidad de nodos terminales lo ejecutó y voy a poder ver que el mejor ccp- bajo Alfa es cero sí es decir que de entre todos los valores que elegimos acá eligió el mínimo bien y luego tenemos una profundidad de árbol de 5 y la cantidad de nuevos terminales de nuevo como antes podemos ver esto de una manera mucho más clara a través de un gráfico con lo cual hacemos lo mismo que hicimos hoy bien solamente que ahora en lugar de usarlo con Tri lo hago con Tri final porque es este árbol Perdón que he generado aquí sería Acuérdese que es en algo la anterior ahora generamos este Tri final que es resultante de haber aplicado el grises así que sin más palabras vemos la estructura del árbol creado y obviamente va a responder a una profundidad de 5 1 2 3 4 5 y tengo obviamente más nodos terminales 9 podemos ver aquí uno 2 3 4 5 6 7 8 fíjense que acá como son más nodos me ha quedado más juntos y en algún caso hasta hace un lapado bueno eso tiene que ver con que con esta configuración si yo acá cambio el size si lo pongo más chiquito o más grande obviamente va a cambiar esa situación y ustedes pueden jugar con estos valores para ver justamente el estado lo que van a hacer es que van a ver estos cuadrados más chicos si estos rectángulos Perdón más chicos o más o menos distanciados bien con esto podemos comparar con el gráfico que obtuvimos anteriormente Sí sí recuerdan si lo rescatamos Aquí está ve que tenía una profundidad de 3 y 5 nodos de decisión Este es el que habíamos generado como Tri al principio bien Ahora el que generamos con el tuneo automático de hiper parámetros como dice el título aquí tiene más profundidad y obviamente si tiene más profundidad tiene más nodos terminales que esto se ve comparando los gráficos de uno con el otro y bien con esto Hemos llegado al final de esta segunda parte de la clase 8 y de la clase 8 común todo hemos podido poner en práctica el desarrollo de un algoritmo de árbol de decisión para un problema de tipo de clasificación y luego hemos ido trabajando otras opciones con el tuneo de hiper parámetros de manera manual de manera automática y también incorporamos el método de validación Cruzada con una forma de edición nueva del score con cada uno de estos ejemplos hemos obtenido un score la idea justamente es Buscar de todas estas variantes que utilizamos Cuál es el mejor score y en base hecho determinar el mejor modelo yo lo voy a dejar aquí después de esta línea como viene aquí abajo dos ejemplos ampliatorios de todo lo que vimos que van a poder interpretar fácilmente porque yo le voy a poner Aquí también Bueno una explicación y independientemente esto Quien tenga alguna duda siempre tiene el campo virtual para consultar una es la posibilidad de trabajar con los hiper parámetros pero en lugar de hacerlo solamente y ponen ccp guión bajo Alfa lo vamos a hacer como dijimos antes de manera particular con Max Death minsapple Speed y minsamble leaf y finalmente vamos a les voy a dejar también un código para que ustedes Ven aquí de lo que es un algoritmo de árbol de decisión pero de tipo de regresión o sea para un problema de revisión y no para un problema de clasificación como Vimos a lo largo de toda esta clase bueno con estos dos códigos que le dejo también en este Notebook que lo vamos a guardar en la clase pero que quedan para que ustedes lo vean terminamos entonces la clase número 8 y los espero en la próxima clase hasta aquí llegamos con la clase número 8 ahora ya tenemos los conceptos y las habilidades prácticas para un nuevo algoritmo de Machine learning los árboles de decisión nos vemos en la próxima clase