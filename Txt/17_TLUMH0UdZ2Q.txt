 Titulo: Clase 9 (parte 2) del Curso de Inteligencia Artificial 
 URL https://youtu.be/TLUMH0UdZ2Q  
 1931 segundos de duracion 
 Hola bienvenidos Esta es la segunda parte de la clase número 9 del curso de Inteligencia artificial de ifes en ella vamos a poner en práctica todo lo que aprendimos en la primera parte vamos por ello [Música] Hola a todos nuevamente vamos a empezar la segunda parte de esta clase número 9 tratando de poner en práctica todos los conceptos teóricos que vimos en la primer parte de esta clase antes de empezar con la clase propiamente dicha vamos a ir a ver lo que hicimos en la clase pasada justamente la parte número 2 en la implementación práctica de un algoritmo de árbol de decisión por qué Porque justamente habíamos tomado en principio la idea de ejemplificar el uso de este algoritmo a partir de un ejemplo basado en un problema de clasificación y habíamos tomado Para ello el dataset de Iris se acuerdan de las flores y del mismo modo habíamos hecho al final sí que lo había dejado como un ejercicio adicional un ejemplo de un problema de regresión donde habíamos tomado como ejemplo el mejor dicho como como medio para poder ejemplificar ese algoritmo en ese caso un Data set de Boston ccv de las casas de Boston del valor de las casas de Boston que ya lo hemos usado también en la parte de análisis de datos bueno por qué referencia esto porque vamos a hacer lo mismo pero ahora justamente con el Random Forest es decir con los bosques aleatorios Vamos a abordar primero el problema de clasificación con el mismo conjunto de datos es decir de Iris que en el caso de los árboles y vamos a ir luego a un problema de regresión y vamos a tomar también el mismo caso el mismo dataset perdón de Boston csv que usamos en el caso de los árboles en la clase número 8 esto nos va a permitir ver qué cosas tienen en común ambos algoritmos Qué cosas son diferentes y también poder comparar lo más importante de todo esto que es el score que logró en un caso y en otro vamos a permitirnos hacer un pequeño paréntesis porque seguramente en esta aplicación introductoria de esta clase habrán visto un detalle que quizás le habrá llamado la atención y bueno puede ser una buena oportunidad abordarlo habrán visto que en este Notebook yo lo que he hecho en el anterior es hacer clic en este símbolo y lo que hace es ocultar o Mostrar todas las celdas que están debajo de Este título simplemente haciendo guía acá fíjense que como está contraído me parece un mensaje que dice que hay 15 celdas ocultas que la veo cuando clic en este botón sí Y ahí aparecen todas las celdas y luego veo en el siguiente título lo mismo bueno Esto es una forma de poder ver rápidamente el contenido si yo soy ordenado y pongo cada una de las secciones con un título que encabece que viene después si a nivel de código de qué se trata es el código que viene después y poder tener una lectura más comprensiva del texto de todo el Notebook y después abrir cada una de las secciones que a mí me interesan para ver la cuestión del código que está de alguna manera referenciado por ese título que está allá arriba y bueno un paréntesis para aprender algo nuevo no en este caso de Machine learning no en este caso ni de bosque ni de árboles sino de lo que es Cómo se maneja el Notebook de cola vamos ahora entonces con el primer código o la primera parte de código de este ejemplo vamos a compararlo con la clase anterior y vemos que las librerías son prácticamente las mismas y o pandas nampas split aquí aparece lo diferente obviamente porque este algoritmo no es igual que el que usé antes que es un decisión triple sino en este caso es un Random Forest classippier y sale de otra librería antes era de sidekitland Tree ahora es de essamble luego viene plot Tree que es lo mismo que usamos en la clase pasada y finalmente grid set se ve que a diferencia de la clase pasada incorporamos keyfall y crossbal score que en este caso no vamos a usar y finalmente warnis es decir que la librería son virtualmente las mismas Así que las ejecutamos y va a llevar como siempre un tiempito más porque no está conectado Así que Esperamos que justamente No solamente ejecute la primera celda sino también que establezca la conexión de este cono ya está ejecutada la conexión Ahora sí ejecuta la importación de las librerías y paso seguido pasamos a incorporar el dataset que vamos a usar para esto que como ya dijimos antes es el de Iris Aquí está lo incorporamos y una vez que está hecho Hacemos como siempre un gel vamos a agrandar un poquito más esta pantalla como solemos hacer para verlo mejor bien ahí Nada nuevo ustedes ya lo han visto muchas veces y hacemos un save para asegurarnos de que realmente hemos recibido todo el conjunto de datos tal cual está prescrito y conocido por nosotros es decir 150 observaciones y cinco características a continuación vamos a preparar los datos para el entrenamiento hecho similar a lo que habíamos hecho la clase pasada donde habíamos logrado el x y el y referenciando al Data con los nombres de cada una de las características para las x y con el nombre de la única característica que es el elemento Target parali pero recuerdan que yo no había puesto aquí abajo este comentario de otra forma de hacer Esto justamente no usando el nombre de las características sino su referencia por su número de índice y eso es lo que vamos a aplicar aquí es decir este código que está aquí es lo que yo le puse como ejemplo alternativo en el cola número 8 y que los invite a que lo proba su cuenta dado que el resultado Debería ser el mismo pero como otra forma de lograrlo bien Esto lo que vamos a hacer aquí con lo cual lo ejecutamos y paso seguido vamos a separar los conjuntos de entrenamiento de Test como lo hacemos regularmente con lo cual al ejecutar este código obtenemos la misma información que habíamos tenido en el caso de los árboles de que el conjunto de entrenamiento está conformado por 112 observaciones y el conjunto de Test por 38 a continuación vamos a crear nuestro modelo con Random Forest clasifire así como en la clase anterior decisión bien Ahora usamos el algoritmo de bosques aleatorios y luego hago el entrenamiento como habitualmente lo hacemos en este caso vamos a usar hiper parámetros la explicación que está aquí arriba ya la vimos en la parte teórica de esta clase con lo cual no vamos a ahondar en ello si simplemente rescatar que vamos a utilizar 10 estimadores a pesar que en la teoría estamos diciendo que es como se debe aplicar que la cantidad de estimadores deben ser 100 o más de 100 pero bueno a título de que quiero mostrarles el gráfico de un bosque de una manera muy sencilla vamos a hacer una cantidad de estimadores que pueda facilitarnos esa visualización Pero obviamente está claro que eso no es lo que debería hacer bien lo ejecutamos y obtenemos este Random Forest clasifire y medimos como hacemos habitualmente su precisión para el modelo de tren y para el modelo de Test obteniendo 098 y 094 bien Vamos a graficar ahora el modelo y vamos a tener en cuenta lo siguiente como hemos repetido desde la teoría y hasta ahora el bosque Está compuesto por árboles si yo me remito a lo que hice en el colar número 8 tengo aquí justamente el código que me llevaba a mí a poder graficar el árbol Pero qué pasa ahora yo no tengo un árbol tengo muchos árboles porque tengo un bosque Cuántos árboles tengo bueno tantos como estimadores y yo haya indicado a la hora de crear el modelo en este caso 10 por lo tanto yo tengo ya una vez creado el modelo tengo un bosque con 10 árboles y cada uno ya está diseñado por lo tanto este código que yo creaba antes para poder graficar un árbol Ahora yo tengo que ejecutarlo 10 veces por lo tanto necesito de un Ford que me recorra y me dé información de cada uno de los árboles del Bosque y por cada uno de ellos haga un gráfico Tenemos aquí Ford árbol que es el nombre que he decidido darle a esta variable como puede ser siempre como decimos cualquiera y Ford class.estimators guión bajo Ford Class es el nombre del modelo que yo creé de Random Ford clasifit y punto estimados guión bajo es cada uno de los árboles que forman parte de ese bosque por lo tanto yo hago este Ford y por cada Ford escribo exactamente el mismo código porque lo que va a hacer es lo mismo que hacía antes solamente que 10 veces lo ejecutamos y bueno va a tardar un tiempo prudencial fíjense que ya se va visualizando abajo ven que van apareciendo los árboles o los arcos obviamente los va poniendo como ya vimos anotaría uno debajo del otro ya terminó con lo cual yo ahora puedo recorrerlos cada uno de los 10 árboles que como mostramos en la teoría no todos están conformados ni por la misma cantidad de características ni por la misma cantidad de observaciones Lo importante es que son 10 y cada uno de ellos podemos observar aquí la forma y justamente la decisión que tiene cada nodo y cuando termina cada uno de ellos obviamente Este ejemplo que he puesto aquí lo he hecho basado en 10 estimadores porque lo que va a pasar a continuación justamente que lo vamos a hacer con 100 y obviamente va a tardar mucho más y la visualización de 100 árboles obviamente va a ser mucho más compleja si lo queremos tomar a título de ejemplo obviamente lo podemos ver con mucha paciencia Pero obviamente se puede ver también así que es lo que vamos a hacer a continuación por eso tal cual dice el título Aquí vamos a repetir El ejemplo pero en este caso con 100 estimadores que como venimos diciendo reiteradamente es el mínimo recomendado por lo tanto creamos el modelo especificamos la cantidad de estimadores aquí lo entrenamos y obtenemos su precisión viendo que en el caso entrenamiento es una presión ideal del 100% y en el caso del modelo de test del 97%, no son malos scores hay que tener cuidado con este 100% del modelo de entrenamiento porque puede ser un problema de sobreajuste bien Más allá de eso lo que vamos a hacer ahora es graficar este árbol para lo cual he escrito el mismo código que había escrito antes solamente que lo he hecho de una manera más condensada fíjense que en este caso lo había hecho en varias líneas esto obviamente permite una visualización del código mucho mejor en este caso lo he hecho de una manera más condensada para poder empezar a ver ahora sí aquí abajo Cómo se van a ir creando cada uno de esos 100 árboles Así que lo ejecutamos ya y evidentemente este proceso va a durar mucho más tiempo que la anterior fíjense que aquí bajo me da referencias del tiempo de ejecución y todo el proceso digamos que va haciendo para crear este árbol bien ahí terminó vamos a corregir una pequeña F de ratas que acá dice gráfico el árbol creado y en realidad es el bosque vamos a ponerlo como corresponde para no cometer un error de concepto y vamos a guardarlo para que se haya registrado en esto que después va a llegar a sus manos bien han visto que ha tardado mucho tiempo obviamente mucho más que en el caso anterior 58 segundos está actualiza aquí abajo con respecto al caso anterior Pero bueno lo que tengo ahora es justamente dentro de esta estructura cada uno de los 100 árboles que ustedes lo han visto porque en esta visualización acelerada que le he puesto en este vídeo han podido ver como iba apareciendo cada uno de estos árboles de este bosque vamos a pasar ahora al grid para bueno ver si con los manejos de hiper parámetros podría obtener un mejor es difícil tener un mejor score porque en el conjunto de Test Debería ser Superior entrenamiento superior al 100% no va a poder ser pero bueno insisto no nos quedemos con esa idea de ese 100% como que ya logramos un objetivo sigamos probando otras alternativas y justamente glitch ser cb nos permite eso esto lo usamos recordarán en el caso de los árboles de decisión y lo vamos a reiterar también en bosques aleatorios vamos a utilizar justamente en el parangred todas las opciones con que quiero que ese grid vaya combinando en puedo tener un mejor score por lo tanto en el caso de la cantidad de estimadores voy a poner una etiqueta en este momento acuérdense que la etiqueta tiene que llamarse igual que cómo se llama o se denomina al hiper parámetro sí es decir lo que tenemos pero no en el árbol aquí en el modelo en este momento bien esos nombres tienen que ser idénticos a las etiquetas que yo pongo obviamente no tienen que ser todos tienen que ser los que yo quiera nutrir a este glitcher se ve elijo en estimados y le ponemos entre corchetes los valores opciones con que quiero que ese ser vaya trabajando en el caso en este mérito 100 200 y 300 en el caso de Max features 23 en el caso de Max sampling dos tercios y tres cuartos acuérdense que este obviamente tendrá que ver con la característica del Data set en este caso tenemos con cuatro características de entrada con lo cual obviamente las opciones no pueden ser muy amplias si fuesen más características esos valores podrían tener mucha más opciones luego más que nada 35 y 7 la profundidad de los árboles de este bosque Y criterium ahí no tengo más que esas dos características luego obviamente hago el cb le digo que quiero un método de validación Cruzada de 10 folls de se acuerdan de los 10 pliegues que esto también lo vemos en la clase pasada y bueno después el resto es similar a lo que habíamos armado obviamente una vez que haga gris lo voy a entrenar para obtener un score lo ejecuto ahora y finalmente el proceso determinado ha tomado 5 minutos esto le da la Pauta De que al igual que en el caso anterior del tiempo que nos tomó graficar el árbol ahora que tenemos 100 estimadores esto tarda mucho más en este caso no son 100 sino que tenemos 100 200 y 300 como opción Por eso tardó mucho tiempo el desarrollo de este proceso Comparado con el que nos tocó cuando hicimos en la clase 8 el mismo proceso pero para un solo árbol obviamente en este caso un grid se ve donde le pongo como opciones 7 200 o 300 árboles para un bosque obviamente era lógico que pudiese tardar el tiempo que tardó lo que vamos a ver a continuación es una forma diferente de poder visualizar los resultados de un proceso de glitch ser se ve ya sabemos porque no hablamos la clase pasada que con el gris ser Severo que se busca es un modelo que tenga el mejor score posible y para ello yo lo que hago es darle valores optativos u opcionales de cada uno de los hiper parámetros y que griser se ve los vaya combinando en Pos de obtener el mejor modelo posible con el mejor escort posible es importante destacar que probablemente haya alguna opción que yo no haya elegido supongamos un estigma de 400 o 250 Sí y quiso podría haberme dado mejor score es decir todavía no es la solución definitiva Es una herramienta más Pero sigue dependiendo de mi elección de mi intervención sin mi intervención hace que las variantes que yo le doy quizás las mejores bueno obviamente va a ser lo posible con ellas Así que es importante que tengamos en cuenta eso para que bueno cuando hayamos corrido un proceso de este tipo podamos considerar volver a hacerlo cambiando algunas opciones si es que los scores que hemos obtenido no volviendo al tema nosotros siempre tenemos a partir de lo que vimos la clase pasada que con se obtienen los mejores estimadores pero es importante visualizar otros que no son los mejores sino que quedaron relegados detrás del mejor para tener una visión conjunta de cómo va variando las opciones de los cifras parámetros y el score que se obtiene por eso vamos a armar un pequeño código acá donde vamos a hacer Que vamos a tomar todos los estimadores que me arroja el cb y los voy a poner dentro de una estructura tipo Data frame para que para poder después recorrerla y presentarla tal cual cuando tomamos un conjunto de datos como hicimos en este caso el Iris o con Boston donde lo pasamos después con un Head sus primeros registros bien acabamos de hacer algo similar con lo cual lo primero que voy a hacer es crear un Data frame como Ven aquí lo voy a poner como no Ver resultados y dónde de dónde voy a tomar la información perdón de grid que es el nombre que le he puesto al glitcher se ve y el valor cv- bajo resolución bajo eso me da el detalle completo de todos los elementos que componen ese modelo con el valor digamos dedicada y pre parámetro elegido para ese caso el score y otro tipo de información más que ya vamos a ver a continuación Por ende si yo voy a hacer esto aquí transitoriamente para que puedan ver a qué me refiero con toda la información o con el concepto de toda la información yo voy a poner un Head de el conjunto de datos resultados en Data frame resultados lo ejecuto y van a poder ver que tengo muchísima información relativa en 35 columnas y tengo 35 datos relativos a lo que me arrojó mi proceso de fíjense que también me da los score por cada uno de los splits se acuerdan que dijimos que íbamos a hacer un volvemos aquí arriba un grid se ve con un validation de 10 así con 10 pliegues bien fíjense que me da a mí aquí el score por cada uno de los pliegues o sea es una información muy amplia muy valiosa y que me va a permitir a mí poder hacer un análisis con todo el nivel de detalle que yo quiera bien lo que vamos a hacer aquí justamente es para no tener tanta información que quizás no nos hace falta sino para el caso digamos que estamos visualizando vamos a tomar solamente algunos parámetros y lo que yo voy a poner aquí con filter luego voy a borrar con Drop todas las columnas params y parciales y finalmente voy a sortear o sea voy ordenar toda estas cinco primeras apariciones porque lo que voy a hacer es un Head y finalmente como dije recién hago estoy haciendo la forma de escribir esto aquí esto sólo podría poner como resultados punto filter igual punto drop.org punto G en toda una sola expresión en toda una sola línea como lo quiebro en líneas voy a tener que bueno esa fractura especificarla para que entienda justamente el código que esto es solamente una sola expresión con esta barra inclinada sí bien luego este detalle lo ejecuto y van a ver ahora que no tengo las 35 características que ha visto recién sino que tengo una dos tres cuatro cinco seis siete características que son las que estoy visualizando pero lo importante aquí es lo siguiente fíjense que tengo los score Aquí sí para el conjunto de Test y para el conjunto de entrenamiento la cantidad de estimadores la cantidad de macsamble la cantidad de Max feets la cantidad de profundidades y las opciones de criterio para cada uno de los cinco primeros casos Si fíjense por el número que yo tengo aquí Que obviamente las variantes fueron muchas sino que lo que yo he hecho aquí es pedirle solamente las mejores porque porque las órdenes estos resultados según mi según este esta característica que está aquí fíjense que aparece justamente ordenada primero la más grande y luego a continuación la siguiente obviamente en este caso no hay muchas variantes porque todo dieron Exactamente lo mismo con lo cual es muy rico Este ejemplo porque literalmente Yo podría tomar cualquiera de ellas sí porque todas tienen el mismo score y lo interesante aquí es ver que ese score lo obtuvo fíjense los cinco casos iguales con distintos valores de hiper parámetros y bueno Esto es una información muy importante no es la única vez que la voy a poder obtener puedo repetir a pesar que sea muy largo el grises se ve para obtener otra combinación de valores en Pos de obtener el mejor score Pero bueno creo que valía la pena tomarse un tiempito para mostrarles esta forma de analizar los resultados porque justamente me va a permitir mirar no solamente el primero ignorando que hay otros cuatro en este caso y capaz que hay más porque solamente toman los primeros aquí Que bueno me han dado también muy buenos resultados con otras combinaciones de parámetros para cerrar esta práctica relativa a un ejemplo basado en un problema de clasificación vamos a comparar como dijimos al principio de la clase la situación del score en el caso de un Random Forest respecto de un 3 decision entonces fíjense que en el caso de el árbol tengo un score de 99 y 92 para el conjunto de entrenamiento y para el conjunto de Test respectivamente en el caso de El Random Forest el bosque aleatorio tenemos 99 y 97 que es mejorado luego del grid se ve llegando a 1 y 097 bueno con esto concluimos el caso de un algoritmo relativo perdón a un problema de clasificación y vamos a pasar ahora al caso de un problema de regresión al igual que como tuvimos Y de alguna manera manifestamos hoy el principio de la clase de El ejemplo que yo les puse en el último código que les dejé para que ustedes lo vieran por su cuenta de El árbol de decisión donde también abordamos un problema de algoritmo de regresión y vamos a utilizar como dijimos al principio también al igual que en aquella oportunidad el Boston ccd como conjunto de datos para realizar este modelo o para practicar Este modelo también Para este caso del Random Forest las librerías son las mismas fíjense que bueno Esto es lo mismo que hicimos en el caso del árbol reiteramos la librería básicamente para que quede un registro esto pero estrictamente esto ustedes saben que no es necesario en tanto en cuanto esas librerías tan importadas y yo no haya caducado digamos la conexión con el color ejecutamos este código para importar las librerías en este caso obviamente tenemos un Random Forest regresor es lo único que cambia respecto de las librerías que tenemos al principio que teníamos un Random classippier y importamos el archivo Boston csv vamos a la carpeta Boston Boston y luego una vez que termina esto como siempre lo creamos una variable un Data frame una variable datos y hacemos un Head y vemos el botón que ya conocemos el conjunto de datos que ya conocemos hacemos un shape para cerciorarnos de que existe la cantidad de filas que ya sabemos que tiene la cantidad de columnas y la cantidad de observaciones características 506 y 14 y vamos a preparar los datos para el entrenamiento como hicimos antes con las cinco características que tenía el conjunto de datos Iris donde poníamos las cuatro para el conjunto de predicciones perdón y la quinta como Target en este caso son 14 características como vemos aquí Así que tomamos las 13 primeras para el conjunto de predictores y la última como Target ejecutamos eso y luego separamos conjuntos de entrenamiento y test como ya sabemos vemos Cuántas observaciones han correspondido a cada caso 379 y 127 y creamos nuestro Random poniéndolo en una variable que hemos dado a llamar Ford red y luego hacemos el entrenamiento una vez hecho esto podemos hacer las predicciones Esto no es obligatorio Es simplemente para si alguno quiere ver como ya hemos visto en otras oportunidades ejecutar esto y ver qué valores tiene este array de ipred bueno es una forma de hacerlo concretamente lo que hacemos a continuación sí es medir la precisión lo ejecutamos y obtenemos 95 y 86 95 para el conjunto de entrenamiento 86 para el conjunto de Test es una distancia considerable es un 0.9 0.09 Perdón este y bueno no sería lo ideal sería ideal que el conjunto de Test fuera cercano al detalle o inclusive superior pero lo vamos a comparar con el caso de clase 8 de El árbol de regresión y en aquella oportunidad teníamos 087 066 el problema era mucho peor Aún es decir que hemos mejorado no solamente el valor del conjunto de entrenamiento sino también la distancia que existe entre el score del conjunto de entrenamiento y el conjunto de Test paso seguido vamos a graficar el bosque con la misma lógica que aplicamos antes cuando era el problema de clasificación es decir un Ford que me arroje la información de todos los estimadores Sí y por cada uno de ellos que es un árbol graficar cada uno de los árboles lo ejecutamos bien aquí vemos entonces el gráfico resultante que como ven es bastante complejo Sí porque obviamente al ser un problema de regresión la cantidad de nodos y el contenido de los nodos en cuanto a las decisiones que toma cada o que están registradas en cada uno de ellos es obviamente totalmente diferente a un problema de clasificación la visualización obviamente es muy complicada están muy superpuestos justamente en virtud de la cantidad de nodos que se trata un nodo encima del otro hasta el punto que en algunos casos como aquí lo tapa Pero bueno Esto lo vamos a tener que configurar justamente con el size que le pongamos con el fix size que le pongamos a este a esta estructura de Sub notes Pero bueno Ahí tenemos nuestro gráfico lo que vamos a hacer a continuación es un tema también muy importante que vimos en la clase pasada que es ver la importancia de las características en este caso nosotros tenemos 13 variables de entrada será necesario tener un modelo con 13 variables de entrada habrá Abraham algunas que serán más importante que otras y en ese caso poder tomar solamente las importantes y dejar de lado las que no lo son bueno para esto teníamos un código que lo vamos a volver a ejecutar aquí porque la situación es la misma y tenemos justamente en este caso la información de Cuáles son las características más importantes y sigue siendo RM o rooms cantidad de habitaciones la característica más importante en este caso no vamos a tomar las características más importantes para generar un nuevo modelo y Buscar un modelo con mejor score o más eficiente sino que vamos a tomar solamente una de ellas con la intención de buscar un gráfico para visualizar las cosas también de un modo muy parecido al que utilizamos cuando vimos el primer algoritmo de Machine learning es el algoritmo de regresión lineal Cómo es esto vamos a tomar en principio como una extracción del conjunto de entrenamiento con lo cual voy a tomar solamente del conjunto de entrenamiento que está conformado por 13 características solamente la característica RM lo transformó en un array porque justamente Eso es lo que me va a requerir más adelante el gráfico esto ya lo hemos visto en otros casos cuando yo tengo una sola variable de entrada tengo que transformarla en a través de nampai en un array para que pueda ser graficada y luego obviamente la variable de entrenamiento la pongo en una variable que he llamado itr por y traen Y luego el conjunto de Test en lugar de tomarlo tal cual también fuera compuesto por las 13 características lo voy a circunscribir solamente a este campo sí bien entonces tengo en lugar de tener el viejo y traen y x traen y X3 e3 voy a tener xr y trxts e its lo generamos y con ello creamos un nuevo modelo obviamente ahora una variable de entrada y obviamente siempre la salida con esto lo que vamos a hacer es un scat no sé si se acuerdan que teníamos el scatter que era un gráfico de dispersión de puntos sí Solamente basado en el conjunto de Test con lo cual Este es el conjunto de Test sobre el cual va a ser probado el modelo se acuerdan que en el caso de lineal dibujamos una línea y veíamos si esa línea era haríamos abarcativa de muchos puntos o de pocos y obviamente si nosotros trazáramos una relación lineal aquí imaginemos una línea obviamente pasaría por mucho de los puntos estaría muy cerca de mucho de los puntos pero también muy lejos de muchos de ellos en este caso vamos a hacer lo mismo solamente que no va a ser una recta el dibujo que represente un algoritmo de búsqueda aleatorios sino que va a ser otra figura totalmente diferente más no va a representar una figura geométricamente conocida sino que algo totalmente diferente y para ello voy a escribir este código si x grid va a ser justamente la grilla en la cual voy a dividir ese esa estructura que voy a dibujar de dos coordenadas y le voy a decir que vaya desde el valor mínimo del valor de Test al valor máximo Alba brotes y haga divisiones desde a 0.1 luego voy a hacer un reclade de lo que es la longitud del equilibrio también para estipular la estructura de puntos ideal para dibujar no los puntos que ya lo pude dibujar sino esta figura que va a representar el modelo del Bosque aleatorio finalmente hago el scatter en Blue para dibujar de nuevo los puntos y en rojo voy a dibujar esta figura que ustedes van a poder comprobar Ahora cuando ejecute este código ven esta línea roja totalmente alejada de cualquier figura como decía recién geométricamente conocida representa el formato del modelo de bosques aleatorio para un problema de este tipo o sea estos conjunto de Test que lo estoy probando esta figura fue inspirada en el conjunto de entrenamiento conjunto acotado acuérdense que en este caso solamente está conformado por la cantidad de habitaciones y el valor de la vivienda tal cual conducimos a que el problema de regresión lineal y fíjense lo curioso de la figura que dibuja en base a la lógica de este bosque bueno con esto cerramos la clase de hoy Espero que se haya entendido todo como siempre todos estos recursos van a estar a partir del Campus y estoy atento cualquier consulta que tengan sobre esto y si no nos vemos en la clase número 10 gracias Aquí finaliza la clase número 9 ahora ya tenemos los conceptos básicos de los bosques aleatorios y sabemos también como programarlos e implementarlos los esperamos en la próxima clase