 Titulo: Clase15 (parte2) Curso Inteligencia Artificial 
 URL https://youtu.be/NUlWcTWsfR8  
 1388 segundos de duracion 
 Bienvenidos a la segunda parte de esta clase Los invito a empezar con ella Hola nuevamente seguimos en esta segunda parte de la clase donde vamos a hablar de los dos temas que nos quedaron pendientes de la primer parte la volubilidad de las redes y el manejo de los pesos de cada una de las neuronas de nuestra red neurona la medición de la precisión de una red neuronal no es muy diferente a lo que vimos ya en el Machine learning es decir le voy a dar a esta red neuronal un montón de valores de entrada va a pasar por todas y cada una de las capas y va a dar un resultado final ese resultado final se mide después y se ve que también o qué tan mal puede haber andado con la predicción que hizo solamente que antes le llamábamos Sport a este valor de la mediación de la precisión y ahora le llamamos función de costo según lo bien o mal que nos haya ido con la predicción es que vamos a tener que ajustar los pesos de cada una de las neuronas de nuestra red neuronal para saber Cómo ajustar los pesos y los sesgos calculamos la derivada o gradiente de la función de costo a cada uno de los pesos y sesgos de la red y lo hacemos capa por capa hacia atrás una por una hasta llegar al inicio este proceso es llamado propagación hacia atrás o Bad para ello la explicación es esa solamente que aquí hay dos conceptos que aún vos no manejas el censo de gradiente y va a propagayo dos conceptos que fueron fundamentales en el artículo que se publicó en 1986 y revolucionó el mundo de la Inteligencia artificial vamos a empezar con el concepto de Back propagation como dijimos antes podíamos suponer que estamos controlando a través de una enorme consola de sonido todas las perillas que modifican los pesos de cada una de las neuronas de cada una de las capas de una red neuronal qué nos proponemos tocar Las perillas cambiar los pesos de cada una de las neuronas o de alguna de ellas capa por capa y medir la función de coste para ver cómo nos puede Tenemos que tener presente que cambiar cada uno de los pesos de una neurona no implica un cambio solamente en ella sino que su cambio afecta a todos y cada uno de los caminos que se generan de las múltiples conexiones que tiene esa neurona con el resto como ya dijimos antes pensar en esta solución sería realmente una locura dado que dar de ese modo con la mejor combinación de pesos para que una función de coste arroje los mejores resultados sería francamente una Misión Imposible el sistema de vapor variation propone analizar la función de coste capa por capa y en cada una de ellas analizar diferentes niveles de responsabilidad de las neuronas de esa capa veamos yo puedo tomar una capa y medir no solo la función de coste sino además ver cuál o cuáles fueron las neuronas que mayor incidencia negativa tuvieron en el resultado de la función de coste e implementar cambios en los pesos de ella o de ellas este proceso se repetiría hacia atrás capa por capa hasta llegar a la primera este análisis de determinar Cuánta responsabilidad tiene cada neurona en el resultado final se reconoce como retro propagación de errores y tiene sentido real que se ejecuta hacia atrás ya que en una red neuronal el error de las capas anteriores depende directamente del error de las capas posteriores si por el contrario yo observaba que era una capa una neurona no tiene responsabilidad en la función de coste no tendría sentido cambiar los pesos de esa neurona ni tampoco de todas las conexiones precedentes para entender esta cadena de responsabilidades hacia atrás vamos a suponer un problema de logística o de entrega de productos vamos a suponer que tenemos un cliente que está disconforme porque un producto que compró por internet Le llegó muy tarde vamos a suponer una red neuronal que está compuesta por capas que tienen que ver con distintos tipos de actores que intervienen en esa entrega de ese producto tenemos la capa de los transportistas la capa de los despachanques la capa de los empaquetadores y la capa de los vendedores obviamente ese cliente recibió el paquete de parte de uno de los transportistas con lo cual si ese transportista tuvo culpa en esa demora yo tengo que ajustar el peso de ese transportista y no de los otros transportistas que están en la misma capa de transportistas si por el contrario la culpa es del despachante yo tendré que ajustar los pesos de la neurona de ese despachante que está relacionado con el transportista que entregó ese paquete obviamente este análisis hacia atrás Me permite determinar Dónde está el problema sabiendo que cuando yo corrija el peso de una neurona todas las otras neuronas que están relacionadas con esta también va a mejorar y van a aportar para que la función de coste sea mejor en un sentido genérico vamos a suponer que todos tuvieron algún problema que hizo que esa entrega se demorara demasiado bueno pues entonces habrá que ajustar un poco los pesos de cada una de las neuronas para que de esa forma la función de coste final sea la mejor una vez realizado esto habría que volver a hacer el mismo proceso que hicimos en Machine learn es decir volver a entrenar el modelo volver a probarlo volver a testearlo y volver a medir su función de costes hasta acá está todo muy claro la teoría está Clara pero aún no sabemos cómo vamos a modificar de manera no manual sino automática los pesos de cada una de las neuronas para mejorar la función de coste Bueno ahí aparece el otro concepto importante que mencionamos recién que acompaña el Back propagation que es la función o el algoritmo de descenso de gradiente el método de descenso al gradiente es un algoritmo clave dentro del campo del Machine learning y que se encuentra en el corazón de la gran mayoría de los sistemas de Inteligencia artificial que se desarrollan hoy en día el objetivo con su uso es reducir la diferencia entre resultado obtenido y el que se busca obtener a través de este algoritmo de descenso de gradiente los pesos de la neurona de la red son modificados para que la red logre ese objetivo supongamos un sistema de dos variables una variable de entrada y una variable de salida de la neurona el valor de salida es igual a la función de activación que se aplica sobre la suma ponderada los resultados se pueden visualizar en una función de tipo convexa como esta que está aquí encontrar el valor mínimo en esta figura sería Encontrar el punto donde la derivada es igual a cero empezando el proceso desde cualquier punto determinado automáticamente de manera aleatoria algo así como encontrar el fondo de este Valle una vez que hayamos encontrado eso tendremos el valor del peso en el caso del ejemplo que hemos usado el único peso de nuestra suma ponderada y Listo ya tenemos el peso ideal de esta neurona para que la función de coste sea la mínima la pregunta ahora es como pasamos de ese punto definido manera aleatoria al punto mínimo donde la derivada es cero El Punto de partida es solamente un punto arbitrario para que podamos evaluar el rendimiento desde ese Punto de partida encontraremos la derivada o pendiente y Desde allí podemos usar una recta tangente para observar la inclinación de la pendiente la pendiente va a informar las actualizaciones de los parámetros es decir los pesos y el sesgo la pendiente en El Punto de partida será más pronunciada Pero a medida que se generan nuevos parámetros la pendiente debe reducirse gradualmente hasta alcanzar el punto más bajo de la curva conocido como punto de convergencia es decir el punto donde la derivada es cero para explicar esto de una manera más clara vamos a usar un ejemplo vamos a suponer que estamos en la cima una montaña y que estamos en un día muy nublado el cual nos permite solamente una visibilidad de no más de un metro nosotros queremos llegar rápidamente a la base de la montaña y entendemos que mirando a nuestro alrededor aún con esa visibilidad de un metro vamos a buscar la parte más pronunciada ya que ella seguramente nos va a llevar más rápido a esa base de la montaña esa observación que hemos hecho en nuestro alrededor para intentar Buscar Cuál es la parte más pronunciada es justamente lo que hace el algoritmo de descenso del gradiente yo voy a bajar ese metro en esa parte más pronunciada y cuando esté allí voy a tener nuevamente un metro de visibilidad y voy a repetir el proceso buscando desde ese lugar también la forma más pronunciada de ese modo paso a paso podré ir a partir de la información que me dé la función o algoritmo de descenso de gradiente llegando finalmente a la base de la montaña pero aún nos queda un tema más Cuál es la magnitud de ese avance que yo voy a ir haciendo paso a paso pensemos un poco si avanzamos a grandes pasos puede que la selección de los puntos vaya de un lado a otro de manera tan significativa que llegar al punto mínimo sea algo que nunca ocurra lo más lógico sería hacerlo con pasos muy pequeños para que no corramos ese riesgo pero el problema ahora sería El excesivo tiempo que esto conllevaría y Por ende un alto nivel de gasto computacional este valor es uno de los más importantes parámetros del mundo de Deep learning y se llama tasa de aprendizaje y como vimos es uno de los valores que debemos manipular a la hora de buscar la mayor eficiencia de la red y de su entrenamiento ahora bien con el ejemplo de la función convexa hemos tomado El ejemplo más sencillo ya que la curva resultante podría ser algo como esto en donde tenemos un mínimo global pero también tenemos mínimos locales y ese es uno de los mayores problemas del algoritmo del descenso del gradiente ya que no permite diferenciar un mínimo de otro y Por ende puede estimar pesos entendiendo que un mínimo local es en realidad un mínimo global no obstante ellos seguimos parados en un ejemplo sencillo dado que estamos trabajando por una sola variable de entrada y sabemos bien que en una red neuronal está lejos de trabajar de ese modo sino con un número muy grande de variables de entrada y Por ende con una gráfica n dimensional y no hablamos del valor de un peso sino de un vector unidimensional formado por cada uno de esos Todo queda a manos ahora de nuestra imaginación ya sabemos que lo que podemos graficar solamente puede llegar hasta tres dimensiones con lo cual este mundo en unidimensional siempre lo hemos repetido muchas veces que adentro nuestra imaginación pero les voy a dar una herramienta justamente para que se divierta se entretengan y puedan tratar de cambiando alguno de los valores de los conceptos que hemos visto de aquí tener una representación gráfica de cómo cambia una red neuronal cuando voy tocando esos hay una aplicación que se llama playground de la empresa tensorflow tensorflow es hoy por hoy una de las empresas desarrolladoras de soluciones que más utilizan en el campo del Deep learning en este caso es una aplicación que ahora esta clase va a estar acompañada de una locución que le va a mostrar Cómo manejarla y realmente es muy práctica para empezar a aplicar insisto todos estos conceptos que hemos visto acá bien aquí estamos en esta aplicación playground de tensorflow Aquí vamos a observar primero esto que está aquí arriba donde me dice si quiero abordar un problema de clasificación en regresión vamos a dejar clasificación y tenemos aquí cuatro posibles escenarios de distribución de puntos para resolver distintos tipos de problemas vamos a este que es el más básico y vamos a elegir una función de activación lineal Así que esto prácticamente lo hemos usado porque es muy particular el uso que podemos usar pero fíjense que en este caso como tenemos dos grupos bien diferenciados probablemente una línea sea una forma de clasificación que pueda funcionar bien Así que hago clic aquí y ya veo que ya tengo miren pasaron rápidamente esto debería pasar más lento pero acá hay dos cosas para observar Bueno aquí está la cantidad de épocas si esto va a seguir tanto como yo le di hasta que yo le dé stop digamos no no hay un límite que yo prefijo de cantidad de épocas Aquí ya está en el gráfico estipulada Cuál es la división correcta para una clasificación o sea este modelo lineal Funciona muy bien y fíjense que aquí está la curva de pérdida del conjunto de Test y la curva de pérdida del conjunto entrenamiento bueno esto por ahora Funciona muy bien pero vamos a ver qué pasa Yo cambio el escenario y voy a poner este escenario esto son de puntos es totalmente diferente bueno ejecuto nuevamente y fíjense lo que pasa miren acá Este esta curva ven que hay una que baja y otra que no O sea no es una buena función de pérdida porque porque está teniendo enormes dificultades de encontrar una línea que vivía estos dos conjuntos que deben evidentemente nunca la va a conseguir porque no hay ninguna línea que pueda adaptarse a ese problema Bueno lo paramos con este volvemos todo para atrás con este botón como si fuera una especie de rifles y voy a pasar a la sigmoid se acuerdan la función de activación Sigma y Bueno pero vamos ahora a ver qué pasa fíjense las curvas de pérdida como se van almoldando pero aún así no consigue un modelo paramos volvemos hacia atrás vamos a tan se acuerdan la tangente hiperbólica bueno aquí fíjense que vayan mirando la curva esta yo lo voy deteniendo un poquito para que ustedes puedan ver esto cuando ambas curvas coinciden y tienen ya un movimiento que deja de tener efecto fíjense que ya se deja de mover allí es porque ya definitivamente Considero que este es el modelo ideal para este problema vamos a otro si este que tiene como dos este grupos diferentes como que estuvieron en extremos diferentes de este cuadrado ejecutamos Bueno yo sé que tarda un poco en encontrar la forma ideal aquí la curva no lo va mostrando sí los spots y será el enorme cantidad de pues no Bueno ahí ya parece que no avanza más Y eso es todo lo que puede hacer Qué pasa si voy a reloj que siempre decimos que es la mejor bueno ejecutamos rápidamente a conseguido un modelo Si puedo seguir un poquito más fíjense las curvas de pérdida bueno y ya ahí determinó que este es el modelo Cuál es la estructura de la red bueno fíjense que aquí tenemos dos variables de entrada una capa oculta de cuatro neuronas y una capa de salida de dos neuronas bien Esto lo que viene determinado de ahora justamente lo vamos a cambiar bueno fíjense que aquí me va mostrando en cada neurona como que va abordando un problema diferente acuérdense que las novedades siempre tienen que tener una resolución una función diferente si fueran todos iguales como dijimos antes todo parecería que fuera una sola neurona gráficamente aquí veo que justamente todos los gráficos son diferentes con lo cual a medida que esa neurona aborda una posibilidad de división diferente Cuál es la posibilidad de visión final Bueno aquí tengo en las dos finales esta y esta puedo agregar más capas ocultas Sí con este botón y a cada capa oculta le puedo agregar más neuronas Sí con este botón es el que ahora tengo dos capas ocultas y no solamente una fíjense que los dibujos de las capas ocultas no son iguales a las capas anteriores van resolviendo temas más específicos que tienen que ver con la forma final sí Bueno lo volvemos a ejecutar Bueno ya rápidamente encontró la solución ya ahí ya estamos Casi casi por la forma de la curva de pérdida la situación ideal fíjense los dibujos que hacen estas neuronas y los dibujos que hacen estas otras no resuelve el mismo tipo de gráfica que tiene que ver con la Gráfica final de de que va marcando la separación de un conjunto del otro y eso me da la idea de que como siempre dijimos en la teoría las capas van abordando temas cada vez más complejos de aquí ya lo más complejo sería aquellos que está cercano a la realidad que si esta división con esta forma la primer capa de neuronas No atiende aún la división parecida a lo que sería la final la segunda capa sí Entonces esto quiere decir que las últimas capas que van llegando a la salida se encargan de definir más en fino más precisamente Cuál va a ser la salida final yo aquí los dejo para que ustedes sigan jugando porque acá varias cosas con las que pueden trabajar en principio cambiar clasificación por regresión y me va a dar otros otras distribuciones de puntos y después trabajar con el learning rate es decir con la tasa de aprendizaje fíjense que en algunos casos podría ser esta vamos un caso de clasificación como los que teníamos antes un poco más sencillo bueno Esto va a ir muy lentamente porque el nene right es muy chico entonces va paso a paso a Pequeños pasos avanzando en base a lo que yo estipule como tasa de aprendizaje Aprendiendo a pasos muy pequeños sí bien volvemos le cambio esta tasa por una más grande bueno fíjense la aceleración que va tomando esto lo paro vuelvo vamos en el raid de nuevo vamos bueno fíjense que va resolviendo mucho más rápido bien Ustedes se preguntarán para que voy a elegir la opción más chica si estaba ahí más rápido Sí no se olviden que esto no siempre es así la más chica de alguna manera puede llevarme mucho gasto computacional pero como sé cuál es la ideal como sé que poner una mayor no me va a llevar al otro problema que vimos que ese problema donde justamente lo optimizador va de lado a lado de la curva convexa y nunca llega al punto ideal Bueno ese problema se puede presentar yo elegí ese una tasa muy grande como ésta fíjense lo que pasa no encuentra la solución no la encuentra porque porque justamente pasa esa cuestión gráfica que les decía recién va de un lado al otro de esa curva convexa y no encuentra la optimización de este modelo para que resuelva lo que tiene que resolver vamos a otro supongamos 03 volvemos bueno va más rápido piensa también las formas de la curva es muy interesante analizar eso bueno concretamente es una aplicación muy buena que realmente le pueden sacar mucho provecho para ir imaginando el efecto que tienen cada una cada una de estas cosas que hemos aprendido es una opción que me parece muy muy interesante muy importante bien después de haber hablado largamente de todos estos conceptos a lo largo de estas dos clases y poder haber jugado un poquito con esta aplicación que les mostré recién termina la clase me despido y ya en la próxima clase empezamos a programar hasta la próxima clase aquí termina esta clase los espero en la próxima clase nos vemos