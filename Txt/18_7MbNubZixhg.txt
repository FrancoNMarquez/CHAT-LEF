 Titulo: Clase10 (parte 1) del Curso de Inteligencia Artificial 
 URL https://youtu.be/7MbNubZixhg  
 1843 segundos de duracion 
 Hola bienvenidos Esta es la primera parte de la clase número 10 del curso de Inteligencia artificial de ifes en ella Vamos a hacer un repaso de todos los algoritmos vistos hasta aquí incorporando algunos conceptos nuevos [Música] [Música] [Música] Hola a todos Cómo están esta es la clase número 10 del curso de Inteligencia artificial de ifes seguimos en el módulo de Machine learning y esta clase número 10 la vamos a separar en dos partes en la primer parte vamos a trabajar con una práctica integral donde vamos a repasar dos de los algoritmos que ya hemos visto antes el de regresión lineal y el de regresión logística y vamos a agregar algunas cosas nuevas que van a formar parte de esa práctica pero que también aplican a otros algoritmos como vimos también el de árbol y el de bosques y en la segunda parte de esta clase vamos a hacer un mouse incorporar un tema Mejor dicho que se llama reducción de la dimensionalidad es un tema muy importante que afecta mucho al rendimiento de los modelos y justamente vamos a dedicar toda la segunda parte de esta clase para ver es importante el tema vamos a empezar entonces con la primer parte de ellas que es la parte de la práctica integral bien ya estamos ubicados aquí en el Notebook de la clase 10 y justamente Aquí vemos el título que va a tratar el primer tema que vamos a abordar en él el manejo de Data set con variables categóricas lo vamos a aplicar como dice aquí a un algoritmo de regresión lineal pero este tema puede aquejar a cualquier tipo de algoritmo y a cualquier tipo de intención de construir un buen modelo con ese algoritmo Qué es una variable categórica una variable categórica es una variable que representa una categoría de así su nombre por ejemplo podemos decir el género que puede ser masculino o femenino o por ejemplo el tipo de documento dni o pasaporte bien Eso es un dato que por lo general está representado por un texto y Que obviamente como tal no permite poder construir con esa categoría con ese dato un modelo porque los modelos necesitan datos numéricos por lo tanto lo que tengo que hacer es convertir esa categoría en un valor numérico Y ese es el tema que va a abordar en esta primer parte de esta clase por lo tanto lo primero que vamos a hacer va a ser incorporar como siempre las librerías que vamos a necesitar para desarrollar esta práctica tenemos pandas nampai tenemos línea recreation de sydler train test split de cycle Y tenemos dos librerías que vamos a usar por primera vez porque justamente tienen que ver con el propósito de esta clase es decir make Transformer y One Hot encoder ya vamos a ver para qué sirven cada una de ellas y finalmente warnings es decir que vamos a arrancar ejecutando esta celda para incorporar todas esas librerías bien lo que vamos a hacer ahora es abrir un Data set desde una URL o sea Data set que vamos a tomar como ejemplo lo vamos a estar desde una URL de un kitkap yo les he puesto aquí que Recuerden el cola clase 2-1 Sí aquí lo tengo lo vamos a abrir donde justamente abordamos ese tema estamos hablando de la primer parte de la clase número 2 o sea hace rato que ya trabajamos con este tema de tomar desde github un tengo un conjunto de datos en ese caso bueno aquella oportunidad fue el Titanic csb ahora vamos a hacer lo propio con otro que tiene los siguientes datos tiene digamos la información relativa a las transacciones de un sitio web de tipo de ventas electrónicas con el cual Ese Conjunto de datos tiene los siguientes datos el número de transacción la edad del consumidor el número de ítem en el carro de compras cuántos ítems va comprando esa persona y están en el carro de compras el sueldo mensual del consumidor el tiempo que duró la transacción la cantidad de veces que el cliente compró en ese sitio el género del consumidor aquí ya tenemos una variable categórica justamente el tier de la ciudad que es el tier de la ciudad esto es una base de datos que proviene de la India donde a determinadas de conglomerados ciudadanos digamos urbanos los categorizan con justamente un indicador que se llama y que justamente identifica si es una población más o menos este densa o más o menos importante o desarrollada bien es un dato también categórico que no va a ser justamente para bueno implementar esta idea de pasar una variedad de categórica una variedad numérica y finalmente el valor total de la compra bueno todo eso está justamente en este conjunto de datos que voy a importar aquí que se llama ecomex ccd bien entonces tomamos desde este conjunto de datos de esta dirección perdón de esta URL de itcap y creamos un Data set que le vamos a llamar datos y luego hacemos un Head para reconocerlo como habitualmente hacemos ejecutamos eso y Aquí vemos que tenemos los datos que estamos referenciando recién dispuestos en este ejemplo de los cinco primeros oraciones y vemos concretamente Que justamente género es una variable categórica Y si te Pierre también es una variable categórica con lo cual lo que vamos a hacer como ese título aquí es transformar las variables categóricas en para ello vamos a usar las librerías que importamos hace un rato y de allí vamos a tomar en principio tres elementos make colon Transformer que lo que hace es crear un transformador de columnas es decir va a haber un objeto que va a tener toda la información lo que tiene que ver con el propósito de transformación de columnas por qué transformación de columnas porque justamente estas dos columnas las tengo que transformar de categóricas anométricas bien seguimos One Hot encoder el tipo de transformador que voy a usar para hacer esa transformación porque el tipo porque las transformaciones no son solamente del tipo que vamos a hacer nosotros en esta clase nosotros ya hicimos una transformación cuál fue escalar los datos cuando nosotros hacíamos que los datos dejarán de tener su valor original para hacer o ser transformado justamente en un valor de tipo escalado bueno allí aplicamos un concepto de transformación entonces esa transformación puede ser pueden ser distintos tipos de transformaciones en este caso la que vamos a elegir es aquel lo que hace es convertir una variable categórica en numérica y finalmente es lo que pone En rigor la transformación en este caso o la ejecución de lo que quiero hacer bien Por lo tanto Aquí vemos el código que tiene que ver con toda esta aplicación que vimos recién en principio lo que vamos a hacer vamos a crear un Data frame con solamente las dos columnas que queremos transformar se entiende Es decir DF es un nuevo que proviene de datos pero no de todo datos sí datos acuérdense que este es esto es decir voy a crear un Data frame solamente con la columna gender y citiar sí qué es lo que he puesto aquí datos Y luego lo que voy a hacer es un Drop na porque un Drop na porque presumo presumo que genderick en alguna observación pueden tener valores nulos para asegurarme de que yo no ocurra lo que puedo hacer es un Drop Leal y si me quedo tranquilo digamos de alguna manera de que ese Data frame tiene esas dos columnas y que ninguna de Las observaciones esas dos columnas tiene un valor bien luego lo que hago es crear el transformador lo que hablábamos Recién con que como dijimos con mail colon Transformers le pongo el tipo de transformador que voy a hacer según el tipo de transformación que quiero hacer que es One Hot encoder le pongo los dos y las dos características que quiero que se transformen que en realidad son las únicas porque lo voy a trabajar justamente sobre DF y de F tiene esas dos columnas bien finalmente hago la transformación con fit Transformers sobre DF Insisto que es el Data frame que tiene dos columnas creo sí el Data frame Transformer DF que es Transformer DF es DF transformado sí es decir con DF tengo los datos sin transformar y en transformar de F tengo los datos transformados y hago un Head para ver qué pasa con ello lo ejecutamos Y qué es lo que pasa con eso fíjese Cuál es el efecto que provoca lo que hace es dividir Mejor dicho crear tantas columnas como columna barra tiene cada una de las columnas originales es decir hender tiene dos opciones femenino masculino Entonces qué hace Crea una columna hender femenil y hender made en el caso de tier tiene 1 2 y hay un tercer elemento no lo podemos ver aquí existe si ponemos un Head con más valores lo vamos a ver que son tres elementos tres opciones lo que hace es crear un citier-17-2 Y citier-3 sí bien entonces bajamos para verlo bien y un 3-2-1 es decir que de dos columnas creo 5 porque porque la primer columna tenía dos opciones y la segunda con una tenía tres opciones bien Ahora lo que voy a hacer con este resultado es verificar Cuál es el contenido ya tengo Claro que hizo con los nombres que hizo con las columnas pero qué le pone al dato ya que el dato original no está más bueno lo que hace es ponerle un uno cuando ese dato se corresponde con el título de esa columna y un cero cuando no lo es por ejemplo vamos a la primera observación hender es email con lo cual lo que hacen la transformación es poner un uno en la columna finger en la columna mail lo mismo la segunda pero la tercera se invierte porque porque seguramente ahora voy a la tercera observación y justamente es masculino sí lo mismo hace con el cityer fíjense que el primero es uno y el segundo dos y el tercero es 2 vamos a verlo abajo qué fue lo que hizo bueno justamente lo que hizo es poner un 1 en el tier 1 y un cero entre dos y obviamente en el 3 en el 3 también un cero en el segundo caso en el segundo caso Perdón vimos que tier era 2 fíjense lo que hace por un cero en uno y un 1 en 2 y continúa un cero en tres si en algún caso hubiese sido un tier 3 que va a ser va a poner un cero en la columna 1 un 0 en la columna 2 y 1 en la columna 3 una vez que logramos esto cuál sería el objetivo del Data set que imaginamos queremos tener para empezar a hacer esta práctica Bueno sería este mismo conjunto pero sin la columna hender y sin la columna citier y qué pondría allí pondría justamente el Data frame que Acabo de crear donde hice el one Hot encoder bien así llevamos con lo cual lo primero que tengo que hacer es Drop eliminar las dos columnas de datos Y luego Con este código a conocer poner axis 1 que indica que lo que quiero eliminar son columnas más no filas bien lo ejecutamos y hacemos un columna si habiendo hecho un datos con un valor en tu list para poder ver la cantidad de columnas que me quedaron y cerciorarme que justamente la cantidad de columnas que me quedaron son las que quiero es decir la que veo todas menos la que nos quería tener que hender y sitiar bien luego vamos a crear un nuevo Data frame que lo vamos a poner datos 1 donde vamos a agregar a este conjunto datos que ya no tiene estas dos columnas todas las otras columnas de este Data frame producto del One Hot encoder bien Entonces qué hacemos datos 1 es igual a datos punto join ligar juntar que voy a juntarle a datos transformar DF que era transformar de F era este Data frame que tenía el resultado del coda entonces lo que hago ejecutarlo y nuevamente Crea una variable column names donde lo que hago en este caso similar a lo que hice recién datos 1.colums.vales to list Recuerden que tu list tiene que ver con que esa información me la pase una lista para poder visualizarla y manejarla como corresponde si no es una lista no lo voy a poder hacer porque es un objeto otro tipo y no me serviría bien y finalmente justamente con columnas visualizamos al ejecutarlo como lo hacemos ahora que la cantidad de columnas que tengo en este nuevo Data frame datos es la que quiero las anteriores de datos y las nuevas que he creado luego del One Hot encoder Qué pasa el nombre de estas columnas no es muy amigable y digamos muy largo también para tenerlo presente para referenciarlo y escribirlo con lo cual lo que voy a hacer es justamente datos 1.coms sub 7 sub 8 sub 9 sub 10 y sub 11 que son estas cinco columnas igual a un nombre que en este caso le puse eso podría poner cualquiera que me de alguna manera me represente una forma más amigable de poder este nombrar una columna femenino masculino si te quiero uno dos y tres y luego a un Head para ver constatar de que justamente he logrado el Data set que yo quería con las columnas pasadas según quoten cover de categóricas a numéricas Y a partir de ahora poder empezar a trabajar mi algoritmo de regresión lineal bien lo primero que vamos a hacer para este algoritmo es dividir la x y la y aquí justamente como esto es una clase de repaso Por decirlo de alguna manera o integradora de conocimiento ya vistos dejo esta pregunta por qué necesitamos dividir las variables de entrada y de salida en X e Y bien la respuesta es porque necesito tener separadas las variables de entrada y las variables de salida u objetivo para después pasar a dividir los datos en conjunto de entrenamiento y test en este caso no voy a tomar todas las variables de entrada para formar la x Solamente voy a tomar algunas el sueldo la hora de transacción el género ahora que tengo separado femenino y masculino y los tres las tres columnas que quiere recién de citiar y la variable de salida Obviamente el total gastado bien hacemos este paso creando la x y la y luego hacemos lo que dijimos recién la separación de los datos en conjunto de entrenamiento y una vez que tengo eso pasamos a crear el modelo como ya lo sabemos hacer y vamos a verificar la precisión que como dice aquí el título es pésima porque realmente es extremadamente baja con lo cual lo que vamos a hacer para intentar mejorarla es agregar una característica más Al conjunto de entrada la característica que vamos a agregar es como ese título aquí la característica récord que es el columns número 5 fíjense que aquí yo tenía 4 y 7 y ahora agregó la columna 5 con esto voy a recrear la variable x no lo voy a hacer con la variable y porque en ese caso no cambia nada sigue siendo el mismo la misma variable Target y lo que voy a hacer va a hacer volver a separar el conjunto de tres entrenamiento volver a crear el modelo volver a entrenarlo y medir su score lo hago y veo que bueno el score crece considerablemente 91 91 cuando tenía 0 19 y 017 pero voy a intentar seguir en la misma idea el mismo procedimiento agregando una nueva característica y lo voy a hacer con la característica age que es la columna es número 1 fíjense que aquí tenía 3 4 5 ahora tengo 1 3 4 5 Sí y hago Exactamente lo mismo solamente que vuelvo a recrear la variable x los otros pasos son los mismos que hice recién intentando ver qué pasa ahora con la precisión y veo que la precisión en realidad ha mejorado sobre todo en el conjunto de Test lo cual no es malo ahora luego de esto les acerco a la siguiente pregunta qué conclusiones podemos sacar respecto de toda esta estrategia que hicimos de agregar una característica más para mejorar como vimos mejoramos mucho el score y agregar una nueva característica a la ya agregada en el caso anterior para obtener una mejora en score pero no tan significativa la conclusión sería que si bien hay una mejora que la vemos fundamentalmente en el conjunto de Test la diferencia no es tan grande la mejora no es tan grande y quizás el hecho de agregar una nueva característica implicaría un gasto computacional muy grande que no ameritaría justamente ese esfuerzo para poder lograr ese pequeña o esa pequeña diferencia de score la segunda conclusión que podemos sacar Es que así como el hecho de agregar nuevas características es una forma de mejorar el modelo también puede serlo quitar características Nosotros hemos visto en clases anteriores en las prácticas que hemos hecho que podemos determinar la importancia de las características a la hora de definir un modelo con lo cual los invito a que en este caso pensemos si quizás alguna de las características que están podemos quitarlas en Pos de mejorar el modelo justamente midiendo la importancia de los predictores Es decir de la variable de entrada con esto Terminamos el ejercicio a partir del cual abordamos qué tema el tema de la transformación de las variables categóricas en numéricas lo que vamos a hacer a continuación es otro ejercicio no con un algoritmo de reelección lineal sino con un algoritmo de revisión logística buscando que lo que dice aquí en el título ver una salida en formato probabilístico ya vamos a entender a qué nos referimos Recuerden que el algoritmo de revisión logística lo que hacía era darme un valor o en un formato binario o un formato de clases es decir blanco negro 01 alguien que tiene una enfermedad o no la tiene y lo otro que tenía que ver con determinadas características que podían calificarse en tres o más variantes pero siempre en una cantidad finita no una cantidad infinita entonces lo que vamos a ver ahora es cómo analizar esa salida de una manera probabilística y no de una manera concreta es decir no por su valor concreto sino por la probabilidad de que ese valor sea una de las clases que está definida en las opciones de salida bien para eso vamos a adelantar mucho el tema pero vamos a empezar por ver como siempre las librerías que vamos a usar para este caso para este ejemplo que son las que están aquí donde vamos a volver al escalamiento de datos Y luego las que ya usamos en cualquier ejercicio vinculado a un problema de radiación logística Así que las incorporamos rápidamente y vamos a utilizar para este caso un Data set que ya usamos que es el de Iris con lo cual lo cargamos collamos este lo hemos hecho anteriormente bien ya está así cargado creamos un Data frame de nombre Iris y acá lo tenemos ya este lo conocemos y el visualizar este Data frame de alguna manera no recuerda tenemos el shape luego la separación de la x y la y que recién preguntamos porque lo hacíamos bien volvemos a hacerlo aquí obviamente donde ponemos en el caso de la x todas las variables de entrada y en el caso de la variable Target que en este caso es la especie de la flor bien y ahora vamos a escalar los datos Perdón no hice la separación de conjunto de tres entrenamientos Ahora sí bien decía vamos a escalar los datos Y aquí nuevamente aprovechamos este repaso para poner una pregunta por qué escalamos los datos Y esto es importante hacerlo bien respuestas en principio Por qué escalamos los datos los datos los escaladamos en principio porque lo que tratamos que debitar digamos con el escaneamiento de datos es que un valor de entrada una característica de entrada pueda ser más importante y más significativa solamente por el tamaño de su cifra no por su importancia a la hora de determinar en este caso si la especie setosa u otra sino porque tiene un número muy grande desde la expresión desde la cifra respecto de otros aquí obviamente el largo del sépalo y el ancho del sépalo tienen una una cifra más grande que en su mayoría de los casos de el largo del Pétalo y el ancho del pétalo la diferencia en este caso no parece ser tan significativa digamos que este problema se agudizaría si por ejemplo una columna de estas tuviese Bueno cuando todos tienen una expresión con una sola cifra que tuviesen expresiones con tres cuatro ciclos y o que tuviese un valor decimal muy pequeño Entonces en este caso Este no es tan grande pero igual vamos a escalar los datos Y es importante en este caso bueno justamente la respuesta está en lo que dijimos en este caso concreto no sería tan importante escalarlo vamos a hacer Igual para repasar pero sí es importante que entiendan de que esto es mucho más importante en la medida que justamente la diferencia del tamaño de la cifra sea muy grande entre una característica de entrada y otra así que bueno escalamos los datos de la forma que ya lo habíamos hecho Recuerden que en el caso de x-30 hago fit y en el caso este no hago fit porque porque justamente x-train son los datos que yo voy a usar para entrenar por eso es transform en el caso de Test simplemente es para comparar para evaluar con lo cual lo voy a hacer sin bien creo el modelo de regresión logística como ya sabemos y medimos la precisión bueno vemos que la precisión es de 0.96 Y 093 sí esto recuerden siempre que puede variar porque porque si yo vuelvo a hacer esto que es justamente generar el separar este los datos en módulo de entrenamiento y en conjunto de entrenamiento conjunto de Test puede hacer que este valor cambie De hecho si en este caso particular lo volviese hacer probablemente pasar a eso tenemos 0 96 0 93 lo ejecutamos nuevamente ven que cambia Sí bueno obviamente esto es parte del entrenamiento por eso es importante que aquí no lo he puesto el Random State las semillas para que me fije esa separación de conjunto de datos y entrenamiento como algo que fue la manera de distribuir que me dio el score más alto bien Ahora vamos a hacer las predicciones para el conjunto de Test esto ya lo habíamos hecho es decir con el modelo predigo todo el contenido del conjunto de Test y pongo las predicciones en resultados son los siguientes Es decir para el primer caso determinó que la predicción según el primer la primera observación del conjunto de Test debe ser versicolor la segunda virginica la segunda la tercera setosa etcétera etcétera sí Ahora qué pasa esto es un dato concreto es un resultado concreto Pero la realidad el algoritmo de la región logística no maneja las cosas de ese modo si nosotros recurrimos a este slide que fue parte de lo que nosotros vimos en la introducción teórica del algoritmo de reacción logística habíamos hablado de que en realidad esto que atienda un problema de ceros y unos como dos posibles salidas de un problema de reacción logística no son todos los valores o cero o uno sino que están ubicados en una función que se llama de tipo sigmoide y sobre esa curva hay valores que están más cerca del uno como hay valores que están más cerca de cero con lo cual estos cuatro valores azules no son 0 concretamente cero ni tampoco estos tres valores verdes son completamente uno sino que son probabilísticamente cero o probabilísticamente uno porque como vemos en este gráfico este cuarto valor azul que corresponde un 0 es el valor que tiene la menor probabilidad de ser un cero pero aún así su probabilidad es mayor de que sea un cero de que sea un 1 lo mismo con este valor verde es el que tiene la menor probabilidad de ser uno pero aún así Esa menor probabilidad lo acerca más al uno que al ser con lo cual por la probabilidad de ser es que el valor se lo asocia a una salida o a otra al 1 o al 0 Entonces eso es lo que nosotros vamos a tratar de ver para este caso de este conjunto de Test que hemos visto recién que tiene definiciones concretas pero están asociadas a definiciones probabilísticas cómo lo logro el lugar de usar model predict o sea el nombre del modelo login model predict voy a usar el método predict guión bajo proa ven que es muy similar la expresión solamente que en lugar de usar predique uso predic pro con lo cual lo voy a ejecutar y fíjese lo que me arroja me arroja una probabilidad para cada observación para cada una de las variantes es decir estos tres elementos es la probabilidad que tiene la primera observación de ser o una cosa o la otra o la otra o una cetosa o una versicolor o una virginica en este caso fíjense que el primer caso fue una versicolor Y por qué determinó que era una versicolor porque justamente el segundo elemento 8.8 elevado a la menos 10 es el valor que tiene la mayor probabilidad respecto de los otros dos es decir este elemento de aquí y este tienen una probabilidad menor de ser un acetosa una virginica que esta probabilidad de ser un versículo por eso dice esta primera observación de las tres probabilidades Cuál es la más alta la que corresponde versículo Entonces el resultado es que la salida es una versicolor en el caso de la virginica lo mismo la virginica es la tercera fíjense la segunda observación en este caso el valor más alto de probabilidad lo tiene la tercera columna es decir la de química entonces determina que por esa alta probabilidad el resultado final es virginica de esta manera funciona del modo probabilístico el resultado que determina de manera concreta como aquí con predique un algoritmo de reacción logística esto es muy importante que lo entendamos Por qué Porque a futuro vamos a empezar a trabajar con esto cuando nos incorporemos a las redes neuronales para terminar este ejemplo si esta práctica vamos a les dejo aquí un código para ver este resultado lo que hablamos recién de una manera un poquito más clara más transparente y justamente lo que hago es un ciclo for que cicle Tantas veces como elementos tenga el conjunto de Test sí es decir aquí veo que el conjunto de Test recordamos que tenía 30 elementos era 150 Las observaciones que tenía el Data set y así tomaba el 20% eran 30 que son las 30 que están aquí y son las 30 que están aquí de manera probabilística aquí de manera concreta Aquí bien Entonces qué voy a hacer con cada ciclo de Ford lo que voy a hacer en principio es imprimir por 100 y redondear cada uno de estos valores Sí para que en lugar de verse expresados así se vean expresado con un número más fácil de visualizar entonces este este y este en el primer ciclo lo voy a multiplicar para ver para verlo de esta manera lo mismo con la segunda observación lo mismo con la tercera con cada una de las 30 luego de hacer esto con np round y multiplicado por 100 lo que voy a hacer es imprimir un texto donde diga que la predicción determinada como en este caso su y que es ipred Recuerden que era esto de aquí y luego en la probabilidad lo que me va a mostrar a mí es la probabilidad de que sea lo primero la probabilidad de que sea lo segundo la probabilidad de que sea la tercero Qué es en este caso es virginica virginica era la tercera Bueno es lo que veo aquí 005 374 86 22 los tres suman un 100% de probabilidad Cuál es la probabilidad más alta la tercera Entonces el resultado en la tercera en versicolor lo mismo 9 09 84 26 y 655 cuál es la probabilidad más alta la de la segunda alternativa que es color aquí versicolor virginica de nuevo en la última verse color la segunda versículo aquí tenemos 12 tosas que la primera Bueno ahí se ve mucho más claramente esta cuestión de cómo determina en base a la probabilidad más alta Cuál es la clase de elegir bien hasta aquí llegamos a esta primera parte de esta clase vamos a vernos ahora en la segunda parte de la clase número 10 hasta aquí llegamos con esta primera parte te invito a seguir practicando e incorporando conceptos nuevos en la segunda parte