 Titulo: Clase 13 (parte1) Curso Inteligencia Artificial 
 URL https://youtu.be/NDor8fLB2fg  
 1900 segundos de duracion 
 Hola bienvenidos Esta es la clase número 13 del curso de ia y última clase del módulo de Machine learning en ella Vamos a analizar proyectos publicados en sitios web de esta forma nos vamos a preparar mejor para la evaluación final de este módulo vamos por ello    Hola a todos Bienvenidos a la décimo tercer clase de este curso de Inteligencia artificial de ifes y última clase del módulo de Machine learning en esta clase no vamos a ver algún contenido nuevo algún conocimiento nuevo sino que vamos a reforzar los conocimientos adquiridos aquí fundamentalmente en este módulo de Machine learn para ello lo que vamos a buscar es investigar o inmiscuirnos en el mundo de los proyectos que ya han sido desarrollados y publicados con algunos de los algoritmos que nosotros aprendimos En ese sentido en esta clase vamos a trabajar con esa idea yendo a algunos sitios que justamente son los que publican este tipo de proyectos para tomar uno de ellos y paso a paso seguir un proceso de cómo hacerlo de esa información y cómo traerlas a nuestro entorno para poder ejecutar la practicarlas y aprender un poco más de esto así que sin más que agregar empezamos con la clase bueno como decíamos al principio de la clase entonces aquí lo que vamos a tratar de hacer es ir indagando una información que vamos a tomar de uno de los sitios que mencionamos al principio y ir haciéndolo paso a paso como si estuviéramos juntos digamos no para ir recorriendo esta experiencia de un modo más real al que les pasaría a ustedes si lo hiciesen por su cuenta en el caso de esto que vamos a hacer vamos a buscar un algoritmo o información del ejemplo que tenga que ver con Random Forest con bosques aleatorios y aquí tenemos Bueno lo que mencionábamos hoy el sitio cabe y el sitio harring Face lo estoy poniendo a título de ejemplo tenemos presente que información para estudiar y bueno o Fuentes para para estudiar en muchas podemos recurrir a libros podemos recurrir a publicaciones que están en otro sitio web los que se llaman regularmente papers que son publicaciones de investigaciones que hacen muchos este muchas personas que gracias a Dios publican sus cosas en sitios públicos también podemos recurrir a bueno las fuentes como videos hay mucha información en vídeos de YouTube en canales de YouTube exclusivos este que se dedican digamos a este tipo de temática y bueno un conjunto de herramientas que siempre están disponibles para nosotros los voy a olvidar de eso que es muy importante que vamos a usar un poco algo eso aquí Bueno son infinitas y desde dos muy variadas las fuentes de información solo aquí nos vamos a centrar básicamente en estos dos sitios web puntualmente en cable pero vamos a recorrer un poco estos sitios aquí tenemos cable y bueno como verán Aquí estoy logueado con mi nombre y vemos que tenemos bueno algunos secciones digamos del sitio donde la primera es competiciones que es un poco la filosofía de Call porque propone bueno temas a desarrollar o temáticas a bordar con premios y bueno elige los mejores proyectos vinculados al tema que propuso como como elemento de competición después tenemos obviamente Data set que podemos recurrir y bajar entonces que pueden estar vinculados a un proyecto o no modelos código de discusión si vamos a Face También tenemos modelos Data set documentos bueno espacio de discusión etcétera etcétera En realidad lo que vamos a hacer aquí a título de muestra vamos a tratar de buscar información vinculada a Random Forest Sí porque justamente el tema que voy a proponer para esta clase y bueno como verán aquí cuando yo pongo en el buscador la palabra me aparece un montón de cuestiones vinculadas a ese tema notebooks en otros casos discusiones bueno en otros casos aparecerán solamente el conjunto de datos vinculados a un proyecto y no el proyecto en sí mismo en otro caso pueden aparecer más del Notebook una explicación muy pormenorizada y detallada de Por qué la persona que escribe ese Notebook y trabaja sobre ese tema ha hecho lo que ha hecho paso a paso como si fuese una clase bueno Y también tienen Este no es menor el tema de cursos es importante que hay pequeñas a sus cursos que también está subidos a estos sitios bien si voy hago lo mismo también pongo Random Forest insisto el tema que vamos a elegir nosotros pueden poner cualquier cosa y Bueno aquí tenemos en principio bueno proyecto Pero bueno pues este que sean muchos más si voy a modes también tengo bueno ya rubro digamos del tipo de cosas que quiero ver y no con el buscador obviamente encarguen lo mismo Bueno este todas esas cuestiones es lo que ustedes tienen como herramientas para ir buscando y van a encontrar proyectos que tienen que ver con el interés que ustedes buscan la temática que abordan es la que ustedes les interesa o por ahí no están buscando nada y les aparece un tema y le parece interesante y bueno van a encontrar proyectos muy complejos por ahí con algunas herramientas que ustedes no manejan bueno bienvenido que puedan investigar nuevas herramientas y bueno en otros casos va a ser simplemente el código sin mucha aplicación en este caso nosotros vamos a trabajar sobre algo que encontré que me pareció muy interesante que es un algoritmo de Random Forest para predecir la posibilidad de que una persona pueda tener una cardiopatía en virtud de la serie de parámetros que bueno tienen o forman parte de un conjunto de datos sobre lo cual trabaja la base de este ejemplo Este ejemplo que tenemos aquí trabaja por Random Forest y también con un algoritmo de regresión logística que también vamos a ver la idea aquí es poder empezar a trabajar con este código llevándolo a un colap nuestro a un nuestro e ir copiando y pegando cada una de las partes esto muchas veces no es necesario porque muchas de estas publicaciones tienen un gift Card con lo cual yo puedo bajar el github o clonarlo y ya tengo todo mi máquina sin tener que estar copiando y pegando Lo que pasa que en principio no vamos a tomar como dije antes todo el código de este ejemplo sino parte con lo cual eso va a ser que vayamos de a poco pero también vamos a ir copiando y pegando como una fase de ir aprendiendo paso a paso algunas cuestiones importantes que tienen que ver con ir viendo cada una de las cosas que componen este proyecto sino también Ver algunos truquitos que tienen que ver con el día a día del trabajo en cola Sí en Notebook que no por menores son no es importante digamos abordarlos y tenerlos presentes si es parte de la práctica diaria y es una forma también de aprender esas pequeñas cosas que nos facilitan el trabajo en su sin mucho más que agregar a todo esto que hemos dicho vamos a empezar con la práctica concretamente como decíamos recién si vamos aquí a este menú de los tres puntos puedo ver que puedo abrir este documento este código de este documento en Google notebooks es decir con Google o bien Download es bajar todo este código a mi disco también tengo la sección vamos a cerrar aquí la acción input en la cual puedo acceder a un conjunto de datos que es el que vamos a usar en esta práctica pero vamos a hacer una suposición para poder aprender algo más y trabajar un poquito más con github que tantas veces lo hemos mencionado y vamos a suponer que ese conjunto de datos no lo tenemos accesible con lo cual lo que yo voy a hacer va a ser Tomar nota bien del nombre de ese conjunto de datos que se esté que está aquí y lo vamos a ir a buscar a Google aquí y lo buscamos y vamos a buscar a un github aquí Tenemos uno que pueda tenerlo entonces entro este veo que aquí está el csv me meto en él y acá me ofrece una View se acuerdan que esto lo mencioné muchas veces especialmente en la en varias prácticas Digamos si desde las primeras este las primeras clases de análisis de datos donde yo podía abrir un conjunto de datos a través de una URL que me ofrecía github que empezaba con estaba en formato r aw bien Vamos a hacer aquí clic en este que me ofrecen y voy a ver que aparecen los datos en el formato que habitualmente conocemos como csv Esto me da dos opciones primero yo puedo copiar esta URL que es lo que vamos a hacer Sí vamos a copiar esta y la vamos a abrir desde el cola que vamos a fabricar o bien Yo podría pararme aquí con el botón derecho y darle guardar como y guardarlo en la parte que yo necesite de mi disco si lo que me aparece por el nombre que yo quiera poner y la extensión SD bien no vamos a hacer eso vamos a copiar esto que está aquí y no lo vamos a llevar al Notebook en el cual vamos a trabajar toda esta práctica si por el momento lo voy a copiar acá sin mucho más y vamos a en principio antes que esto ver todo el tema de las librerías que vamos a necesitar para esta práctica con lo cual voy a abrir una celda nuevamente pero la quiero poner arriba con lo cual como está abajo hago clic en la flecha y la pasó arriba me voy al cable y vamos a tomar las dos primeras librerías que son nampai y pandas y también tengo más abajo estas otras librerías y me la llevo también al cola bien este mapa lo vamos a sacar por ahora y ahí tenemos las librerías que vamos a usar para este proyecto le vamos a quitar estos comentarios de aquí que no me hacen falta Y tenemos dos libres nuevas que ya la vamos a Bueno a comentar más adelante Así que empiezo por importar libres y ahora tendría que importar este este conjunto de datos con el formato de URL que tiene pandas Así que vamos por eso ahí tenemos entonces la URL puesta en una variable que se llama URL y abrimos un Data frame con los datos de esa URL y le ponemos tarjeta s bien acto Seguido lo que me sugiere es hacer un Head Así que vamos con eso lo tomamos de aquí y lo pegamos y ahí tenemos ven los mismos datos que tenemos aquí obviamente esta línea la he salteado porque esta línea considera que yo tengo el conjunto de datos en el disco y lo levanta porque he usado la forma de la este URL con el formato bien Ahora tengo la misma situación habiendo tomado los datos de un lado de otra manera de una manera o de otra Perdón este tengo ya los datos en mi colap a partir de haberlos podido ver con el gel Así que pasamos a la siguiente instrucción que es un shape para ver justamente si la cantidad de observaciones y de características es la que corresponde Así que ahí tenemos 319.795 y 18 características voy al cable y efectivamente tengo eso tengo también aquí un título Sí así que vamos a también copiar los títulos de acá con lo cual voy a tomar esto lo pinto lo copio y me lo llevo a mi cola tengo que ponerlo en una celda de tipo texto no una celda de tipo código Entonces lo pongo aquí lo voy a poner en negrita con lo cual lo pinto y hago clic aquí y lo voy a poner en con un tamaño que se puede regular del siguiente modo yo pongo tres numerales eso me da un tamaño chico con dos uno mayor y con uno uno más grande que todas las opciones anteriores con la lógica que esto implica así que bueno ya tengo aquí mi título pero lo quiero poner arriba como está Sí en el cable arriba del shape Así que lo que hago nuevamente es usar la flecha y lo paso sí bien a continuación nos vamos a Carl y lo que hago ahora es Buscar a través del método info justamente información de las características de cada una de justamente las características que tiene este Data frames Así que lo copio lo pego agregó una celda más de código y lo ejecuto y tengo la información donde veo que muy pocos datos son de tipo numéricos sí BM y fiscal gel mental healthday el resto son de tipo objeto mayoritariamente son datos categóricos sí es decir que son datos que deberíamos transformar Si queremos usar esa característica para nuestro modelo a continuación vemos que lo que propone es trabajar con la categorización de los grupos de edades de qué se trata esto Bueno vamos un poquito más arriba y vemos Que justamente está la característica categoría de edad que está descrito de modo muy particular con rangos de edades y aquí el autor de esta publicación propone reemplazar eso por textos que digan joven adulto viejo o muy viejo entonces a través de cada una de estas instrucciones dice que reemplace esos rangos por cada una de estas correspondencias de tipo texto sí es decir que Entonces vamos a aplicar eso vamos a ir aquí a copiar este texto como venimos haciendo lo pegamos en el cola agregando un elemento de tipo texto sí como siempre lo ponemos en Evita y le ponemos tres signos numerales y ahora vamos el código lo pegamos aquí Y de paso también pegamos el distrite que me muestra a continuación hecho esto hacemos las dos acciones ahí la primera ahí la segunda y con el display puedo ver lo que vimos en las clases pasadas una descripción completa de las características de tipo numérica donde vemos la cantidad al promedio a la desviación estándar el mínimo el máximo y los percentiles 25 50 y 75 que me propone ahora el autor bien ver si hay valores nulos si esto ya hemos visto mucho así que tomamos el título lo llevamos al colar agregamos un texto bien vemos los valores nulos y no hay ninguna característica que tenga valores nulos bien Vamos al cable que lo quisiera a continuación verse duplicados esto es importante porque muchas veces la información duplicada se considera redundante y Por ende se puede eliminar concretamente aquí el autor lo que hace es eso proponer eliminar los registros duplicados así que vamos con el código lo ponemos lo ejecutamos Y tenemos la información de que de la totalidad de observaciones Perdón que tiene este conjunto de datos que dijimos es 319.795 hay 35.830 registros duplicados con lo cual lo que propone aquí el autor es eliminar esos duplicados Así que lo que vamos a hacer Bueno lo hacemos con esta instrucción que es Drop duplicate y la ejecutamos bien lo que deberíamos haber ahora y que acá el autor no propone pero yo sí Les propongo hacerlo es ver cuántos registros quedaron dado que eliminé los duplicados Así que vamos a volver a hacer un shape y ahora vemos que ya no hay más la cifra anterior que repito 319.195 sino que ahora habiéndole restado el duplicados me quedaron 283.965 observaciones veamos que propone el autor a continuación la visualización de la distribución de datos esto es muy común y es muy importante para ver cómo están distribuidos y para eso vamos a recurrir a una herramienta gráfica donde nos va a mostrar justamente si los distintos valores que tienen cada una de las características Están bien distribuidos están más concentrados en un valor respecto de otro bien copiamos el título primero y luego el código como venimos haciendo hasta ahora bien acá tengo entonces la variable categórica fixtures que lo que hace es justamente tomar del Data frame de effect todos los tipos de variables de entrada sí de características que son de tipo objeto Por ende de tipo categórica luego marco Cuál es el formato el tamaño el size del gráfico que voy a hacer y finalmente el Ford en el cual voy a poner de categórica al features primero la i que va a ser lo que me va a permitir usar como una variable que va a indicar cada uno de los ciclos empezando de Cero en adelante y luego con feature tomar los nombres de cada una de las características ahora categórica al feto tiene un montón de elementos que son los nombres de cada una de las variables de entrada tipo categórica enumerate lo que hace es enumerar justamente la cantidad de elementos que están dentro de esa variable y Por ende esa cantidad de elementos es lo que me va a dar la referencia para que está ahí vaya Sabiendo desde cero hasta Qué valor tiene que asignar luego hago el suplots y luego uso aquí sns que si vamos arriba recordemos que es una de las librerías es sibon alias que importamos al principio y que justamente sirve como patrollip para hacer gráficos el resto de las referencias que tiene que ver con el resto del código se la dejo aquí impresa en la pantalla para poder seguir rápidamente con la ejecución de esto y Ver el resultado como vemos aquí tenemos para cada una de las variables categóricas los valores posibles en este caso por ejemplo no Y sí y la cantidad de elementos no Y la cantidad de elementos sí Ahora voy por ejemplo con fumador sí o no veo que tengo cuántos son fumadores y cuántos no son fumadores aquí si la persona es bebedor o no tengo no y tengo sí vamos a tomar estos dos casos por ejemplo en el caso de los fumadores está bastante proporcionada la cantidad de las personas que fuman y no fuman en el caso de los alcohólicos son mucho más significativos los No que los sí En el caso de vamos a tomar otra característica es un poquito más abiertas sí bien en este caso de la edad se acuerdan se irá viejo muy viejo adulto joven fíjense que está distribuida de una manera en la cual obviamente entre el viejo y el joven hay una diferencia bastante importante en el caso del sexo el género sí está Igualmente distribuido igual esto lo podemos analizar para cada uno de los casos para entender la posible influencia que puede tener en cada una de las de los modelos que vamos a desarrollar a continuación bueno la variedad de tipos de datos en el caso de las variables categóricas de sí o no o si son más variantes en cada uno de los casos como aquí también tenemos bueno bueno muy bueno pobre excelente bueno Esto es un elemento muy común para poder analizar los datos antes de empezar a desarrollar el modelo ahora vamos a hacer lo mismo pero para las variables no categóricas que es lo que propone el autor a continuación ver lo mismo pero para las numeric fitos si no para las categóricas fitos Así que también copiamos este código que tiene una lógica exactamente similar a la de recién solamente que el gráfico es de otro tipo así que vamos a agregar el código aquí no pegamos lo ejecutamos en el caso anterior el gráfico era de tipo count plot en este caso es de tipo East lot estos son los famosos histogramas que ya hablamos alguna vez y fíjense que bueno puedo ver si los datos están muy concentrados o guardan este dibujo que dijimos que en la forma de la distribución normal o sea la forma acampanada bueno en el caso bmmi tiene una distribución de este tipo en los otros restantes casos está muy concentrado respecto de los valores mínimos sí en este de cuánto tiempo duerme este bueno está como con un gráfico bastante raro no con algunas puntas muy marcadas pero un poquito más distribución ahora el autor nos propone ver el ratio de bueno gente que tuvo problema de corazón entonces este tomamos el título lo llevamos a nuestro cola como venimos haciendo subimos y vamos a traernos el código que tiene que ver con un gráfico de tipo país ese de tipo torta Sí entonces típico gráfico de torta muy conocido y podemos ver cuántas personas han tenido problemas de corazón Eso Perdón 9,54% Cuántas no la han tenido que es el 90.46% . bien volvemos al cable y ahora lo que tenemos que hacer es el Level coding de qué se trata esto esto ya lo vimos no de esta manera llamado o ni la de la forma que lo vamos a hacer En parte sí en parte no tanto pero tiene que ver con la transformación de las variables categóricas en No categóricas ya hicimos el análisis de todos los valores los categóricos no categóricos el ratio de la variable en este caso Target objeto que es si la persona tiene o no una cardiopatía y en este caso vamos a utilizar primero vamos a hacernos el título Antes que nada Ahora sí vamos a traer la librería de processing Never vamos más abajo Acá hay mucho comentado por lo tanto obviamente no vamos a tomar eso esta línea que crea la variable l de tipo Level encoder justamente y ahora sí el resto del código que es lo que hace bueno obviamente lo que hace es generar un Ford para que cicle Tantas veces como variables categóricas existen sí bien acá Bueno este código es el que justamente me dice en la variable categoría de calcos cuáles son las variables de tipo categórica lo que va a hacer aquí es definir si el unic de esa columna supongamos en el caso de tomar la primera columna mido la dimensión del Unique es decir cuántos valores únicos o diferentes tiene esa característica si esa característica tiene menor o igual a 2 quiere decir que es de tipo binaria como acá dice la el comentario Sí con lo cual yo voy a transformar eso en un cero o en uno depende Si es una opción u otra y en el caso que las opciones sean más de dos o sea que no sea de tipo binario que vamos a aplicar vamos a aplicar un wat hot encoder pero no justamente la librería que se llamaba Así que usamos otras veces sino que este esta librería que se llama get dames que hace un proceso muy parecido al que hicimos pero bien es otra herramienta que eligió aquí el autor en lugar del que usamos nosotros y luego hacemos un Head para ver el resultado lo ejecutamos bueno y aquí vemos el resultado obviamente vamos a tomar un caso de una variable que tenía dos valores posibles Por ejemplo si era fumador no tenemos sí y no vamos a ver si lo encontramos aquí fumador acá tiene uno y cero uno y cero uno sí tenemos otros casos donde tenía más de dos valores posibles por ejemplo este que está aquí en hertz vamos a buscarlo bueno Y aquí tenemos el proceso similar a lo que nosotros habíamos logrado con el water que es en el caso de gengels excelente justo bueno pobre y muy bueno y hace el mismo trabajo acá son cinco valores posibles el primer la primera observación es muy bueno con lo cual tiene uno es muy bueno y cero en nosotros cuatro restantes Sí vamos al caso del tercero por ejemplo es justo tiene uno el justo y cero cero cero sí Ese es la misma mecánica solamente de acá uso se ve aquí arriba get damise y no el método What holtencoder Más allá de que el nombre que le usa para identificar es justamente porque ese es el nombre del proceso después hay método de llama así y otro que no bien hasta aquí con la transformación de las variables y ya estamos entonces en condiciones de poder empezar a generar nuestro modelo para el cual previamente como bien propone aquí el autor tengo que empezar por dividir nuestra x y nuestra y aquí tenemos quien lo hace con hilok donde justamente recordarán y lock ya lo hemos usado en las primeras clases justamente de análisis de datos donde en el primer caso toma a la variable Target con hilo referenciando el elemento número 0 y el resto de los elementos de uva al final los toma como el resto de las variables de entrada Sí porque es cero porque justamente el primer valor Sí el 0 es el valor Target y el resto son el resto de las variables de entrada tengo mi y mix Bueno lo ejecuto y ahora vamos a pasar a hacer lo que ya sabemos también que es la generación de nuestro modelo a partir de incorporar vamos a sumar algunas librerías pandas ya la tenemos metrix no la tenemos vamos a llevarla qué más 30 Split estas dos como les dije es parte del código que no vamos a utilizar por lo tanto no me la llevo estándar estas cuatro sí la de la que ahora sí estándar escáner porque vamos a escalar los datos Forest justamente le he hecho el ejercicio y la de regresión logística que es la que vamos a usar que también es parte de este ejercicio como les adelanté al principio bueno veamos esta y nos la llevamos bien ahora ejecutamos todo esto y vamos a pasar a hacer aquí tareas que ya conocemos bastante que es el tema de separar el conjunto de entrenamiento el conjunto de Test y descargar los datos aquí lo he puesto en una sola celda Bueno lo copiamos en una celda no hay problema son todas cosas que ya no son familiares Así que no hace falta que estén separadas las ejecutamos bien y creamos finalmente nuestro modelo bien en la siguiente celda llevo toda lo que hacemos es primero entrenar el modelo luego hacer las predicciones siempre con los datos separados porque fue lo que hicimos anteriormente medimos el aquiura Sí sí el score en base a los datos escanados el x-train y el que traen instalado Y luego medimos el Arquero así entre y finalmente lo imprimimos para ver los resultados bien como verán tardó bastante y aquí tenemos el resultado final tenemos una iglesia muy alto para el conjunto de entrenamiento y uno no tan alto y bastante diferente para el conjunto de Test lo que vamos a hacer ahora es también se acuerdan que vimos que una forma de visualizar El discord digamos de un modelo es esto que usamos y también la matriz de confusión solamente que la matriz de confusión la vamos a hacer de un modo gráfico porque justamente es lo que propone aquí el autor de esta publicación Bueno fíjense qué manera tan particular y tan interesante de ver los datos Recuerden que la matriz de confusión lo que hacía era en este caso tenemos valores 0 y 1 es decir cuántos ceros los predijo como 0 que sería esto Cuántos cero lo predijo como uno mal predecidos Cuántos unos los predijo como cero mal predecido también y cuántos uno lo predicó como uno que sería lo correcto si pagamos que los elementos la diagonal principal son los que marcan los aciertos y la otra diagonal y lo contrario en este caso fíjense que poco lo que me predice a mí aquí el bajo score conjunto de Test Es que tengo un alto número de unos que han sido mal predecidos fíjese que son más los uno mal predecidos que bien predecidos y no más sino mucho más y prácticamente aquí estamos hablando de casi ocho veces más este valor que este valor lo cual me habla de que los casos de predicción en valor 1 digamos que sería la persona que sí Tuvo una cardiopatía Bueno Este modelo no ha sido eficiente si en el otro caso bien con esto cerramos esta parte y vamos a ver a continuación lo que interpone el autor también que es la alternativa de usar el método de regresión logística el modelo perdón de regresión logística para intentar otra forma de ver si podemos lograr un mejor hasta aquí llegamos con esta primera parte de la clase Te espero en la segunda parte nos vemos