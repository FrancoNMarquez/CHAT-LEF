 Titulo: Clase14 (parte 2) Curso de Inteligencia Artificial 
 URL https://youtu.be/La9JEBk6ZVU  
 742 segundos de duracion 
 Bienvenidos a la segunda parte de esta clase Los invito a empezar con ella Hola a todos nuevamente continuamos con la segunda parte de esta clase en la primer parte de esta clase vimos como emular un proceso de razonamiento humano a través de un proceso computacional pero todos sabemos que en este ejemplo que tomamos de referencia de si voy a jugar o empezar a jugar o no al pádel hay tres factores que intervienen pero en nuestra vida no es tan sencilla Por lo general tenemos mucho más que tres factores para tomar una decisión por ejemplo en este caso podemos pensar que si bien están esos tres factores pueden haber otros que son de emergencia y tienen que ver a partir del momento que yo vaya a jugar al padre por ejemplo si hay buen clima si tengo el vehículo para poder movilizarme y poder llegar u otros similares estamos hablando de factores que son diferentes de los anteriores los anteriores son más programáticos en el tiempo los que mencioné recién son más emergentes como por ejemplo también podría pensar si ese día tengo un compromiso o no Bueno puedo diferenciar esos tres factores de estos otros tres factores y pensar en una estructura que ya no solamente se resuelva a través de un perceptrón sino a través de un segundo percepción el segundo perceptrón va a estar ubicado en una misma estructura vertical la cual se va a llamar pero también una decisión requiere muchas veces una cadena de elementos que están conectados para justamente llegar a esa decisión final vamos a suponer que decidimos viajar ese día porque tenemos un problema en el vehículo con un colectivo bueno en principio sé que si Quiero viajar en un colectivo que tengo que tener una tarjeta para poder hacerlo bueno lo primero que tengo que ver es si puedo encontrar esa tarjeta segundo una vez que la encuentro sé que esa tarjeta tiene que tener un saldo en dinero para poder pagar ese pasaje con lo cual lo segundo será ver si esa tarjeta tiene dinero se entiende que lo que estoy hablando son de un montón de cuestiones que están enlazadas y que van a llevar hacia el final voy a poder ir a jugar o no al padre es decir que hay una cadena de decisiones enlazadas en donde las primeras decisiones generan salidas que son entradas para la siguiente decisiones y potenciando este problema podemos pensar en nuevos perceptrones que se dispongan en otras varias estructuras verticales es decir en otro conjunto de capas en donde todos los perceptrones están conectados con sus pares esta estructura compleja a la que Hemos llegado se llama perceptrón multicapa y los perceptrones multicapa son reconocidos hoy en día con el nombre de redes neuronales y los perceptrones con el nombre de este gráfico va a terminar en una estructura final que tendrá dos salidas si es el caso de una salida binaria como el ejemplo que tomamos o bien en una salida que tenga más de dos opciones como en el caso cuando intentamos adivinar el número que estaba representado en una imagen de nuestro Data set Eminem teniendo en cuenta todo esto y este conjunto de capas que forman parte de esta estructura que ahora llamamos red neuronal podemos identificar tres elementos una primera línea de capa que se llama capa de entrada una última línea de capa que se llama capa de salida y todas las capas intermedias se llaman capas ocultas esta estructura de capas ocultas nos permiten como hablamos recién llevar a cabo una decisión capa a capa con diferentes niveles de complejidad esto en este nivel de decisión complejo se llama conocimiento jerarquizado este conocimiento jerarquizado será cada vez mayor en la medida que nuestra red neuronal tenga más capas de neuronas más neuronas por capas y en consecuencia un mayor nivel de conexiones entre ellas generando una estructura profunda de decisión y dando lugar a una red de aprendizaje profundo es decir una red de tipo Deep learning vamos a suponer el caso de cómo actuaría una red neuronal para intentar dilucidar Cuál es el número que está en una imagen tal cual como lo hicimos con nuestro datasette Méndez cómo sería el proceso las primeras capas pueden centrarse en cosas básicas como los ejes y líneas de esa imagen la siguiente capa pueden tomar esa entrada y centrarse en uniones entre los ejes para formar figuras simples luego las siguientes capas pueden unir esas figuras simples para definir si lo que están viendo Parece ser un número y tratar de dilucidar qué número es hasta acá vamos bien con esta idea de la red neuronal y el Deep learning Y parecería ser una estructura sencilla pero lo real es que lograr que esas neuronas sus capas tuvieran un funcionamiento jerarquizado como el que vimos y que cada una de ellas abordaran diferentes tipos de decisiones profundas y niveles de complejidad no fue tarea sencilla y algunas teorías que se desarrollaron a los fines de los 60 recién pudieron empezar a aplicarse 20 años después en lo que se llamó el invierno de la Inteligencia artificial concretamente los científicos de aquella era se encontraban con tres grandes problemas el primero de ellos el manejo de los pesos de las neuronas ya definimos que dentro de cada neurona hay una suma ponderada esto es similar a lo que vimos en un algoritmo de regresión lineal múltiple de esta manera se operan los valores de entrada y sus pesos además de ello Tenemos también la función escalonada para definir el valor de salida a través de un elemento básico y esencial que se llama umbral todos estos valores pueden ser alterados buscando que la red neuronal pueda tener el resultado con el mayor nivel de precisión posible el problema en aquel entonces fue que esos valores sólo se podían ajustar manualmente para hacer que la red funcionara mejor y eso era una tarea prácticamente imposible para graficar esto imaginemos que tuviésemos en una sala de grabación donde están esas consolas gigantes que tienen millones de perillas vamos a suponer que cada una de estas perillas me permitirá cambiar el peso de cada una de las sumas ponderadas que hay en cada una de las neuronas de mi red neuronal sería prácticamente imposible pensar que manualmente yo pudiera encontrar la mejor combinación para que la red de ese modo manual tuviese su mejor rendimiento Ese fue el primer gran problema que tuvieron los científicos y que le llevó 20 años poder llegar a que alguna persona pudiese encontrar una solución a ese problema bien el segundo punto era la necesidad de contar con funciones de activación como ya vimos y recién mencionamos las neuronas necesitaban de una función de tipo escalonada que transforme resultado lineal de una suma ponderada en una salida no lineal como Proponen las funciones escalonada recordemos que esta función me da solamente dos posibles valores de salida ceros y unos estas funciones vital pero más allá de ello Lo importante es el rol fundamental de esta función rol que cumplía con resultados muy pobres las funciones escalonada y por ello fue necesario pensar en funciones que cumplieran con el mismo rol pero con resultados muy superiores el tercer problema fue la volubilidad que tenían esas redes por aquel entonces Te acordás del ejercicio de nuestra clase número 10 en él hablamos tomando como ejemplo un algoritmo de regresión logística que en el caso de un problema de clasificación de flores Iris la salida no era un valor concreto setosa versicolor O virgica sino un porcentaje de posibilidad para cada uno de los tres valores posibles de salir bien esta lógica no aplicaba a los perceptrones ya que la salida del mismo era simplemente un cero o un uno y eso solamente es aplicable o es Útil para algunos casos pero si tenemos una red normal grande un pequeño cambio en solo uno de los parámetros puedes encadenar una serie de modificaciones no deseadas En las siguientes capas y cambiar por completo el resultado de salida es decir tengo una red muy voluble lo que se necesitaba es que los perceptores tuvieran una respuesta más real es decir no que me digan si es una serie o una clase de flor o no sino que me dijera Qué probabilidad había de que fuera cada una de las tres clases posibles otro ejemplo si tomamos el caso de Géminis que ya usamos no necesito que la red neuronal me diga concretamente qué número es el de la imagen sino un porcentaje de posibilidad para cada una de las opciones de 0 a 9 de que esa imagen corresponde a ese número de esta manera cuando cambia un parámetro en lugar de cambiar totalmente la serie de decisiones es decir abruptamente pasa a cero o pasa a uno cambia sutilmente sólo lo necesario y Por ende el impacto en las capas posteriores es mucho más controlado la falta de solución a estos problemas más una considerable merma en las inversiones que había para estas investigaciones En aquel momento produjeron lo que recién mencionábamos como el invierno de la Inteligencia artificial hasta que en el año 1986 salió esta publicación que provocó un resurgimiento de la Inteligencia artificial impulsado también por el aumento de la capacidad computacional y la disponibilidad de grandes conjuntos de datos con logros que no pararon de crecer hasta lo que conocemos hoy en día lo que nos queda por saber ahora es cómo se resolvieron a través de este artículo estos tres problemas que mencionábamos Pero esto es un tema que queda para la próxima clase hasta la próxima clase aquí termina esta clase los espero en la próxima clase nos vemos