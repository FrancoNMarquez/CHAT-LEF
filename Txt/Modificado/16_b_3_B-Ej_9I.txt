 Titulo: Clase 9 (parte 1) del Curso de Inteligencia Artificial 
 URL https://youtu.be/b_3_B-Ej_9I  
 1227 segundos de duracion 
 Hola bienvenidos Esta es la primera parte de la clase número 9 del curso de Inteligencia artificial de ifes en ella veremos los conceptos básicos del algoritmo de bosques aleatorios y de sus hiper parámetros empecemos con ello  Hola a todos Bienvenidos a la clase número 9 del curso de Inteligencia artificial de ifes seguimos en el módulo de Machine learning y en ese módulo vamos a ver un nuevo algoritmo que es el de voz que es aleatorios esta es la primera parte de la clase número 9 en la cual como hemos visto en las clases anteriores vamos a hacer una introducción a la teoría y después vamos a pasar en la parte número 2 a la práctica bueno el algoritmo de bosques aleatorios es uno de los algoritmos que habíamos identificado como algoritmo de tipo supervisado y aquí tenemos una lista que vimos en la primera clase introductoria de este curso regresión lineal revisión polinomial revisión logística árbol de decisión y bosques aleatorios bien este nuevo algoritmo Antes que nada tenemos que decir que además de ser de tipo supervisado sirve para problemas de regresión tanto como para problemas de clasificación el ver el nombre de estos dos últimos algoritmos bosques aleatorios y árboles de decisión nos permite presumir que debe haber una buena relación entre ellos y eso es lo que vamos a ver a continuación tal como sucede a la naturaleza que nos rodea es decir el concepto que tenemos de bosques y árboles en el ámbito de Machine learning también un bosque en este caso aleatorio es un conjunto de árboles que en el caso de Machine le llaman árboles de decisión aquí el gráfico de alguna manera nos demuestra ese concepto nosotros podemos ver aquí una estructura de un árbol tal cual vimos en la clase pasada ese algoritmo luego otro árbol que identificamos como un r2 y así n árboles que todos en conjunto con forman un bosque los datos para la conformación de cada uno de estos árboles que forman parte de este bosque nacen de un único datasette quizás el mismo Data set que aplicamos en la casa anterior enteramente a un árbol solamente que en este caso este Data set se distribuye en los n árboles de qué manera se distribuye bueno como el nombre del algoritmo lo indica de manera aleatoria Por eso aquí ustedes pueden ver que los árboles tienen colores diferentes en sus nodos y lo que hemos querido representar aquí es que justamente la distribución no es uniforme en todos los casos sino que es absolutamente aleatoria vamos a ver más detalles de este algoritmo este algoritmo como dijimos recién crea un bosque con un conjunto de árboles de decisión de manera aleatoria ahora siempre todo esto lo hacemos en Pos de que de como siempre Buscar el mejor nivel de score posible Qué característica también podemos Resaltar de este algoritmo la aleatoriedad se aplica a dos conceptos a dos elementos no solamente a la cantidad de observaciones sino también a la cantidad de características es decir que la distribución del conjunto de datos en distintos árboles distribuye aleatoriamente cantidades de observaciones y cantidades de características por ello se divide en 100% de las características y observaciones y se crean en el subconjuntos con cada uno de ellos bien con cada uno de esos n subconjuntos se aplica a cada uno de los n árboles que forman parte de ese Bosque pero ahora bien si tengo n árboles como sé cuál es el valor de la predicción del Bosque en su conjunto bien de dos maneras diferentes depende el tipo algoritmo de que se trate si es de clasificación o de regresión Obviamente que si tengo n árboles tengo n resultados en el caso de un algoritmo de tipo de regresión lo que se hace es promediar los n resultados para obtener la predicción final y en el caso de que sea un árbol de tipo de clasificación lo que se hace se hace un sistema de votación eligiendo de todos los resultados Cuál fue el que más veces Se repitió y ese será el valor final del Bosque en su conjunto por si acaso hayan quedado dudas respecto de este último punto vamos a ejemplificarlo a través de dos gráficos en principio aquí tenemos un gráfico de un algoritmo de tipo de regresión tenemos nuestro bosque con árbol 1 árbol 2 árbol n cada uno de estos árboles tiene resultado 1 resultado 2 resultado n Qué tipo de resultados son estos son resultados propios de un algoritmo que como pusimos aquí arriba está vinculado a un problema de regresión por lo tanto para obtener un valor final que represente a todo este conjunto de árboles que represente al Bosque lo que voy a hacer es promediar estos n resultados y obtener un resultado final por el contrario si ahora vamos a un algoritmo que aborda un problema de clasificación la lógica es similar solamente que en este caso no es un tema de regresión con lo cual no se pueden promediar los resultados sigo teniendo los n árboles con sus n resultados pero en este caso es un voto por mayoría cómo sería bueno obviamente no va nadar todos los árboles resultados diferentes muy probablemente como es un problema de clasificación en muchos de ellos los resultados sean similares Sí vamos a suponer que en este caso el resultado 1 y el resultado 2 atiende a la alternativa o la opción a de un sistema de clasificación de un problema de clasificación y en el caso resultado n arroja la opción B si Supongo que puede ser un problema binario a o b Entonces cuál sería el resultado final a por qué Porque hay dos árboles que me dan como resultante el valor a y uno solo que me da el valor B obviamente Esto no puede ponderar a una mayor cantidad de opciones de salida de un problema de tipo de clasificación y la lógica sería la misma siempre el voto por mayoría para obtener el resultado final bien una vez que entendimos Cuáles son las características de este nuevo algoritmo de bosques aleatorios vamos a meternos en el capítulo hiper parámetros tema que profundizamos mucho en la clase anterior ya que vimos que esto es muy importante para poder configurar en algoritmo Y obtener el mejor score también vimos que hay formas de tunear estos hiper parámetros de manera manual de manera semiautomática o de manera automática pero al fin y al cabo siempre La idea es estar cambiando los valores y parametros insisto para tratar de obtener en mejores cuerpos posible el primero de estos elementos en este caso los bosques aleatorios es nestimate o sea cantidad de estimadores que es o qué se trata en estimator Ni más ni menos que la cantidad de árboles que yo quiero para el bosque eso lo puedo fijar el valor estándar es 100 eso ya le da una idea de que cuando hablamos de un bosque es un bosque muy grande y se sugiere Que obviamente este 100 sea el valor mínimo si yo voy a configurar este hiper parámetro en instrumentos Debería ser un valor de 100 sería por defecto no tiene sentido o mayor a 100 nunca inferior eso para que realmente sea un bosque que tenga una cantidad de árboles que pueda ser o representar un buen modelo también en otra clase hablamos de este hiper parámetro criterium sí se acuerdan que teníamos dos opciones gini o entropía con las ventajas que describimos o desventajas que describimos en la clase anterior repasemos un poco de qué se trataba este hiper parámetro básicamente de lo que se trata es de ver cuál es el criterio para establecer la operación de decisión que está en cada nodo de cada árbol por ejemplo en la casa anterior tomamos como ejemplo el tema de las flores de Iris recordarán entonces en el nodo yo preguntaba por qué Por el largo del pétalo por el ancho del sépalo por el largo de el sépalo por el ancho del pétalo Sí bueno eso es parte de la edición y una vez que elijo la característica por qué voy a preguntar Mayor A qué valor menor a Qué valor quién decide eso bueno justamente esta este Perdón hiper parámetro criterio en el cual nosotros podemos elegir como vimos la clase pasada al igual que en el caso de los árboles también en los bosques las opciones o entropía Max filtros que quiere decir esto quiere ser cantidad máxima de características vamos un poquito hacia atrás a la teoría que vimos hace un rato dijimos que el bosque aleatorio distribuía aleatoriamente la cantidad de observaciones y la cantidad de características en este caso con este hipermetro yo le digo como máximo Cuántas características del 100% de ellas quiero que entren a cada uno de los árboles hay una norma que se puede generalizar Aunque no es obligatoria de que habitualmente se toma como criterio establecer la raíz cuadrada de la cantidad de observaciones si yo tengo por ejemplo como en el caso de Iris cuatro observaciones puedo sacar la raíz cuadrada de 4 y con eso fijar como hiper como valores tipo de parámetro Perdón que en cada árbol Tienen que entrar como máximo dos características Cuidado Que este como máximo no quiere decir que pueda ser menor es decir puedo tener un árbol que tenga una sola característica de las 4 Pero como máximo sería la raíz cuadrada de en ese caso 4 y sería el valor 2 esto insisto es un criterio universal no es fijo yo puedo poner que sea tres cuartos Sí para el caso de El ejemplo que estamos tomando recién como referencia Max samples relacionado directamente con lo que hablamos recién porque nace del mismo concepto dijimos que los bosques aleatorios distribuyen aleatoriamente en cada árbol una cantidad de características que lo que tratamos con Max feature pero también una cantidad de observaciones que es lo que vamos a tratar justamente con Max samples es decir así como en el hiper parámetro maxito yo le digo Cuántas características como máximo quiera que entra en un árbol con Max sample le dio cuantas observaciones como máximo quiero que entren a cada árbol y finalmente over score quiere decir fuera de la bolsa en inglés obviamente no porque se habla de la bolsa porque lo que se dice es que como en Max features y en Max samples sí yo tomo un conjunto y no el 100% de las características u observaciones van a quedar valores dentro de la bolsa como concepto y otros fuera de la bolsa Cuáles van a ser lo que van a estar dentro los que entren justamente a ese árbol Cuáles van a ser el resto los que están fuera de la vaca fuera de la bolsa Bueno lo que se busca en este caso si se quiere es que esos valores si sean son los cuales se va a testear para obtener el score bueno la eficiencia del modelo esto es muy importante sería como una suerte de paralelismo con lo que vimos antes con el conjunto entrenamiento del conjunto de Test Nosotros entrenábamos con un conjunto y testeamos con el otro con el que quedaba afuera se puede decir que el conjunto de Test era un ov del total sí de de datos cuando lo separamos entre entrenamiento y test bueno en este caso puede tomarse con paralelismo Eso sí los datos que quedan fuera para conformar el árbol yo Los dejé fuera para eso pero los pongo para testear Esto hace que justamente me garantice una mayor capacidad de generalización que lo que siempre deseamos de este modelo así como recurrimos a los gráficos para que ustedes pudieran entender mejor Cuál es la lógica que impera a la hora de que un algoritmo de bosque aleatorio Determine el resultado final para un problema de regresión y para un problema de clasificación también vamos a recurrir al gráfico para entender estos últimos conceptos de la distribución de las características en diferentes árboles si para ello me voy a adelantar un poquitito a la clase que viene ya que le voy a mostrar lo que sería un gráfico resultante de un bosque así como pudimos graficar un árbol también se puede graficar un bosque solamente que no los van a ver como vimos en este gráfico tentativo que aparece un árbol al lado del otro si no aparece un árbol debajo del otro obviamente para visualizar Esta esta este gráfico que hemos logrado Aquí sí este plot que hemos logrado Aquí he hecho un algoritmo muy sencillo con solamente 10 árboles lo cual contradice lo que dije recién de que como mínimo debe ser recién Pero bueno no estoy buscando aquí un buen score sino que estoy buscando aquí es una para que ustedes puedan visualizar rápidamente esto que estamos explicando obviamente tengo los 10 árboles uno debajo del otro vamos al primero de ellos fíjense que en el primero de ellos tengo en cada no decisión largo el para este nuevo raíz Perdón además un árbol tiene una decisión petand el ancho del pétalo el ancho del sépalo pero faltan una característica es decir que en este árbol hay tres de las cuatro características sigo con el próximo tengo el ancho del pétalo el largo del pétalo de nuevo el ancho del pétalo de nuevo largo del pétalo fíjense que en este caso no hay ninguna referencia a dos de las cuatro características justamente las dos que tienen que ver con Sí vamos a pasar en largo este que es un poquito grande para poder visualizarlo bien acá tenemos otro ancho del pétalo largo del pétalo ancho del pétalo largo el sépalo no hay ancho del cepal es decir tres de cuatro a este último de no este último en total sino este último ejemplo que quiero mostrarles que es el caso muy particular es un árbol muy cortito y fíjense que tiene ancho del pétalo ancho del Pétalo y nada más es decir una de las cuatro características con esto le quiero dar como ejemplo que no en todos los casos van a existir la misma cantidad de características ni la misma cantidad obviamente de observaciones Bueno espero que con este ejemplo que lo vamos a repetir lo vamos a ver nuevamente en la parte 2 de esta clase se puede haber entendido mejor este concepto de redistribución de una determinada cantidad de características por cada uno de los árboles de nuestro bosque finalmente ventajas y desventajas de los bosques aleatorios en el caso de las ventajas se puede decir que es un algoritmo de muy fácil implementación Y que es muy muy eficiente mucho más eficiente que los árboles Sí esa alta eficiencia se puede lograr aún sin hacer un gran trabajo sobre los hiper parámetros Más allá de que recién hablamos Vimos a cinco de ellos y dijimos que como siempre el trabajo ahí parametros nos va a llevar un mejor score en este caso de los bosques a veces no es necesario ajustar mucho no sirve parámetros para obtener un buen score Obviamente si se puede hacer y se puede hacer con las herramientas que vimos en la clase anterior de grid se ve qué más tenemos que con una gran cantidad de árboles obviamente 100 o más obviamente esta cuestión del sobre ajuste super ampliamente nosotros teníamos que en el caso de los árboles El problema del sobre ajuste era muy importante ahora ustedes entiendan que tengo ya no un árbol y que cada uno de ellos representa una variedad muy diferente al otro con lo cual es difícil que esta suerte de copia que hacía de la realidad el árbol cuando era un solo árbol puede darse en el caso de los bosques aleatorios se pueden manejar también en este modelo valores faltantes o nulos si lo que se hace justamente en este Universo de valores si se dan situaciones de ese tipo se pueden tomar valores promedios de una misma característica para reemplazar ese valor nulo o faltante curiosamente lo que vamos a destacar como desventaja tiene relación directa a lo que recién destacamos como ventaja bueno muchas veces esto pasa en realidad dijimos que una gran cantidad de árboles sí 100 o más me da la posibilidad de que justamente Este modelo como un todo del Bosque no esté afectado por el sobreajuste pero también con riesgo de que si en Pos de su objetivo tengo una enorme cantidad una cifra muy grande de árboles termine en detrimento modelo en términos de velocidad es decir que sea un modelo muy lento no va a estar afectado por sobre ajuste Pero puede llegar a ser muy lento hay que buscar un equilibrio entre esa ventaja y esta posible desventaja bien y obviamente que recién lo vimos en el gráfico esta ventaja de poder mirar en un gráfico el árbol y rápidamente entenderlo no se da en el caso del Bosque fíjense que recién vimos un ejemplo solamente con 10 árboles ustedes imaginen si tuviese que recorrer de arriba hacia abajo que he hecho cuando ustedes impriman en la práctica de la parte que viene van a ver que justamente aparecen los 100 árboles y tarda muchísimo viste por graficar si en árboles no no no no lo hace muy rápidamente ustedes se imaginarán bueno Obviamente que si eso es así van a poder comprobar que recordarlo visualmente es aún más lento y obviamente no va a ser tan fácil de visualizarlo Pero bueno Al fin y al cabo Esto va a pasar en la mayoría de los modelos simplemente lo tenemos que medir con determinados elementos Como por ejemplo con el indicador del nivel de precisión del modelo o sea el Score y bien hasta aquí esta primer parte de esta clase número 9 la introducción teórica de bosques aleatorios vamos a ver después la segunda parte con todo lo que tiene que ver con la implementación práctica de este nuevo algoritmo Les recomiendo repasar todo aquello que haya tenido que ver con la práctica de árboles si bien hablamos de Cuáles son las diferencias y que de alguna manera este algoritmo nuevo es superador del anterior es importante que entiendan algunos conceptos o repasen mejor dicho algunos conceptos que tienen que ver con la validación Cruzada y con el tuneo automático de parámetros recuerdan el grid se ve porque lo vamos a aplicar en la práctica de esta segunda parte también para los bosques y vamos a hacer en el caso de esta práctica una un ejemplo para un problema de clasificación y un ejemplo para un problema de regresión en el caso de la clasificación vamos a repetir el conjunto de datos de las flores de Iris y en el caso de la regresión vamos a repetir el Data set se acuerdan del valor de las casas de Boston csv la idea de repetir los conjuntos de datos tiene que ver comparar justamente un modelo con otro es decir esto nos permite poder evaluar el rendimiento de diferentes modelos en el mismo conjunto de datos y ver justamente esta suerte de competencia a la hora de determinar Cuál es el algoritmo mejor para el problema que yo tengo seguramente más adelante vamos a hacer una práctica donde justamente vamos a hacer en un solo conjunto de un solo Notebook si tomar un conjunto y aplicarle automáticamente todos secuencialmente los algoritmos que hemos visto y medir todos los scores y en una tabla poder tener justamente una idea de Cuáles pueden ser los mejores para cada caso también vamos a poder ver a través de una estructura de este tipo en algún momento Cuáles pueden ser los hiper parámetros o los valores de los parámetros y los score que se obtienen con ellos de modo que también podamos visualizar más allá de que tenemos una forma de que nos diga directamente la detección automática del tuneo de parámetros bueno Cuáles son los parámetros para cada score y poder ver no solamente los valores que fueron los más exitosos porque tuvieron el score más alto sino ver lo que los presentan también como una suerte de visualización conjunta de cómo van variando los hiper parámetros y cuáles son los resultados que se obtienen bueno en concreto repasen todo lo que vimos la clase pasada porque lo vamos a aplicar también en la práctica es decir en la segunda parte de esta clase hasta aquí llegamos con esta primera parte los esperamos para poner en práctica todo lo aprendido en la segunda parte