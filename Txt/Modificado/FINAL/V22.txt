 Titulo: Clase 12 (parte1) del Curso de Inteligencia Artificial 
 URL https://youtu.be/YOdajMsWZAQ  
 1150 segundos de duracion 
 Hola bienvenidos Esta es la primera parte de la clase número 12 del curso de Inteligencia artificial de ifes en ella Vamos a aprender los conceptos básicos de los algoritmos de tipo no supervisado empecemos  Hola a todos Bienvenidos a la clase número 12 del curso de Inteligencia artificial de ifes seguimos en el módulo de Machine learning pero hoy vamos a empezar a ver Otro aspecto del Machine learning que son los algoritmos no supervisados hasta ahora vimos lo contrario los algoritmos supervisados y vimos varias opciones las más importantes de ese ámbito ahora vamos a empezar a desalar este otro camino de los algoritmos no supervisados y dentro de ellos vamos a elegir uno de los ritmos más populares que es el de kang mean clustering hemos podido recorrer como dijimos recién un largo camino de los algoritmos de aprendizaje supervisado y al haber podido asimilar muchos conceptos sobre ellos así como también haber hecho muchas prácticas con las más importantes opciones de ese ámbito creo que estamos en condiciones de hacer algunas reflexiones sobre ese tipo de algoritmos de qué hablamos cuando hablamos de aprendizaje supervisado cuando hablamos de aprendizaje supervisado nos estamos refiriendo a un tipo de aprendizaje que se basa en descubrir la relación existente entre unas variables de entrada y una variable de salida o lo que es lo mismo decir que el aprendizaje surge de enseñarle a estos algoritmos Cuál es el resultado que queremos obtener para un determinado valor y con ello se genere un modelo que pueda predecir información de lo que puede pasar en el futuro concretamente tras mostrarles muchos ejemplos de lo que pretendemos el algoritmo pueda predecir y si se dan las condiciones para poder encontrar un patrón el algoritmo va a ser capaz de dar un resultado correcto incluso cuando le mostremos valores que no haya visto antes ejemplo de aplicación de esto ya hemos visto muchos a lo largo de todas estas clases pero vamos a ahondar en algunos ejemplos más para seguir reflexionando Por ejemplo si quisiéramos encontrar Cuál es la relación entre un correo electrónico y su clasificación como spam o correo deseado seguramente seríamos capaces de leerlo y poder clasificarlo sin problemas pero la pregunta es seríamos capaces de explicar cuál es el patrón que Define si un correo sea o no spam si le damos a un algoritmo de aprendizaje supervisado muchos ejemplos de correos y cuál es su clasificación es seguro que es el algoritmo va a tener la respuesta y va a encontrar un patrón con el cual definir un modelo de predicción más ejemplos un algoritmo de aprendizaje supervisado en el año 2016 pudo aprender a diagnosticar Si una persona sufriría o no de depresión a partir del contenido de su cuenta de Instagram con una eficiencia mayor a la que tendrían los doctores como lo hizo bueno simplemente tomando la información de miles de ejemplos de usuarios que usaban esa herramienta y padecían esa enfermedad de allí encontró un patrón y pudo justamente con esa información establecer la posibilidad de diagnosticar esa enfermedad estos dos ejemplos más todos los ejemplos que vimos en las prácticas anteriores nos permiten aseverar que si le mostramos a uno de estos algoritmos suficientes datos de entrada y de salida y si existe una relación o patrón es algoritmo va a ser capaz de aprenderla y darnos los elementos para crear un modelo por esto mismo el aprendizaje supervisado ha sido el paradigma que más aplicación práctica ha tenido durante las últimas décadas liderando nuevamente la corriente al alza que ha vivido en los últimos años la Inteligencia artificial como ya sabemos lo de encuadrar estos algoritmos como algoritmo de tipo supervisado viene del hecho de que al Mostrar los resultados que queremos al algoritmo estamos participando de la supervisión de su aprendizaje ahora La pregunta sería si esto es el aprendizaje supervisado Cuál es o qué es el aprendizaje No supervisado el aprendizaje No supervisado es el paradigma que consigue producir conocimientos únicamente de los datos que se proporcionan como entrada sin necesidad en ningún momento de explicarle al sistema Qué resultado queremos obtener bien quizás esta definición sea un poco compleja y no nos permita entender cómo se puede aprender sin recibir ninguna Pauta previa pero para entender un poquito mejor vamos a ver un ejemplo vamos a suponer que yo quiero hacer una fiesta y voy a invitar a 100 personas seguramente muchas de esas personas son amigas y Por ende dentro de la fiesta va a haber un alto número de subgrupos que van a estar conformados por las personas que se conocen previamente Mi idea es otra Mi idea es que no haya más de 10 grupos y Por ende lo que voy a buscar es que haya personas que estén en cada uno de esos grupos que tengan elementos común o que tengan afinidades por eso lo que voy a hacer es a cada persona que entra hacerle una serie de preguntas por ejemplo que profesión tienen en dónde trabajan Qué edad tiene su situación conyugal si una serie de preguntas no importa Cuáles pero que me permitan saber cuál es el perfil de esa persona y con ello conformar estos 10 grupos de qué manera bueno buscando que cada uno de los integrantes de estos 10 grupos un promedio tengan una respuesta a esas preguntas que sean similares a la de los otros integrantes de ese grupo de esta manera voy a tener 10 grupos en donde haya una gran homogeneidad en las respuestas en los perfiles de sus integrantes y ese grupo va a ser bien diferente de otros esos grupos no tienen nombre es decir Yo puedo ponerles número puedo identificarlos con una letra pero no van a tener una identificación con lo que reconocemos el aprendizaje supervisado como etiqueta en este caso no hay etiquetas Sí sé que ese grupo está integrado por gente que tiene un patrón común y ese grupo es diferente de los otros nueve pero no tiene una identificación Es más si en la fiesta concurriese una persona 101 102 haciéndole las mismas preguntas que le hice a los anteriores voy a saber en cuál de esos 10 grupos debería ubicar a esa persona este problema que acabamos de resolver se llama clasterización y es un tipo de problema muy importante dentro del campo de Machine learning como vemos sin la necesidad de darle información de salida ni tampoco de que alguien supervise la respuesta del modelo en relación a esa información de salida hemos podido generar un tipo de conocimiento de valor solo con la información que le dimos de entrada hasta aquí son todas buenas noticias ya que ahora tenemos un tipo de algoritmo que me permite crear modelos con menos trabajo de parte nuestra que lo que implicaba un modelo de tipo supervisado Pero y siempre hay un pero la dificultad de los algoritmos supervisados es que no tienen ningún ejemplo de respuesta con el que saber si el algoritmo está actuando correctamente utilizando un sistema de medición de score que nos permita valorizar la precisión del modelo y poder saber si el mismo Será o no exitoso por el mismo motivo tampoco podemos saber si en el ejemplo de la fiesta que necesitamos recién la cantidad de grupos que se definieron para el modelo es la más adecuada no obstante y volviendo a las ventajas de este tipo de aprendizaje los conjuntos de datos para entrenar son menos costosos de conseguir pensemos el siguiente ejemplo si quisiéramos entrenar a un algoritmo para clasificar animales como usamos de ejemplo recuerdan en la primer clase de este curso necesitaríamos no solo las imágenes de entrada sino también a alguien concretamente un ser humano que vaya visualizando imagen por imagen etiquetando las con el nombre del animal al que corresponden y esto en de datos que como mínimo suelen superar los 100.000 ejemplos Las 100.000 observaciones habla de una tarea que no es fácil o barato de hacer y que el aprendizaje de tipo no supervisado No nos exige un tema muy importante lo representa el hecho de que los algoritmos más potentes de este tipo no supervisado son capaces de descubrir a la perfección Cuál es la estructura interna que han generado dichos datos a ver si pensamos en el ejemplo de las figuras de animales podemos entender que cada grupo responde a un tipo de dato totalmente diferente del resto pero totalmente igual al resto de los miembros de su grupo Esto va a ser siempre así todas las imágenes de los animales que vemos en un grupo tienen que ser siempre iguales para que este algoritmo entiendan que pertenecen a un mismo cluster definitivamente no y ahora vamos a ver un ejemplo para tratar de entenderlo mejor volvamos Por un instante al datasette Méndez que usamos en la clase pasada todos sabemos que este Data set tiene imágenes digitalizadas de números manuscritos por ejemplo Estos son uno Estos son uno esto también es un uno y esto también lo es si bien esta información la podemos conocer ya que cada uno tiene un valor con una etiqueta cada uno de estas imágenes tiene un valor con una etiqueta en el Data set pero si no tuviésemos dichos etiquetas podríamos identificar como seres humanos con una simple observación a Qué valor numérico del 0 al 9 corresponde una imagen Obviamente que sí a pesar de que todos los números no son exactamente iguales un ser humano puede diferenciar una representación numérica de la otra ahora preguntémonos si no tuviéramos dichas etiquetas podríamos identificar con un modelo de Machine learning a Qué valor numérico de 0 a 9 corresponde una imagen justamente con un algoritmo de tipo no supervisado podemos hacerlo ya que esto buscará similitudes entre valores que no son idénticos pero representa un patrón a partir del cual los ubica en un grupo u otro en este caso en el grupo de los números estas estructuras conceptuales son denominadas espacios latentes y una vez que construimos este espacio las máquinas consiguen capacidades tan interesantes como las de saber si una cosa es similar a otra cosa el aprendizaje No supervisado señala un camino Muy prometedor en el futuro de la ia la segmentación de clientes que se utiliza en el campo del marketing es solo uno de los muchos casos de éxito de aplicabilidad de este tipo de técnicas de Machine learning sobre la cual ahora veremos uno de los algoritmos más conocidos el decammings clustering para comenzar a hablar de este importante algoritmo y empezar a conocer cómo trabaja un proceso de aprendizaje No supervisado vamos a empezar como otras tantas veces con un caso que tomaremos de ejemplo de aplicación imaginemos que trabajamos en una empresa implementando procesos de ia que efectivicen el funcionamiento de la misma y el jefe de marketing nos solicita la segmentación de los clientes en los siguientes grupos clientes de nivel bajo promedio o platino en función del comportamiento de gasto con fines de marketing dirigido y recomendaciones de producto sabiendo que no existe tal etiqueta histórica asociada a esos clientes cómo será posible categorizarlos bien aquí es donde el algoritmons clustering puede ayudar ya que es una técnica de aprendizaje automático no supervisada que se utiliza para agrupar datos no etiquetados en categorías o grupos similares pero específicamente cómo funciona este algoritmo la idea detrás del agrupamiento de camíns es dividir un conjunto de datos en un número específico de conglomerados Ese es el número k de allí el nombre de este algoritmo Cummins todos los puntos dentro de cada conglomerado son similares entre sí y aquellos en diferentes conglomerados también son diferentes Cuáles serían los cinco pasos claves que lleva un proceso de agrupamiento de tipo camisa primero especificar el número de cluster segundo determinar aleatoriamente los centroides para cada cluster tercero asignar cada punto del conjunto de datos al cluster más cercano cuarto recalcular los centroides de cada cluster en base al promedio de todos los datos que forman parte de cada uno de ellos y quinto y final repetir los pasos 3 y 4 hasta que las asignaciones de cluster dejen de cambiar o se alcance el número máximo de alteraciones la explicación fue demasiado rápida Bueno vamos a ver este ejemplo esta animación que tenemos aquí de 14 iteraciones paso a paso para entender mejor estos cinco últimos puntos que referenciamos para entender mejor estos cinco puntos que recién mencionábamos vamos a recurrir a la animación que vimos mientras explicábamos esos cinco puntos pero lo vamos a ir viendo detenidamente iteración por iteración Cuáles eran los dos primeros puntos que mencionábamos justamente de estos cinco el primero de ellos era establecer la cantidad de conglomerados recordemos El ejemplo que tomamos en donde decíamos que un jefe de marketing nos pedía segmentar a nuestros clientes en tres categorías bajo medio o platino o alto bien Esto no es una etiqueta que quiere decir con esto eso es una idea que nos ha solicitado nuestro jefe pero no es tan etiquetado los clientes los clientes en realidad son toda esta nube de puntos sí que en principio no están tipificados de ningún modo el segundo punto es elegir un centroide para cada uno de los conglomerados es decir si hay tres conglomerados habrá tres centroides los centroides eligen de manera aleatoria es decir que en el primer punto puede estar en cualquier lugar de esta 9 puntos en este caso elegimos este centroide este centroide y este centroide paso siguiente lo que hace el algoritmo es determinar la distancia de cada uno de los puntos es decir los clientes respecto del centroide e identifica a cada uno de ellos con el centroide más cercano es decir que todos estos puntos que están pintados de naranja están pintados de naranja porque entiende el algoritmo están más cerca de este centroide que de los otros dos lo mismo con los amarillos y lo mismo con los azules pero aquí no termina el proceso porque porque lo que tiene que buscar este algoritmo es la mejor ubicación de cada uno de los centroides por eso se habla de que este algoritmo tiene un proceso de iteración que lo que hace iteración por iteración como dicen justamente los pasos 3 y 4 ir acomodando los centroides en un nuevo lugar por qué no un nuevo lugar vamos al caso el centro de naranja como ustedes podrán observar el centro de naranja tiene una distancia respecto por ejemplo este punto que es el más alejado menor que la que tiene respecto del punto más alejado que está hacia abajo lo ideal sería que este centroide estuviese en un lugar más central que tuviera una distancia equidistante con cada uno de los miembros de su cluster bien Eso es lo que va a buscar este algoritmo en cada una de las iteraciones y por eso observemos en la iteración 1 el punto naranja ya no está en el mismo lugar que antes volvamos hacia atrás ven que está en esta posición ahora se corre a otra posición que está más central respecto de la nube de punto naranja Lo mismo sucede si ustedes observan con el amarillo fíjense Perdón la posición anterior y la nueva y el azul la posición en la iteración 0 y la nueva posición en la iteración 1 este ciclo Qué pasa genera una nueva posición y Por ende una nueva necesidad de reverer si los puntos que pertenecen a ese conglomerado siguen teniendo la menor distancia respecto de su centroide o ahora que los centroides se movieron de lugar Quizás esté más cerca de otros centroide y Por ende pasa a pertenecer a otro cluster fíjense que aquí en este caso veamos en el donde están los puntos amarillos tiene muchos puntos naranja es decir que son anteriores miembros de El cluster naranja y ahora están más cerca del cluster Amarillo también en el caso azul tiene muchos puntos amarillos que antes le pertenecían al grupo amarillo y alguna naranja lo mismo que antes le pertenecían al grupo Naranja es decir que en este caso hay una reubicación de centroides y encuadramiento de los puntos en relación a el cluster que le pertenece Y al nuevo cluster al cual le puede pertenecer porque puede cambiar o no Si vamos a la iteración 2 vemos que el ciclo se sigue repitiendo y que los centroides van cambiando de lugar Si observen que cada vez que pasa una iteración la alteración del lugar del centroide ya no es tan radical ya no es tan grande como los casos anteriores y Esto justamente habla de que cada iteración me va a llevar a buscar el lugar de mejor ubicación del centroide fíjense que inclusive respecto de los casos anteriores la división de cada uno de los clusters Y tomó como referencia esas líneas negras también va cambiando porque justamente hay una redistribución voy a pasar a la iteración 6 voy a pasar alteración 7 y fíjense que también lo que va disminuyendo entre una comparación y otra son los puntos que antes pertenecían a un cluster Y que ahora pasan a otro es decir todo va siendo más depurado los cambios van siendo más sensibles y terminarán cuando bueno como dice el punto 5 de los cinco puntos que anunciamos que describen este algoritmo cuando la cantidad de iteraciones si alcance lo que yo especifique para el cluster porque obviamente cada iteración lleva a un consumo computacional y la idea es que esto no esté indefinidamente funcionando o bien antes de llegar a la última iteración ya el algoritmo se dé cuenta que por más que itere la posición que tiene el cluster era ideal y esa posición ya no conviene que cambie bien hasta aquí llegamos con esta primer parte de la clase Ahora ya sabemos de qué se tratan los algoritmos no supervisados y en particular este algoritmo también classing ya estamos en condiciones de empezar a programar nuestras primeras líneas de código para ello Así que lo vamos a hacer como siempre en la siguiente parte de esta clase hasta aquí llegamos con esta primera parte los esperamos para poner en práctica todo lo aprendido en la segunda parte