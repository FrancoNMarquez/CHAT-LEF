 Titulo: Clase17 (parte 2) Curso Inteligencia Artificial 
 URL https://youtu.be/frbxynGYOSQ  
 1831 segundos de duracion 
 Bienvenidos a la segunda parte de esta clase Los invito a empezar con ella   bueno seguimos ahora con la segunda parte de esta clase y vamos como dijimos antes a un programa más complejo como bien aquí la complejidad a ver nosotros estamos tomando muchas veces y hasta ahora fundamentalmente para poder ir avanzando poco a poco conjuntos de datos que ya vienen hechos Sí este en realidad todo lo que hicimos con Géminis y Fashions son conjunto de datos que ya vienen preparados vienen preparados del punto de vista que ya está definida la cantidad de imágenes que corresponden Al conjunto de entrenamiento Cuántas son las que corresponden Al conjunto de Test y vienen debidamente separadas las imágenes vienen todas formateadas iguales de 28 por 28 y tienen algo muy importante un etiquetado el problema que vamos a tener muchas veces con las imágenes y que nosotros vamos a querer clasificar cosas que no van a abrir siempre de ese modo seguramente vamos tener que hacer un trabajo muy delicado y muy llevadero de conseguir las imágenes para entrenar a la inteligencia Y luego etiquetarlas para que pueda generar su modelo en realidad aquí hay algunas cuestiones que pueden ponderarse por sobre otras es decir si yo quiero entrenar a una red para clasificar determinadas tipos de imágenes tengo que tener las imágenes si no las tengo porque no consigo de dónde sacarlas bueno las tendré que buscar y crearlos yo manualmente es decir voy a tener que crear todas las imágenes en esa creación de toda ese Ese Conjunto de imágenes que no es un conjunto de datos Y es un grupo de imágenes que están imagínense dentro de una carpeta bien Voy a tener que bregar porque las imágenes tengan la misma dimensión dentro de lo posible Esto no es una cuestión se puede reformatear después dentro del código como ya la hemos visto pero si pueden tener un formato igual sería lo ideal sí bien Cuántas imágenes voy a lograr para entrenar estamos hablando de que fallan en tiene 70.000 imágenes usted se imaginan que juntar 70.000 imágenes no es una tarea sencilla Así ya vamos a ver en próximas clases que hay métodos de poder sacar por ejemplo a través de Google Pero insisto no es una tarea poco llevadera y luego verde etiquetar las imágenes para poder entrenar esa inteligencia si yo tengo imágenes por ejemplo de perros y gatos sí tendré que tener todos los perros etiquetados como perros y todos los gatos etiquetados Como gatos bueno Esta última parte puedo guiarse y hay mecanismos que justamente vamos a ver en esta clase para poder tratar de evitar esa parte pero la primera parte que es Juntar todas las imágenes no queda otra por lo pronto yo aquí les voy a pasar a ustedes a través de el campus virtual un conjunto es una carpeta insisto no quiero decir la palabra por conjunto porque se van a confundir con el conjunto de datos ya viene pre hecho una carpeta sipiada con imágenes de caballos y otra carpeta sipiada con imágenes de seres humanos en ambos casos Si tengo una división de un grupo de imágenes que han sido están preparadas o están etiquetadas con la carpeta no etiquetadas que están preparadas dentro del nombre de la carpeta como destinadas a entrenamiento y otra que están en una carpeta que está destinadas a validación sí Pero insisto las imágenes son simplemente archivos que van a ver que el nombre del archivo va a decir caballo 1 o humano 1 Pero eso no quiere decir que eso sea un conjunto de datos donde cada una de esas imágenes está etiquetadas Sí bueno por eso vamos a ver cómo trabajar en este caso suponiendo que estas imágenes que yo les doy usted la van a tener que lograr por sus propios medios para diferenciar otras cosas que no son caballos y humanos como el ejemplo que vamos a ver aquí supongamos autos de motos por decir algo bueno ustedes van a tener que conseguir las imágenes de los autos las imágenes de los motos la van a tener que poner en dos carpetas diferentes y vas a tener que sacar algunas imágenes de autos y algunas imágenes de motos para ponerlas en otras carpetas destinadas a validación y así tener de alguna manera dividida las carpetas de entrenamiento con autos y motos y las carpetas de validación o test con autos y mundos bueno esa es la base de la ejercitación que vamos a ver en esta clase Así que pasamos sin hacer más larga esta aplicación alcohol bueno acá estamos en el cola clase 17-2 de la segunda parte de esta clase donde vamos a ver algunas cuestiones que son de antes de ver el código propiamente dicho es muy importante para el tipo de trabajo que vamos a llevar a cabo fundamentalmente para lo que hablamos recién en relación a tener carpetas con una gran cantidad de imágenes de lo que quiero clasificar en este caso de caballos y de seres humanos da la particularidad de este caso a través del campus virtual yo le voy a brindar a ustedes como les adelante dos archivos zip que contienen estas imágenes que van a estar en ese campo virtual y les pido que cuando las bajen la pongan en una unidad de Drive la que ustedes quieran esto obedece a que a partir de esta clase les voy a enseñar Cómo vincular una sesión de colap con una unidad de Drive de esta manera yo cada vez que inició una sesión de cola puedo vincular a través de un proceso que se llama montaje de la unidad de Drive a la sesión de colap y directamente tomar los datos de allí sin necesidad de estar subiendo los como lo hacemos antes con algún Comando llevándolos a nuestro espacio transitorio donde está espacio de almacenamiento transitorio que nos ofrece cola sino directamente con Drive otro tema importante que tenemos que empezar a ver aquí como novedad y que seguramente nos va a acompañar de ahora más es la opción de usar el entorno de ejecución de tipo gpu que me ofrece justamente Google cola el acelerador por Hardware de lo que sería habitualmente una plaqueta aceleradora de gráficos que tienen muchas computadoras de alto nivel Pero quizás nosotros no tengamos acceso a un recurso calificado de ese tipo Y en lugar de usar la opción Non que aparece siempre cada vez que abre una sesión de cola de manera predeterminada uso la opción gpu luego le doy guardar y lo que hace yo no lo voy a hacer aquí pues ya tengo la sesión iniciada lo que hace es generar una nueva sesión Iniciar una nueva sesión Pero ahora con la modalidad de ejemplo Esto va a ser que todo proceso de tratamiento de imágenes se va a celebrar considerablemente versus la opción estándar de cola ahora en sí Entonces vamos a el montaje de la unidad de drive y lo hago justamente con from Google kolab import Drive y Drive Mount y la carpeta donde voy a poner justamente o voy a conectar voy a montar mi unidad de Drive una vez que lo haga justamente me dice que ya está montado porque lo acabo de ejecutar voy aquí a la carpeta y veo que aparece justamente la unidad de Drive la abro dentro de así aparece la unidad mi drive y allí aparece la misma carpeta que yo tengo si voy acá a la unidad de Drive Ven aquí tengo la carpeta archivos dentro de la cual tengo los dos zips que ustedes deberían bajar de el campus virtual y tener su propio Drive bien si yo voy a esta parte de aquí voy a acceder exactamente a la misma información es decir aquí tengo un zip y acá el otro abrimos un poquito más esta ventana para que se vea bien el la carpeta sipiada que va a tener las imágenes para entrenamiento y la carpeta sitiada que va a tener las imágenes para validación lo que tengo que hacer a continuación es descipear todos estos archivos que bueno conecte que están en mi unidad de drive y conecte ahora mi cola y lo primero que voy a hacer es crear un pad luego voy a abrir el archivo zip de esta manera y finalmente voy a poner el contenido de todas las imágenes ahora desde el archivo zip las voy a descifrar y las voy a poner en esta carpeta dentro de la carpeta tmp que ya la vamos a ver es una carpeta estándar de la unidad de almacenamiento de kolla y una carpeta que yo le voy a poner horse original sí voy a hacer exactamente lo mismo luego con el archivo zip destinado de validación con lo cual creo el local zip luego abro el archivo zip y finalmente hago el extracto y finalmente Cerramos el ZIP que es el recurso que hemos importado aquí esto es muy similar a lo que hacemos en el explorador de Windows Sí cuando justamente tomamos un archivo que está sipeado o comprimido y lo abrimos y lo colocamos a partir de un proceso como puede ser un archivo rar o de ese tipo a la carpeta o el directorio que yo quiera cómo veo todo esto Bueno voy a la unidad de almacenamiento drive y voy a ir a abrir a este icono de aquí y se me despliegan todas estas carpetas y voy a ir justamente a la carpeta tmp que es la que asignado aquí horse original y validation acá tenemos la primera works todas las imágenes de Los caballos son todos archivos de tipo png y más lo mismo otro tanto con todas las imágenes manos no confundan esto que está aquí que son los nombres de los archivos con etiquetas insisto estas imágenes no están etiquetadas A diferencia de lo que teníamos en el conjunto en Miss o Fashions sí bien nos falta ver también validación horse Exactamente lo mismo tengo las dos carpetas y dentro de cada carpeta tengo las cimas que solamente que las imágenes no van a ser entrenamiento sino que van a ser para validar la precisión de este modelo que estoy generando bueno en el siguiente paso Vamos a crear unas variables en las cuales vamos a guardar la ruta o el pass de la ubicación en este caso de los las imágenes para entrenamiento imágenes de caballo para entrenamiento imágenes de humanos para entrenamiento imágenes de caballos para validación e imágenes de humanos para validación y vamos a poner un print en cada caso para ver cuántas imágenes hay dentro de cada una de esas carpetas lo ejecutamos y vemos el resultado que me dice que hay 500 imágenes de caballos para entrenamiento 527 imágenes de humanos para entrenamiento y 128 y 128 imágenes para validación a continuación gracias a mclop y ya lo que manejamos como estructuras para imprimir justamente imágenes vamos a imprimir una tira de 5 imágenes de caballos y de seres humanos simplemente para visualizar y tener una idea aproximada de qué tipo de imágenes son las que tienen estas carpetas que acabamos de bajar y descomprimir aquí tenemos cinco imágenes de caballos y cinco imágenes de seres humanos fíjense que en realidad no son fotos son imágenes a color pero son dibujos y todas están formateadas en 300% justamente con la referencia que tienen al costado de abajo cada una de las imágenes y ahora viene la definición del modelo como lo hicimos antes primero contra sunflow importando Flow y luego siempre consecuencia el modo del que era tf le volvemos a poner el móvil al modelo creamos una capa de convolución donde digo que el input van a ser este imágenes de 300 por 300 pero ahora no de uno que sería un canal de grises sino de 3 porque son imágenes a todo color bien en este caso defino una primer capa de convolución de 16 y un canal del 3 por 3 y una función de activación de tipo relu luego la capa de pooling de 2 por 2 hago otra capa de convolución donde incremento la cantidad de mapas de características sigo usando un filtro de 3x3 y la misma función de activación y hago otro pulin de dos por dos y en la última capa de convolución incremento nuevamente la cantidad de mapa de características sigo usando el filtro de 3x3 y el Max puliendo por dos y finalmente la capa flaten que ya hemos visto anteriormente una capa densa de 512 y siempre la función de activación relu y la última capa que la capa de salida una capa densa de una neurona Por qué de una neurona Porque aquí tengo dos opciones o es caballo o es hombre por eso justamente la función de activación ya no es softmax sino como ya dijimos antes cuando es un problema de tipo binario es una función de activación de tipo sigmoide bueno ejecutamos el modelo para crearlo y con su marido podemos ver como ya habíamos visto antes todas las características de este modelo que acabamos de que a diferencia del modelo que creamos anteriormente tenemos tres capas de convolución y finalmente las que ya conocemos floten la densa y la densa de salida obviamente en este caso al ser en más capas de convolución tenemos una cantidad más grande de parámetros Más allá de Que obviamente Tenemos también imágenes de 300% y no de 28 por 28 como teníamos antes fíjense simplemente Este detalle que las imágenes no son 800% sino son de 298 Perdón 98 por el mismo problema que vimos antes que tampoco eran de 28 por 28 ya deben ser por 26 porque Saca los bordes de la imagen como ya sabemos bien lo que vamos a hacer a continuación es compilar el modelo como ya lo hicimos en el caso de los ejercicios anteriores Y aquí vamos a incorporar una novedad en realidad hemos venido trabajando con dos optimizadores sgd y Adam hoy vamos a incorporar un tercero que aquí lo estamos importando también de trazos louqueras y lo incorporamos como en los casos anteriores en el parámetro optimizar y vamos a estar agregando un concepto que es muy importante tanto que lo vimos en las clases teóricas que es la tasa de aprendizaje en este caso Lenin raid lo vamos a fijar con el valor 0.001 es decir una tasa de aprendizaje que va a trabajar de manera muy lenta respecto de otras opciones que pueden ser 0,01 y 0.005 que aquí se las dejo en el comentario de abajo que luego de hacer esto que vamos a hacer con esta tasa ustedes podrían probar cambiar esa tasa volver a compilar el modelo volver a entrenarlo y ver son los score que nos arroja bien luego también vamos a hacer un cambio en la función de pérdida vamos a usar binary Cross entro Y si recordamos lo que usamos en la primer parte de esta clase en la misma situación de Conspiración habíamos usado otra que es esparce categórical por qué la diferencia porque en este caso hacemos referencia a un modelo que buscaba dar solución a un problema de múltiples salidas no era binario Era muchas salidas tantas como elementos tenía el conjunto de datos Fashions que eran 10 en este caso volvemos tenemos una salida que atiende a resolver si una imagen es un caballo o un ser humano con lo cual es una salida de tipo binaria y por eso en la función de pérdida se elige esta opción a continuación voy a hacer un proceso que vas a llamar justamente procesamiento de datos por qué recordemos cómo estamos en este momento con lo que tenemos como datos nosotros tenemos carpetas con imágenes que no están etiquetadas si están en carpetas que tienen un nombre los humanos por un lado los caballos por el otro Pero eso no quiere decir que las imágenes están etiquetadas este conjunto de imágenes aún no es un Data set no tiene forma de Data Zeta ahora con este proceso es lo que vamos a hacer justamente vamos a crear como dice aquí este texto tensores que se llama tensores o a qué se refiere son estas estructuras que vimos aquí en vuelvo al caso de El ejemplo de hoy cuando hicimos este se acuerdan que dijimos que esta estructura tiene en principio la definición de la cantidad de observaciones el alto el ancho y el canal de color que utiliza Bueno eso es un tensor y por eso nosotros en ese tipo de estructura es lo que tenemos que transformar nuestras imágenes para que después puedan ser utilizadas para entrenar porque si no tienen este formato no van a poder ser utilizadas ni para entrenar el modelo ni para crear el modelo ni para validar el modelo ni para hacer algún tipo de predicción con ese modelo así que bueno el próximo paso Entonces es utilizar image Data generator que es una librería de queras en la cual lo que hago es en principio escalar los datos esto es igual a lo que hicimos antes cuando lo hicimos con una simple cuenta vuelvo al caso anterior se acuerdan esto que está aquí de la primer parte de esta clase Bueno lo usamos con otra herramienta Pero esto que viene ahora no lo hemos hecho antes porque antes teníamos un Data y ahora no que es justamente generar un conjunto de datos con estas imágenes que están en una carpeta para generar este conjunto de entrenamiento con este generador hay cuatro datos importantes que debo asignarle en principio el nombre de el directorio del cual tiene que tomar las imágenes luego el formato de las imágenes 300 por 300 luego el backside que es el tamaño de lote A qué se refiere el tamaño de lote cuando yo vaya a entrenar el modelo que quiero generar eso lo voy a hacer con lotes de imágenes es muy difícil darle todas las imágenes en un solo acto para que se ejecute el entrenamiento habitualmente por el peso que tienen las imágenes y justamente por lo complicado que implica todos los recursos computacionales que hay que tener para generar Este modelo con imágenes se va haciendo de alotes bueno con este parámetro aquí te fijo el tamaño de cada uno de sus lotes y finalmente el Class binary que lo que le digo es que lo que voy a hacer aquí es una definición de imágenes tipo binaria si tengo nada más que dos diferentes tipos de imágenes es decir que en este caso le va a poner 0 a 1 y uno al otro no nos confundamos en este caso no le va a poner horse a los caballos y se suman a los seres humanos lo que le va a poner a cada uno de ellos es un número que va a permitir diferenciar uno de otro pero como cuando teníamos en el caso del fallons que sabíamos que el no era la bota Pero además que no decía bota si no decía el número nueve bueno en este caso como no es un problema que tiene varias opciones más de dos concretamente sino que tiene dos le pongo Class binary y hago exactamente el mismo procedimiento para generar el conjunto de datos para validación bueno teniendo claro todo esto ejecutamos Esta parte Y tenemos la definición aquí de 1027 imágenes que le pertenecen a dos clases tan distribuidas en Dos clases caballos y seres humanos y 256 imágenes que son el conjunto de validación que también están diseminadas en Dos clases diferentes luego viene el entrenamiento del modelo como ya lo hemos hecho antes a posterior de la compilación aquí tenemos dos elementos que no veníamos usando de este modo anteriormente porque veníamos trabajando con conjuntos de datos que ya estaban pre hechos aquí hemos usado un generador para generar nuestro propio conjunto de datos y por eso primero le paso el conjunto de entrenamiento y luego el conjunto de validación o de Test a continuación la cantidad de épocas que en este caso hemos elegido 15 este número obviamente es importante la elección de ese número por supuesto porque obviamente trabajando con imágenes con una gran cantidad de imágenes y con las dimensiones que tienen el tiempo en virtud de este número que yo pongo aquí va a variar muchísimo en cuanto también a si dispongo de la gpu o no Porque ustedes vieron que yo le sugerí elegir la opción con gpu Pero eso no siempre va a estar disponible en colapse entonces obviamente Esto va a jugar en el tiempo final de entrenamiento Si los resultados no van a variar por eso pero si el gasto computacional y el tiempo que le vamos a tener que dedicar al entrenamiento va a variar mucho de acuerdo a este valor y de si tenemos o no la gpu luego tenemos estos dos parámetros steps y validation steps en ambos casos 8 porque 8 vamos un poquito al paso anterior y hemos recordemos que aquí tenemos 128 en el conjunto de entrenamiento y batch site 32 en el conjunto de validación habíamos dicho que eso lo hacíamos para que las imágenes vayan formando parte del entrenamiento de alotes y no todas las imágenes en un solo acto nosotros tenemos 1027 imágenes en el conjunto de entrenamiento y 256 en el conjunto de validación bien lo que tenemos que hacer Entonces es dividir este valor por 128 y me va a dar 8 dividir este valor por 32 y también me va a dar 8 por eso estos dos valores que le indican al entrenamiento que tiene que ir haciendo este entrenamiento con lotes de imágenes y no con todas las imágenes le indica En cuántos lotes va a hacer ese entrenamiento y es 8 en ambos casos y finalmente este parámetro verbos 1 le indica cómo voy a visualizar el entrenamiento con verbos 1 le digo que quiero ver esta información de la cantidad de epoch uno de 15 dos de 15 y esta barra que está aquí que es la barra de avance que van a ir viendo que va a ir creciendo como toda barra de avance y me va diciendo bueno en qué parte de entrenamiento está cada uno de sus entrenamientos bien una vez que tenemos esto lo ejecutamos yo voy a acelerar el vídeo porque obviamente Esto va a tardar mucho para justamente sacar la conclusión final la corrupción final es que la precisión del conjunto de entrenamiento es muy buena y Hemos llegado al 100% si esto como ya lo venimos diciendo desde los modelos de Machine learning puede ser una buena noticia o pueden ser no una tan buena noticia porque podemos tener no un gran algoritmo sino un algoritmo sobre ajustado y esto lo vemos porque justamente el conjunto de validación tiene un valor digamos que ronda el 80% porque digo ronda porque ustedes saben que de acuerdo a la cantidad de veces que lo prueben o la experiencia de cada uno cuando lo pruebe puede ser que sea un valor un poquito inferior a eso o superior a eso pero ronda ese 80% con lo cual tengo un 20% de diferencia entre el alquiler así de un conjunto de la criolla del otro lo cual es extremadamente Claro que manifiesta un problema de sobreajuste bueno justamente hay dos formas de evitar el sobre ajuste en lo que tiene que ver las redes neuronales convolucionales Y eso va a ser un tema que vamos a abordar la clase que viene bueno Y finalmente vamos a probar el modelo nosotros ya hemos hecho algunas pruebas con obviamente los Data set que hemos utilizado eminís y fallon de menis que ya dijimos y venían preparados pero esta es la primera vez que vamos a probar un modelo con algo que hicimos completamente nosotros desde el conjunto de datos Aquí hay una función que yo he diseñado dado que la idea es probarlo de una manera muy práctica con imágenes que voy a bajar desde distintas urls sí es cierto pueden buscarlo digamos a través de Google imágenes de caballos y de humanos y empezar a probarlo he hecho una función justamente para no repetir el código Tantas veces como pruebas vayas a hacer entonces este aquí voy a hacer una función que se llama predecir que tiene una URL aquí como parámetro de entrada obviamente en la URL lo que le voy a mandar va a ser la URL que contiene la imagen o cada una de las imágenes que quiero predecir o evaluar con este modelo luego tenemos esto que está aquí que es de URL que si ustedes recuerdan la clase de web scrapping justamente era el mismo argumento que usamos en aquel entonces para traer todo el contenido de la web en este caso el contenido es una imagen si no es un sitio web sino que directamente una imagen y la pongo en una variable que le he puesto respuesta luego lo que hago es justamente volcar todo ese contenido de esa imagen a una variable img y pasarla a un formato normalizado por eso la divido por 255 y con np array que es Nampa array le doy el formato de raíz que tienen que tener las imágenes a continuación yo no sé en qué formato viene la imagen Es decir de cuánto por Cuánto es con lo cual tengo que garantizarme que como Este modelo necesita imágenes de 300 por 300 la imagen sea de 300.800 con lo cual utilizo el método Bienvenidos a YouTube Aquí está importado en realidad digo bienvenido porque es una librería que vamos a usar muchísimo de aquí hasta hasta la última clase de redes neuronales convolucionales o visión computacional bien entonces vuelvo a poner dentro de la variable img la imagen ahora garantizándome que sea de 300 por 300 luego lo que hago es hacer la predicción Pero antes hago un re-have de img para garantizarme que tenga la forma de tensor se acuerdan que esto ya lo habíamos hablado aquí le doy 300 por 300 Por 3 que es el tipo de canal en este caso las imágenes tienen tres colores y este -1 donde iría la cantidad de observaciones tal cual lo habíamos hablado antes en este caso sería menos uno saque no hay una cantidad de observaciones Es solamente una observación porque es un objeto luego predicción me va a dar un resultado como es un problema binario no es que me va a dar un porcentaje por cada una de las opciones me va a dar solamente un porcentaje Lo que pasa que yo tengo que tener un umbral en este caso el umbral que voy a poner es el 0,5 Y a partir de su umbral si la predicción es mayor a 0,5 se tratará de un ser humano y caso contrario se trata de un caballo la función devuelve justamente la clase que la clase en realidad es el texto más el valor de la predicción para que ustedes lo puedan ver bueno habiendo desarrollado esta función lo que voy a hacer es hacer uso de ella con lo cual aquí puesto tres ejemplos de seres humanos de urls que apuntan imágenes seres humanos y tres ejemplos de URL que apuntan a imágenes de caballos esto para saberlo De antemano y después ver si la predicción puede haber sido certera o no y en cada caso voy a hacer print de predecir mandándole el valor de URL puse los seis ejemplos juntos así lo ejecutamos todos juntos y vemos los resultados Bueno lo probamos entonces y vemos los resultados bien Recuerden que en los tres primeros casos son humanos y los tres últimos son caballos en el primer caso bueno determina que hay un humano con un 0.89 casi llegando al 100% de certeza de que es un humano en el caso del humano 099 el segundo manos 099 en el caso del ser humano también hay una total certeza de que es un ser humano en el cuarto caso es un caballo pero lo determina con cero simboliza que está muy cerca del umbral o sea podría haber sido tranquilamente visto como un caballo porque insisto el umbral de 0,5 y está apenas por encima del 05 no obstante es una mala predicción Pero acuérdense que nosotros tenemos un así en el conjunto de test de 0,80 es decir que tengo un 20% de posibilidad de error sí bien y aquí tenemos una prueba que hay un error no obstante en los dos casos restantes ha hecho una buena predicción que es un caballo con una predicción del 0.01 o sea está muy cerca de cero que sería la certeza absoluta o la predicción absoluta de que eso es un caballo bueno Esto ustedes pueden seguir utilizándolo sería interesante que lo hicieran buscando otras imágenes y poniendo aquí el resultado de esas urls y ver bueno Cómo funciona el modelo sabiendo que como dije antes tenemos un modelo con un 20% de error hasta aquí llegamos con esta clase en la próxima clase vamos a ver bueno este problema que hemos hablado hoy mencionado en cuanto al problema de sobre ajuste como ir solucionándolo y vamos a volver a utilizar nuestro viejo Data set en Miss para justamente ver las diferencias de Qué cosas puedo usar para ir superando el problema de sobre ajuste así que hasta la próxima clase aquí termina esta clase los espero en la próxima clase nos vemos