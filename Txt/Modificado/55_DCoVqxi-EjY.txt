 Titulo: Clase 28 (parte 2) Curso de Inteligencia Artificial 
 URL https://youtu.be/DCoVqxi-EjY  
 2298 segundos de duracion 
  Esta es la segunda parte de la clase número 28 te invito a empezar con   ella  bien aquí estamos entonces en la segunda parte de esta clase donde como dijimos en la primer parte de esta clase vamos a trabajar ahora sí con una red neuronal recurrente con lstm y con la opción bidireccional que vimos en la teoría que abordamos en la primera parte de esta clase lo primero que vamos a hacer es instalar el la aplicación que utilizamos para leer archivos de tipo eh PDF Así que arrancamos con eso vamos a instalar luego una serie de librerías que ya vamos a ver bien dónde las vamos a aplicar vamos a montar el Drive para Acceder al archivo que vamos a usar para esta clase y luego vamos a extraer con esta función extraer texto de PDF que la venimos usando en las clases anteriores el contenido de ese archivo y lo vamos a llevar dentro de una variable texto es es exactamente la misma función que usamos en las clases eh anteriores Así que esto ya seguramente no hace falta que lo expliquemos pero sí vamos a abordar Cuál es el contenido del archivo que vamos a usar en este caso para esta práctica el archivo se llama relatos.pdf y lo he armado en base a pedirle a ch gpt que me haga o me simule o me genere relatos de relatores de fútbol argentinos sobre lo que sería una jugada previa y el gol sí es decir que la idea sería que con varios relatos de este tipo generemos un Corpus la inteligencia pueda entrenarse con ellos y a partir de eso yo haga lo que tiene que ver con el tema de esta clase que es generar texto a partir de una frase es decir la generación de texto puede ser algo que tiene que ver con un prom como nosotros vemos muchas veces en chat gpt donde le digo que me cree una poesía que me cree un una definición o un relato que yo quiera hacer una exposición que yo quiera hacer desde la nada simplemente dándole un prom o alguna serie de características pero también existe o en lado dentro de lo que es la generación de texto en cuadrado dentro de lo que es la generación de texto está también la situación parecida a lo que nos pasa a nosotros cuando por ejemplo en Google escribimos un mail y nos aparecen palabras sugeridas a la derecha bueno eso también es generación de texto y algo de eso es lo que vamos a hacer generar un texto completamente como decía recién en ch PT que pimos por ejemplo que nos escribe una poesía eh requeriría un Corpus muy grande o una inteligencia entrenado con un Corpus muy grande para generar todo un texto y que tenga sentido y que sea lo que nosotros esperamos no genere en este caso lo que vamos a hacer va a ser Buscar una inteligencia a la cual yo le puedo dar una primer frase supongamos de tres o cuatro palabras parecido a lo que insiste lo queos hacemos cuando escribimos un mail y que nos genere las 10 o 20 palabras próximas a esa primera frase y que podamos ver que tenga conexión con el inicio de la frase Sí bueno Esto un poco lo que vimos en la teoría cuando ejemplificamos el caso de bueno que cuando estudié en Alemania me enseñaban a estudiar alemán me enseñaban hablar en alemán bueno o que es un día azul Sí bueno esa cuestión es cómo generar la próxima palabra de acuerdo al contexto que traigo aquí el contexto va a ser muy cortito un grupo de palabras tres cuat cinco no más que ellas y después lo vamos a pedir Insisto que nos escriba 10 o 20 palabras que seguirían a ese texto según lo que entiende la inteligencia Según Lo Que Fue entrenada bueno y el resultado Obviamente el resultado en sisto está muy acotado este archivo está lejos de ser un archivo un muy grande pero bueno es una primer prueba y justamente La idea es que ustedes puedan después con esto poder buscar otros archivos más grandes justamente en la finalización de esta clase Voy a hacer eh una una muestra de Cómo entrenar se acuerdan con lo que usamos la clase pasada los 10 libros de recursos humanos a ver si nos genera algo mejor dado que en ese caso se trata de un Corpus mucho más grande volviendo al punto en lo relativo a esta función exalar texto desde PDF lo que vamos a abrir va a ser este archivo que lo vamos a señalar Primero aquí y después lo vamos a ver aquí en en el código sería Drive my Drive archivos nlp y dentro de nlp está relatos PDF Sí bueno cerramos esta ventana y esa ruta es la que tenemos aquí sí bien con lo cual ya tenemos definida la función Insisto que la venimos usando en las últimas prácticas y la apertura del documento que insisto es lo mismo porque usamos la misma función Así que lo ejecutamos sin más palabras y ya tengo entonces dentro de documento justamente ese contenido de relatos si ahora yo veo el contenido de documento Bueno aquí está sí obviamente es un poquito más largo que esto pero bueno me muestra como siempre la primer parte s Buenas tardes amigos nos encontramos en estea emocionante partida bueno el rato no es 100% tal cual como relato en argentino pero se aproxima bastante ha hecho un buen trabajo de chat gpt igual obviamente la idea que yo podría eh haberle puesto más proms para pedirle como ustedes saben chat gpt que no estoy conforme con lo que me generó y me gener algo mejor en base a algunas cuestiones algunas consideraciones para que vaya generando mejores l pero como base para esto es más que interesante eh obviamente como dijimos lo vamos a hacer después con los los Corpus de recursos humanos Y ustedes lo pueden hacer con el material que ustedes les parezca mejor generado por char gpt o libros o documentos del tipo que ustedes consideran Bueno una vez aclarado esto lo que voy a hacer como tantas otras veces es eh colocar todo este texto en minúscula Y splitear en este caso lo voy a splitear por enter es decir fíjense por este carácter barra n que creo que ya saben todos ustedes que esto significa el la marca de enter sí bien o el corte de línea para decirlo de otro modo con lo cual ahora en Corpus tengo bueno piteado este documento en párrafos que están separados eh en cada caso en Que aparezca un un indicador de corte de línea o que ve da de línea o ent bien para ver esto ahora veo el Corpus y veo lo mismo que vi anteriormente aquí arriba pero obviamente ahora separado porque Corpus es una array que tiene párrafos del texto original obviamente en ese párrafo ya no existen estos caracteres barra n porque han sido considerados solamente para tomar como referencia para separar en en oraciones todo el texto y obviamente los quita del Corpus bien ya tengo el Corpus Entonces explito por lo tanto lo que vamos a hacer ahora es simplemente como hacemos siempre para que se vea más así Más allá de que Perdón aquí visualmente ya es bastante claro como se ve este la separación en oraciones bueno imprimo la oración sub uno y veo Buenas tardes amigos nos encontramos qué es lo que veo aquí al principio de este texto sí ven La cero es un es un espacio vacío sí la uno es esta frase que ven aquí y que reproduzco aquí cuando le digo que el número uno bien hecho esto como siempre ahora voy a tokenizar con lo cual creo el tokenizador y lo que hago justamente es entrenar el tokenizador con el cor acuérdense que para que pueda tokenizar bien ese texto yo tengo que to entrenar Perdón ese token con el Corpus que yo tengo Sí y luego justamente empiezo a a partir de eso este tomar la referencia de Cuántas palabras tiene ese tokenizador con el Word index Acuérdese que el Word inish lo que hace es darle a cada palabra un valor numérico sí no Como tantas palabras haya sino por tantas palabras diferentes que haya sí bien Entonces ejecutamos esto y ya tengo obviamente en el total words la cantidad de de de palabras que tiene mi vocabulario en base al Corpus y lo imprimimos y podemos ver el tokenizador donde está el número que le asignó a cada una de las palabras el uno la dos en tres bueno esto ya lo hemos visto un montón de veces y Cuántas palabras en total forman parte de mi vocabulario generado a partir del Corpus que son 442 palabras bien antes de continuar con la clase práctica de código duro Vamos a abordar algunos conceptos teóricos que son necesarios ir viéndolos este en detalle y paso a paso para entender todo lo que va a venir después en principio lo que tenemos que diferenciar Aquí Cuál es el objetivo que perseguimos en la primera parte de esta clase y el objetivo que estn buscando ahora el objetivo que perseguimos en la primera parte de esta clase fue resolver un problema de clasificación clasificación de texto como clasificación hemos hecho otras veces problemas de clasificación hemos hecho otras veces con redes neuronales convolucionales con redes neuronales y con Machine learning sí es un problema clásico solamente que en este caso está contextualizado en lo que estamos haciendo justamente que es el abordaje de los textos bien ahora eh lo que vamos a hacer es otro tipo de problema como ya lo adelantamos hace un rato que es de generación de texto en el caso de la clasificación de texto y todos los problemas de clasificación en general sabemos que necesitamos un conjunto de datos de validación Sí por qué Porque justamente para ver si ese algoritmo está aprendiendo de que ese texto por ejemplo como veíamos recién era sarcástico no era sarcástico yo tenía que tener textos etiquetados como sarcásticos y como no sarcásticos para que el algoritmo pudiese entrenar pudiese aprender y luego con el conjunto de validación Yo podría ver si el algoritmo está resolviendo bien o mal en base Al conjunto de tex Bueno estoy explicando lo que ya hemos visto un montón de veces creo que está no hace falta explicarlo mucho más que esto Pero cuál es la cuestión aquí cuando estoy llevando adelante un problema de generación de texto No necesitamos como bien dice aquí un conjunto de validación Sí por qué Porque es una cuestión predictiva sobre lo cual está creando algo y no hay algo que ya ha sido creado antes para ver si esa creación está bien o está mal esto impera el criterio nuestro que somos los que vemos el resultado de la generación que hemos pedido Sí entonces aquí hay algunas cuestiones muy particulares a través de las cuales el algoritmo aprende obviamente no tiene una etiqueta con lo cual aprender Pero va a tener un sistema que va a tener como una especie de etiquetado parcial que va a ir construyendo a partir del cual va a aprender Bueno cómo es esto vamos a verlo paso a paso Vamos a tomar como ejemplo una línea cualquiera del Corpus que dice que la semana tiene más de 7 días Sí es parte del relato donde el relator usa esta frase como ya tenemos este Word Index creado donde ls un la s2 etcétera etcétera sí lo que vamos a hacer es transformar Sí cada una de esta esta frase digamos esta frase en concreto Sería para todas las frases pero en el caso del ejemplo de esta frase en concreto pasarla a una secuencia de números sí entonces 2 8 3 10 31 13 3 3 12 3 13 sería como el número que representa esto es un ejemplo por supuesto cada una de estas palabras sí supongamos que le correspondía a eso S Bueno una vez que yo convierto esta secuencia de palabras que forman el texto en una secuencia de números a partir del Word Index lo que se hace es armar subsecuencia que tienen que ver con ir Armando parejas y que eh esas parejas vayan creciendo en tríos en cuartetos en quintetos o sea arranco de un par y después le voy sumando sí En las siguientes secuencias un número hasta llegar al final con Este ejemplo se ve claramente aquí primero tengo 2 o porque son los dos primeros valores la siguiente secuencia es 28 31 la siguiente 2 8 31 31 se ve claramente es muy fácil de ver no entonces la última secuencia Cuál va a ser la que va a coincidir con la expresión original 2 8 3 10 3 11 16 3 3 12 3 13 Es decir genera sobre una secuencia de números Sí una cantidad de secuencias n secuencias que es igual a la cantidad resultante entre conformar una primer pareja y después cada uno de los elementos que se vayan osando Sí por eso en este caso tenemos 1 2 3 4 5 6 7 cuando justamente el el la Ray inicial era 1 2 3 4 5 5 6 7 8 ese siempre va a ser uno menos porque arranco de un par bien hasta ahí vamos con la primer parte de esta historia y lo vamos a ir haciendo en código para que se vaya viendo justamente en el transcurso de lo que vamos haciendo y podamos visualizarlo por eso esto que tenemos aquí es lo que vamos a codificar aquí creo una una Ray input sequences Sí y lo que voy a hacer es forline in Corpus es decir voy a recorrer cada uno de los párrafos de mi Corpus y lo que voy a hacer es convertirlos en secuencia text to sequences de cada Line y a partir de tokenizer lo voy a poner dentro de token list es decir que lo que voy a hacer es cada línea s voy a hacer algo como esto cada línea nuevo aquí la voy a convertir en est O sea que ese for está haciendo eso que señalé recién por cada línea una vez que hago esto lo que tengo que hacer es la segunda parte de lo que vimos aquí es decir ir Armando este conjunto de secuencias a partir de una secuencia de números bien cómo hago for in Range Range que va de uno a token list Qué es token list bueno es la cantidad de elementos que tiene justamente mi token es decir en este caso dijimos se acuerdan que teníamos ocho entonces va de un a o eso que quiere decir que va a ser uno menos que la cantidad total porque acuérdense que empieza desde cero la numeración Entonces qué va a hacer en cada caso va a armar token list si token list va a ir desde el principio hasta y + 1 Sí en el primer caso el principio Cuál va a ser c y + 1 es 2 y acuérdense que cuando pone hasta dos quiere decir que siempre es la anterior O se va 0 y 1 y así en cada vuelta I va a valer un valor más y Por ende el valor hasta de lo que yo vaya a poner en N Grand sequen va a ir siendo un valor más cuando termine este for el resultado va a ser algo similar a lo que vimos aquí en este sencillo ejemplo bien lo ejecutamos y ya tenemos el resultado bien en este caso por qué armo esta estrategia porque justamente la forma de aprender que va a tener este algoritmo es la siguiente aquí justamente lo he puesto en un párrafo para que se entienda bien la idea es decir yo voy a armar parejas después tríos después cor más secuencias y para cada caso es decir cuando haya una palabra va a aprender de que existe como sugerida una próxima cuando haya dos palabras también va a existir una próxima cuando haya tres palabras Existirá una próxima Y así sucesivamente Qué quiere decir que la inteligencia tiene que entender que que después de dos y 8 hay un 310 después de dos y 8 310 hay un 31 y así sucesivamente Esa es la forma en que se entrena esta Esta generación de texto este algoritmo de generación de texto porque no hay una etiqueta más allá que la etiqueta la vamos a fabricar no hay un etiquetado previo va a haber una suerte de etiqueta que justamente se va a generar a partir de esta lógica que estamos Armando por lo tanto a continuación lo que vamos a hacer en principio es eh medir eh Cuál es el largo de la máxima oración por qué porque de aquí ya tenemos un problema que ya lo vemos justamente cuando hamos esta cadena de secuencias de que todas las cadenas no son iguales la primera es de dos y la última de ocho y eso no lo podemos dejar así tenemos que tener vectores iguales sabemos que no puede haber vectores irregulares bien Por lo tanto lo primero que vamos a averiguar es cuál es el vector más largo Sí cómo bueno con esto que hemos puesto Aquí vamos a buscar justamente Max de lende x cuando x Sí es lo que está en las input sequences Es decir de todas las input sequences que acuérdense que lo generamos aquí que tiene todas las secuencias de todos los párrafos es decir insisto todo esto de todos estos imagínense todo lo que hay Sí vamos a buscar cuál es el más largo entonces for x in imp de cada uno le vamos a medir el len y del len o sea de los largos de cada uno Dame el máximo Y eso lo voy a poner dentro de una variable sequen len que después la vamos a imprimir para conocer Cuál es el valor de eso y vemos que es 29 Cuál va a ser el trabajo que vamos a llevar a cabo Ahora va a ser un trabajo que se llama padeo es un proceso Perdón que se llama padeo que consiste en tomando esta cuestión de la dimensión máxima rellenar con ceros cada una de las eh posiciones que no tienen número entonces supongamos que para el ejemplo que venimos trayendo que no es este 29 que tenemos acá sino el ejemplo teórico Sí vamos a suponer que la cantidad máxima es 10 Entonces qué tengo que hacer se acuerdan la primer secuencia era 2 o bien a esa 28 qué hago le pongo och ceros sí formando un vector de 10 posiciones y lo que le voy a poder o la opción que tengo para hacer es si quiero que los ceros estén adelante o estén atrás obviamente como yo estoy haciendo algo que me va a buscar siempre el próximo valor me conviene que los ceros estén adelante y no atrás sí bien Entonces esto es lo que le decía la clase pasada de que si bien los en beding busca eh en general que no hayan posiciones con valores ceros sino que estén ocupadas todas las posiciones A diferencia de los problemas anteriores que había por ejemplo el sistema de conteo de palabras que generaba muchos espacios vacíos para este problema particular de generación de texto no queda otra que que todos los vectores sean iguales y como tengo que ir Armando estas secuencias y estas subsecuencia no queda otra que rellenar esos espacios con cero bien se entiende Este ejemplo gráfico se enti Este ejemplo gráfico lo que vamos a hacer ahora es justamente hacerlo en el código que venimos trayendo es dec tengo que generar ahora todos vectores de 29 posiciones para ello lo que hago es decirle que a input sequences que tiene toda esa cadena que hablamos recién quiero que su largo máximo sea Max sequen Lane que es este 29 que tenemos aquí y con padding le digo como dije recién dónde Quiero los ceros pre antes post después los quiero antes Entonces le pongo pre con np justamente transformo todo este resultado en una array y lo vuelvo a poner en el mismo input sequences que tenía antes s ejecuto esto lo puedo poner otro nombre variable aparte bueno es para reutilizar la misma nom el mismo nombre de variable Perdón podría haber sido la misma Ahora viene una cuestión muy interesante que es Cómo se arman las etiquetas de una lógica que vengo trayendo de una resolución de un objetivo que no tiene etiquetado bien muy fácil yo tengo que tratar de tomar en esta secuencia que tenía acá arriba que tomamos como ejemplo Sí el criterio de establecer de que el último elemento es la etiqueta Por qué Porque como dijimos hoy sí si yo tengo que el primer elemento es un dos tiene que haber algo que me diga sabes qué después del dos lo habitual es que siga un ocho cuando tengo un dos y un O tiene que ver algo que diga sabes qué después del dos y el 8 lo mejor o lo más habitual no lo mejor lo más habitual es que haya un 310 eso es lo que tiene que ir aprendiendo la inteligencia Y cómo lo va a ir aprendiendo bueno justamente lo que yo voy a hacer es que cada elemento final de cada vector va a ser la etiqueta va a ser el I se acuerdan este concepto de i Sí y el resto va a ser la x es decir que estos vectores si tengo vectores de 10 posiciones para este ejemplo no de los 29 decir Tratamos de separar El ejemplo teórico que vengo trayendo del ejemplo práctico de lo que estamos llevando adelante en el código no bueno si estoy parado en esta cuestión de que todos los vectores son de 10 posiciones Entonces todos los vectores van a tener nueve posiciones para definir a la x y una posición para definir a la y s si vamos al código nuestro serán 28 para una cosa y la número 29 para la otra sí bien entonces Este ejemplo que está aquí gráficamente Sí bueno lo que voy ahora a hacerlo es en la práctica con lo cual lo que voy a definir ahora es xs y y lo que digo que de input sequences me tomé todas las filas y solamente las columnas hasta la men1 Qué quiere decir tomo todas menos la última y en el caso de labes que sería la i va a ser exactamente lo contrario tomo todas las filas pero la columna solamente la última bueno ejecuto esto y finalmente vamos a generar las is yo aquí le puse labes pero todavía en labes no tengo la forma de arma de las I Por qué Porque en el caso de las labes no vamos a trabajar con el número si que corresponde a cada etiqueta 8 31 31 etcétera etcétera sino que vamos a tener que formar un vector que tenga tantas posiciones como el vocabulario completo Acuérdese que vocabulario completo tenía Tenemos aquí arriba 442 si este elementos y para representar el o que sería por ejemplo la primera etiqueta vamos a tener que hacer algo como esto sí poner 0 1 2 3 4 5 6 7 Se en la séptima posición poner Perdón en la octava posición que corresponde al subíndice número siete sí voy a tener que poner justamente un uno representando que ese elemento que está allí es el número ocho Pero por qué Porque está o tiene un uno en la octava posición bien una vez logrado esto hago lo que acabo de mostrar justamente para crear mi S A partir de lab sí diciendo que la cantidad de elementos totales es igual a la cantidad de palabras totales que tiene mi Corpus y lo que voy a hacer es pasarlo a categórico Sí el número categórico sí es en una representación de ceros y unos poniendo el uno en la posición que le corresponde al número natural bien haciendo esto Entonces ya tengo mi x tengo mi es decir tengo mi x y mi etiqueta que en realidad no vino desde el principio como siempre nos pasa cuando hacemos este o entrenamos algoritmos sino que la tuve que yo ir generando con todo este proceso que descubrimos en todos estos pasos precedentes bien insisto tengo mi x tengo mi ahora lo que tengo que hacer Ni más ni menos como dice Este título aquí es crear nuestro modelo de red neuronal en este caso red neuronal recurrente vamos a recurrir a sequential que ustedes saben que es este el método que usamos la cas que usamos de tensor flow para ir poniendo o definiendo cada una de las eh capas de la red que vamos a crear de manera secuencial bien la primer capa es una capa de eding Sí qué es lo que va a hacer Bueno lo que ya sabemos es transformar todo este conjunto de vectores de 29 posiciones en embeddings por lo tanto lo que tengo que darle como información es cuál es el tamaño de mi vocabulario las 400 y pico de palabras y con 200 le digo el tamaño de los vectores en los que yo quiero que haga los embeddings Recuerden que los vectores que tengo son de 29 posiciones pero con 29 posiciones no vamos a hacer un embedding porque eso obviamente no tiene que ver con el sistema de similitud que vimos en las clases pasadas Por ende defino que quiero eh vectores de 200 posiciones que igual fíjense recuerden siempre que 200 es mucho menor que la cantidad de palabras o sea es la mitad o sea que eso Si volvemos a a sistemas más viejo como el conteo de palabras obviamente tenemos vectores de 400 y pico de posiciones en este caso son 200 las que elijo y luego le indico de todo lo que tiene que ver lo que va a entrar De qué tamaño es o el input lens sí los textos que van a entrar estas secuencias que están numéricas que representan los textos que van a entrar De cuántos son bueno de un largo igual al máximo 29 men1 porque acuérdense que la etiqueta no va a entrar en este caso sí bien Entonces luego lo que hago es agregar una capa de tipo lstm y bidireccional dos conceptos que vimos en la primera parte de esta clase lo defino con 150 neuronas y finalmente voy a hacer una capa de salida de tipo softmax por qué porque acá no tengo que hacer un problema de clasificación de cer o uno si es es sarcástico o no sarcástico acá lo que tengo que decir es cuál de las 400 y pico de palabras voy a dejar de ser y pico y voy a decir el número que corresponde para ser lo más preciso posible 442 palabras Cuál de las 442 palabras sí es la que debería seguirle a la que bueno forma parte del texto que vengo escribiendo por ello la función de activación de la capa de salida tiene que ser sof Max porque tengo 442 posibles resultados de salida y luego hacemos el sumary para ver justamente el modelo completo como lo vemos habitualmente y bueno dicho Todo esto lo ejecutamos bien allí tenemos el sumar o el resumen de lo que es la composición de la red que acabamos de crear y lo que vamos a hacer ahora es como siempre hacer la compilación y el entrenamiento bien allí terminó el entrenamiento 200 os bastante para que a pesar de que es un texto muy cortito trate de tener un proceso de aprendizaje importante y lo que vamos a hacer es graficar vos aquí que la curac es de 097 es muy bueno vamos a graficar la curva justamente de aprendizaje que es que está aquí donde vemos justamente como ha crecido y Que obviamente en los entrenamientos ya prácticamente de el 25 en adelante si ya la evolución fue muy poquita es decir que ya la mayor parte del aprendizaje la obtenido justamente hasta epoch 25 vemos cuando lo recorremos aquí que ya es así O sea inclusive en algunos casos como en el 146 ha sido superior al final bueno Esto nos puede llegar a entender que Obviamente el número de epos ha sido más que suficiente desde antes de los 200 que yo le puse bien lo que vamos a hacer ahora finalmente es generar el texto con nuestro modelo con lo cual la frase inicial va a ser lleva la pelota Sí y le vamos a pedir que eh haga 20 palabras luego de la palabra pelota que sugiera 20 palabras luego de la palabra pelota teniendo como referencia el entrenamiento hecho con el Corpus que yo le pasé bien Lo que vamos a hacer con esto es eh for una variable cuando usamos el el ión acuérdense que no voy a crear ninguna variable esto para iterar Tantas veces como nextwork o sea va a ir agregando 20 palabras y Esto va a iterar 20 veces en cada una de esas iteraciones lo que va a hacer es tomar la frase inicial Y tokenizar sí para que esté en la misma sintonía que eh toda la lo que hemos entrenado y lo ponemos dentro de tois Y qué vamos a hacer al igual que como hicimos con el Corpus original padar sí es decir agregarle con ceros completar con ceros para que tenga el mismo régimen sí que tienen los vectores del Corpus original es decir los 29 - 1 bien con los ceros puestos adelante Bueno lo que ya vimos anteriormente que hicimos con las secuencias del Corpus original lo mismo con este pequeño texto que lleva la pelota tiene que estar en la misma sintonía una vez que hago esto lo que hago es con predict de model acuérdense que ese modelo que creamos recién darle como como input el token list Sí y decirle Cuál de todas las predicciones es la mayor Sí con eso ar Max y lo pongo dentro de predict sí es decir cuál es la palabra más eh que tiene el mejor score o la que tiene la sugerencia más alta para poder justamente este ser la adecuada para continuar en este caso a la palabra pelota pero esto Va a continuar con lo cual va a ser la palabra la mejor palabra que continúa pelota y después si esa palabra fuera eh el jugador o el él puntualmente sí Cuál es la palabra ideal que va a seguir a él puede ser jugador Cuál es la palabra ideal que va a seguir a jugador Y así sucesivamente pero acá hay un tema muy importante que tenemos que ver bien Qué tiene predicted tiene la palabra sugerida por este algoritmo como que debería ser la más conveniente para seguir la frase desde la palabra pelota no en realidad tiene un número sí Recuerden que lo que me da Aquí vamos al modelo nuevamente la capa densa de salida es una softmax que tenía tantas posiciones como el vocabulario como el tamaño de vocabulario Está bien entonces solros recordemos que el tamaño vocabulario que teníamos era de 442 palabras Entonces qué Me da me da algo como lo que teníamos aquí cuando vimos el tema de las etiquetas Es decir me va a poner un número en una determinada posición si entonces lo que yo tengo que tomar a partir de allí es cuál es ese número y luego Recuerden que tengo un índice donde cada número está asociado a una palabra Por eso voy a crear una variable output Word que va a ser la palabra definitiva que me sugiere este algoritmo y voy a recorrer sí completamente el Word Index es decir el dice de palabras y justamente voy a estar comparando el número obtenido con cada uno de esos índices hasta encontrar cuando coincida el número de índice con el valor de la predicción entonces podré acceder a la palabra al texto de la palabra Y esa palabra será la que pondré en esta variable que Acabo de crear con lo cual finalmente voy a tener que la frase inicial es igual a frase inicial en este primer caso lleva la pelota más el output Word que es como el ejemplo que decíamos recién supongamos que la próxima palabra sea lleva de la pelota é Sí con lo cual la próxima frase inicial Qué va a ser lleva la pelota él y la predicción supongamos que sea jugador luego la frase inicial será lleva la pelota el jugador Y así sucesivamente entendido esto bueno ejecutamos el código y vamos a ver qué resultado nos da y vemos que dice aquí lleva la pelota están los pies del habilidoso mediocampista del Pampa Si miran el documento en alguna parte del relato le pone a un equipo lo pone lo pone como Pampa Sí realmente Endo que la Argentina tiene que ver con eso le puso ese nombre así que de allí viene Este no es algo desubicado que lo ponga porque justamente en el relato Pampa es uno de los equipos que usa el relator el medio capita del Pampa Diego el fútbol argentino que viva el fútbol argentino que viva bueno y ahí sigue bueno es bastante Bueno sí el resultado obtenido insisto porque tiene coherencia lo que dice va siguiendo una línea coherente de lo que está Armando aquí como relato a partir insisto de tres palabras y obviamente de un entrenamiento con un Corpus muy chico para hacer un ejercicio más importante yo aquí les dejo lo mismo que hicimos en el ejercicio de la clase pasada Sí donde tomamos 20 libros de recursos humanos con la idea de poder hacer el mismo circuito donde juntábamos todos los documentos sacábamos las salvaciones limpias y toda esta cuestión y lo que vamos a hacer es entrenar sí a nuestro algoritmo con eh ese con ese Corpus sí Pero cuál es el problema aquí en realidad eh hacer Esto va a llevar muchísimo muchísimo tiempo sí muchísimo tiempo para que tenga una idea yo he he pagado a cola para que me deje usar uno de sus de sus gpu sí que es este es el llamado B1 Sí una de las de las GP más poderosas y he tardado tres horas Sí aquí les muestro el entrenamiento hecho un entrenamiento de 50 sí bastante bueno eh conveniente porque fíjense que no es exagerado como el caso recién fíjense que llego a los 95 72 y todos los scors anteriores han sido inferiores a eso o sea que no he hecho entrenamientos de más Este y bueno obviamente obtengo un resultado pero para que ustedes lo puedan usar y no tengan que hacer todo esto lo que yo es he hecho es el guardado Este modelo y le he puesto model rrh h5 h5 es la extensión con que se guardan los modelos que se generan con t Flow y con model save guardo ese modelo esto lo hemos visto en algunas clases pasadas Sí con lo cual ahora lo que yo debería hacer sería poder justamente usar un modelo pero en lugar de crearlo entrenarlo como está aquí sí lo que voy a hacer va va a hac recurrir a ese modelo por eso acá al final dice utilizar el modelo guardado Sí y Bueno les muestro cómo sería todo el ciclo que tendría que hacer mucho más cortito que toda el anterior para usar ese modelo justamente lo levanto de aquí esto yo se los voy a dejar en el campo virtual por supuesto y acá les sugiero que lo que deberíamos hacer deberíamos hacer todos los pasos desde el principio hasta la creación del modelo o sea evitar el paso que es de crear el modelo de compilar y de entrenar y de guardar sí es decir vamos un poquito hacia atrás yo debería hacer todo hasta este punto Sí o sea este punto no lo voy a hacer este punto tampoco menos que menos porque es el de entrenamiento sí Y obviamente grabar no tiene sentido Porque yo lo estoy tomando de algo está grabado ya luego de esta recomendación vamos aquí abajo y ejecutamos sí esto y nos da este resultado es las eh Perdón la frase inicial es las habilidades intelectuales y acá está la frase que dice las habilidades intelectuales se refieren al saber hacer entre otras palabras son el conocimiento en acción laboral que puede ser desarrollado a través bueno Y esto ustedes también pueden jugar un poquito en ponerle este valor de next Wars en un valor más grande para que genere una frase obviamente mucho más Este mucho más desarrollada no tan cortita un detalle no menor que les dejo también este aquí para que intenten a ver si por ahí con su computadora que tienen sin comprar gpu de de Google de colap este pueden llegar a hacerlo es la posibilidad fíjense que aquí le pongo un break Sí en en esto que hemos hecho aquí de ir tomando los 10 libros de recursos humanos para que tome solamente el primero por allí tomando solamente el primer libro bueno pueda ser más factible lograr un entrenamiento con un tiempo prudencial al que ustedes puedan recurrir Obviamente que aquí ustedes pueden dejar esto andando mucho tiempo y si logran que luego del entrenamiento ustedes Bueno se desatienden de la computadora por decir de alguna manera Este pero se ejecute esta instrucción y esto lo colocan en el Drive Sí bueno si Por ende o por un motivo u otro la conexión se cae la la sesión de cola se cae no va a haber problema porque Ed ya habrán guardado este archivo dentro de su propio Drive Y bueno ya está tranquilo que el día de mañana este cuando ven vuelvan a reiniciar la sesión podrán recurrir a este modelo porque lo tienen en su propio Drive a pesar de que cuando terminó esto y cuando se terminó y se grabó y después se desconectó porque quedó la máquina sin uso como hace Cola habitualmente con Estos espacios este no van a perder el modelo y van a poder volver a levantarlo justamente con esta esta parte que yo les he dejado aquí de utilizar el modulo guardado Sí así que ya sea este modelo que yo les doy o bien otro que generen ustedes con un Corpus propio que puede ser este libro u otro no este pueden asegurarse que pueden darle la posibilidad de dar muchos entrenamientos que dure mucho pero que ustedes no estén pendientes de Cuándo se termina para que no pierdan el modelo Una vez que se les terminó la sesión de cola Bueno hasta aquí llegamos con esta clase muy larga nos vemos en la próxima clase Hemos llegado al final de esta clase nos vemos en la próxima  clase