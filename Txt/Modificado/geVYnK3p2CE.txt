Hola bienvenidos al curso de Inteligencia artificial de ifes esta es la primera parte de la clase número    29  Hola a todos Bienvenidos a la clase número 29 del curso de Inteligencia artificial de ies continuamos con el módulo de procesamiento del lenguaje natural y el tema en cuestión hoy es l Chain con concretamente Qué es Lan Chain Por qué deberíamos usarlo y cómo funciona vamos a empezar a dar respuestas a cada una de estas preguntas Lan Chain es un framework de tipo Open source que les permite a los desarrolladores que trabajan con ia combinar grandes modelos de lenguaje como gpt 4 con fuentes externas de computación y de datos el marco Se ofrece actualmente como un paquete de python o javascript o typescript para ser específicos en este contexto en nuestro caso nos centraremos como venimos haciendolo al principio de este curso con python para comprender Qué necesidad satisface Line Chain echemos un vistazo a un ejemplo práctico a estas alturas todos sabemos que ya gpt o gpt 4 tiene un conocimiento general impresionante podemos preguntarle sobre casi cualquier cosa y vamos a obtener una respuesta bastante buena supongamos que queremos saber algo específicamente a partir de nuestros propios datos es decir a partir de de nuestro propio documento podría ser un libro un archivo PDF un Word etcétera etcétera plan change nos permite conectar un modelo de lenguaje grande como gpt 4 a nuestra propia fuente de datos no estamos hablando aquí de pegar un fragmento de un documento de texto en el mensaje de chat gpt estamos hablando de hacer referencia a una base de datos completa llena de nuestros propios datos y no solo eso una vez que obtengamos la información que necesitamos podemos hacer que l change nos ayude a tomar la acción que que debemos realizar por ejemplo enviando un correo electrónico con alguna información específica y la forma de hacerlo es muy similar a la que hemos venido aplicando hasta aquí esto es tomar el documento al que deseamos hacer referencia en nuestro modelo de lenguaje luego lo dividimos en fragmentos más pequeños y hacemos los embedding los cuales los vamos a terminar almacenando en una base de datos vectorial esto Ahora nos permite crear aplicaciones de modelo de lenguaje que siguen un proceso general un usuario hace una pregunta inicial luego esta pregunta se envía al modelo de lenguaje y se utiliza una representación vectorial de esa pregunta para realizar una búsqueda de similitud en la base de datos vectorial esto nos permite recuperar los fragmentos de información relevantes de la base de datos vectorial y enviarlos también al modelo de lenguaje ahora el modelo de lenguaje tiene tanto la pregunta inicial como la información relevante de la base de datos vectorial y por tanto es capaz de dar una respuesta o realizar una acción l change ayuda a crear aplicaciones que sigue un proceso como este y en base a las dos capacidades mencionadas nos permite pensar en una cantidad infinita de casos de uso práctico todo lo que implic asistencia personal será enorme puede tener un gran modelo de idioma para reservar vuelos transferir dinero y hasta para pagar impuestos ahora emos las implicaciones para estudiar y aprender cosas nuevas puede tener un modelo de lenguaje grande hacer referencia a un programa de estudios complejos y ayudarnos a aprender el material lo más rápido posible la codificación el análisis de datos las ciencias de datos todo se verá afectado Por esto una de las aplicaciones que se consideran más relevantes es el poder conectar grandes modelos de lenguaje con datos existentes de la empresa como datos de clientes datos de marketing u otros es muy probable que vayamos a ver un progreso exponencial en el análisis y ciencia de datos nuestra capacidad para conectar los grandes modelos de lenguaje con apis avanzadas como la de meta o la de Google realmente hará que las cosas despeguen significativamente la principal propuesta de valor de l Chain se puede dividir en tres conceptos principales Contamos con los contenedores llm que nos permiten conectarnos a modelos de lenguajes Grandes como gpt 4 o los de hing Face las plantillas de mensajes nos permiten evitar tener que codificar el texto que es la entrada a los llm luego tenemos índices que nos permitirán extraer información relevante para los llm las cadenas que nos permiten combinar varios componentes para resolver una tarea específica y crear una aplicación llm completa y finalmente tenemos y algo muy importante que vamos a ver más adelante los agentes que permiten al llm interactuar con apis  externas expuesto todo lo que es la introducción a unchain vamos a tomar este gráfico que está aquí como referencia dado que ahora en el lab vamos a identificar cada uno de estos componentes codificándolas con python y las librerías obviamente de l Chain antes de empezar con la aplicación concretamente en el ámbito de colap tenemos que ver algunas cuestiones de environment de contexto y concretamente tenemos que usar la Api de chat gpt para todo lo que tenemos que hacer y también tenemos que usar la Api de pinec que es una una de las tantas es la que vamos a elegir nosotros base para guardar los embedding de los vectores que vayamos generando en estos prácticos vamos a ver por qué el tema de python y cuál es la No solamente la utilidad sino la importancia de guardar estos vectores allí pero vamos a centrarnos primero en la la Api de openi y vamos aquí tenemos la la página open.com en la cual vamos a incorporarnos con login eh yo voy a entrar rápido porquees ya estoy logueado y yo ya he hecho la registración Pero obviamente lo que van a tener que hacer ustedes poner un uso de contraseña o bien entrar con la contraseña de Google que es lo más usual bien una vez que estamos aquí tengo chat gpt que entraría a usar el chat gpt como un corriente o la Api nosotros vamos a entrar a Api y aquí tenemos en principio sí esta esta apik esta opción apik hago clic aquí y haciendo clic en este botón puedo crear una nueva eh clave para usar mi apq una Secret key obviamente ya la he creado eh tiene para ponerle un nombre y obviamente la la apik me la sugiere en este caso Open y bueno obviamente ya la puedo cambiar eliminar Pero obviamente la voy a ver parcialmente pero puedo entrar a ver obviamente la la la la apik que corresponda está codificada aquí obviamente para que no la pueda ver suar cualquier persona por una cuestión de seguridad pero cada uno de ustedes la podrá tomar y vamos a ver que la vamos a tener que pegar ya vamos a ver en el co paso seguido vamos a ir a settings para bueno hacer lo más doloroso que es justamente el pago Sí en Billings sí tengo todas las cuestiones que tienen que ver con el aquí yo ven que tengo 8.85 pendientes porque he hecho una compra de $ todavía tengo ese saldo a favor y aquí tengo en principio el p metods que Obviamente le ponen lo que edes ya saben Sí el número de la la tarjeta de crédito o el nombre de ustedes o como si fueran hacer cualquier compra usual común y corriente y eh si quieren ver los precios pueden entrar aquí a pricing lo cual me va a llevar a esta web que tenemos aquí donde tengo todos los precios de todos los productos que tiene eh open hay y puntualmente este vamos encabezando los ya gpt pero no es el único ya vamos a ver aquí tengo gpt 4 turbo el cual depende del modelo que vas a usar es el costo en este caso Más allá de eso el costo es coincidente en otros casos no bien en principio tengo un valor para acciones de input como sería escribir una una pregunta o pedirle algo y otro para el output que sería la respuesta siempre es más caro el valor del output que el valor del input esto se cotiza esto es 0.01 cada 1000 ST Y en este caso lo mismo 0.03 cada 1000 tokens Aquí tengo inclusive una calculadora para poder estimarlo Igual vamos a poner un código dentro del cola para poder hacer con gpt 4 lo mismo los valores no cambian Perdón son un poquito más caros Sí aquí estoy viendo 003 versus 001 006 versus 003 Sí el caso en este caso el triple en este caso el doble si aquí fíjense que entre los modelos hay diferencia dentro gpt 4 gpt 3.5 Turbo es el mucho más barato muchísimo más barato fíjense que ya 0.001 cuando al principio tenía 0.01 y en este caso 0.03 bien obviamente en la medida que el modelo es menos avanzado Obviamente el costo es menor no bien luego tengo otros productos como asistentes Sí para bueno con retriable cor interpret perdón y retriable que ya vamos a ver son acciones que vamos a ver más adelante luego para para tuneo de modelos para los embeddings a b2 que también lo vamos a usar porque es parte de toda la práctica que vamos a hacer con el L change eh los modelos base d Vinci es uno de los que vamos a usar también y después tenemos otro tipo de productos que en este caso no vamos a usar Dali que son los productos que generan imágenes no es el caso lo que vamos a ver nosotros pero si los modelos de audio whisper y tts whisper lo vamos a usar para convertir un audio en texto y tts para lo contrario todos tienen Su costo obviamente bien aclarado esto esto lo que van a tener que hacer obviamente es hacer el pago como corresponde y van a tener habilitado a partir de allí el uso a través de la piki si ustedes usan la piqui pero no han pagado evidentemente les va a dar un error porque tien una piqui para Acceder al lpi pero la Api no tiene el pago para poder generar la acción que ustedes le están pidiendo y finalmente el pinec que aquí obviamente e lo puedo hacer clic en login para poder entrar y este servicio es totalmente gratuito Sí así que no no hay ningún tipo de inconveniente en poder poder este usar este producto a diferencia del de recién porque bueno es totalmente abierto y gratuito bueno acá estoy dentro de pyon hagan caso miso esto porque ya tengo un índice creado una base de datos de índices creados Así que eso en principio no lo encontrarían si cuando ustedes ingresen Aquí van a tener aquí a apik al igual que lo que hicimos recién en chpt Pero obviamente en Open perdón pero sin mediar cuestiones de de precio en este caso lo que voy a tener que hacer simplemente es crear mi piqui con este botón de aquí yo ya la tengo creada le he puesto primera y eh obviamente la la piqui es esta que aparece aquí este con este bueno estos símbolos que ocultan el valor sí estos numeral Perdón estos asteriscos eh Y con este botón la puedo mostrar Sí con esta la voo ocultar y con este botón la puedo copiar para pegarla en lo que vamos a hacer a continuación bien aclarado todo esto vamos a ver algo muy importante un pasito más antes de ir al colat que es cómo generar un archivo para guardar toda esta información de este environment lo próximo entonces que tenemos que hacer es crear un archivo con el bloc de nota cualquier editor de textos que se llame punto m como Ven aquí arriba pun enb de envir Y sí por favor muy importante no equivocarse en la representación de estos tres valores en el nombre de cada uno de estos parámetros Open apik pyon apik y Pon m porque si no obviamente van a tener un error qué datos van a poner allí los que tienen que ver con lo que vimos recién en principio la apik que la van a recoger de aquí cuando creen la picki de Open Ai es lo que van a poner en la parte de el primer parámetro de este archivo es decir esto que está aquí eso sería la información que ustedes tienen que poner entre comillas luego vamos a pycon y acá tengo dos datos en principio la apik que dijimos que la podemos visualizar con esto y luego el nombre del environment por eso cuando ustedes van el archivo de nuevo punto m ven que los datos que piden son la apik que tienen que ponerla aquí entre comillas y el nombre del envir también aquí entre comillas este archivo lo guardan Y luego sí lo vamos a tener que poner en nuestro Drive para poder levantarlo desde el cola Así que eso es todo lo pueden hacer en cualquier parte de su computador siempre después teniendo presente de moverlo hacia el espacio de Drive que es el que vamos a usar para poner todos nuestros archivos como venimos haciendo habitualmente con nuestros cols bien habiendo abordado toda la teoría introductoria y todas las cuestiones de configuración de entorno vamos a empezar con nuestro primer lab de cola la pln 9 en este caso donde vamos a ver como dice el título aquí los componentes principales de lunch de la primer parte después en la segunda parte de esta clase Vamos a continuar con el resto en principio lo que tenemos que hacer es importar las librerías pero más que importar primero tenemos que instalar todas estas aplicaciones open lch token que nos va a ayudar a poder calcular eh digamos todo lo que sera la tokenización que nos va a cobrar obviamente eh Open e kpt antes de hacerla para tener justamente la seguridad de que vamos a tener primero que tenemos saldo para hacerlo y después si estamos dispuestos a asumir ese costo luego pycon que es lo que vimos recién y python DM que es lo que nos va a permitir levantar el entorno esc el archivo que hicimos recién justamente para poder tener configuradas las apik tanto de Open Ai como la de pyon así que instalamos todo esto nos va a llevar un tiempito muy importante antes de empezar no olvidarse en este caso es muy importante conectarse con este Bueno un gpu de colap y no Simplemente con cpu porque muchas de estas cosas no van a funcionar Así que empezamos por Instalar todo esto que está aquí bien luego vamos a mostrar con show Line change la versión de Line change esto es muy importante porque es un software de Última Generación Que obviamente eh Está sacando versiones permanentemente Así que es muy importante en este momento Esta es la versión que vamos a usar que ustedes puedan constatar con cuál de todas las versiones de l change están trabajando bien paso seguido vamos a crear las variables de entorno esto les recuerdo aquí las este bueno las URL de cada una de las plataformas tanto la de la apik de openi como la de pycon Sí y bueno Y aquí si ustedes quieren dejar nota digamos de cada uno de los datos que tienen en el archivo que reci creamos con el punto m también lo pueden hacer aquí a título de dato para que justamente lo tengan siempre a mano bien dicho Todo esto lo que tengo que hacer ahora es montar el Drive para justamente ir a buscar entre otras cosas ese archivo punem que acabamos de colocar Así que montamos el drive y lo hacemos como habitualmente nos manejamos con esto bien allí terminamos de montar el drive y ahora vamos a importar os y DM para justamente hacer esta cuestión de levantar ar ese archivo que tiene el environment del cual habíamos hablado antes así que hacemos clic aquí y luego con loa DM donde voy a buscar en content drive mydrive y en el particular yo tengo este punto m dentro de archivos nlp así que de allí lo voy a levantar y luego con os en vinom and get Open ap key lo que voy a poder ver por pantalla a ver si me responde con la Api que yo sé que tengo entonces de esa manera me doy cuenta de que justamente estoy conectado como corresponde ahí La respuesta es positiva con lo cual quiere decir que yo ya estoy debidamente conectado y puedo empezar a utilizar Esta bueno esta este servicio de Open sí lo primero que vamos a ver aquí recurriendo a este imagen que teníamos en la teoría es el tema de los modelos Sí en principio vamos a ver el modelo llm y luego el modelo chat Sí en ese caso van a ver que son dos sistemas diferentes que tienen que ver con los tipos de servicios que nos da el tipo de modelos que nos brindan Open Así que empecemos por lo primero vamos a ver el Last model que saben ustedes que significa llm y vamos a usar el gpt 3.5 Turbo que es el que veíamos hace un rato sí bien para ello voy a frine change llms voy a importar Open a y allí voy a llamar justamente a la clase Open Ai le voy a dar el model name text inch 003 que es el que vimos recién cuando entramos a el detalle de los precios y voy a trabajar con la el Max tokens en 1024 que es lo que tiene configurado por defecto eh chat gpt y temperatura 0.7 temperatura es un parámetro que va de c a 2 y tiene que ver en principio Si queremos una respuesta que sea más precisa Más estructurada o más libre o más creativa Por decirlo de algún modo sí bien aquí tenemos eh e también la posibilidad de además de trabajar con text Vinci también con gpt 3.5 Turbo bueno Estos son elementos este opcionales y por eso aparecen justamente en la lista de productos que tienen en el detalle de precios eh Open Ai así que bueno en este caso vamos a usar el primero de ellos pero en realidad ustedes pueden usar el modelo que quieran Sabiendo de que en algunos casos puede que un modelo se ajuste mejor a una cosa u otra bien entonces creamos eh esta variable gpt3 que va a ser una instancia de Open con todas estas características que hemos mencionado recién bien y ahí tengo ya la instancia creada y ahora lo que voy a hacer es darle un prompt en este caso explíqueme que ch gpt a esta variable que Acabo de crear y voy a poner la respuesta en una variable que he dado en poner la  respuesta bien a partir de esto yo puedo hacer un print de la vara de respuesta para ver qué fue lo que me dio justamente como respuesta y aquí dice claramente chat gpt Es una herramienta de chatbot basada en procesamiento el lenguaje natural nlp que permite a los usuarios bueno bla bla bla bla bla bueno todo esto que está aquí es la respuesta que yo he logrado me de chat gpt a través de Eh bueno ahora python y toda esta este uso de esta librería lunch Sí es lo que habitualmente escribo a través de un prom el mismo entorno de hept ahora lo hago desde el entorno de colap mediante python y mediante la librería lch bien en este caso podemos ver que puedo pedirle que me dé la cantidad de tokens que corresponden a explíqueme que es un chat gpt y la cantidad de tokens que me da la respuesta entonces de este modo yo puedo darme cuenta que tengo ocho para uno y 149 para el otro y empezar a hacer este tema de los cálculos Sí porque en este caso le hice una pregunta de ocho tokens y una respuesta de 149 Y eso va a tener un costo bien aquí tenemos una referencia del costo de acuerdo al modelo que yo he utilizado Sí el d Vinci o el gpt 5 Turbo Pero obviamente ustedes tien que tener claro que esta referencia que está aquí no corresponde si uso gpt 4 por ejemplo sí bien en este caso yo he utilizado eh Tex davinci 003 y no gpt 3.5 turo porque hay una cosa muy importante que yo aquí se las he dejado Como comentario que en realidad la alternativa de gpt 3.5 Turbo hubiese funcionado bien con esta pregunta ahora si yo Quiero una no una pregunta sino un conjunto de preguntas un conjunto de pedidos digamos ag gpt El problema es que ese modelo No tolera eso y Por ende el que tolera tanto una pregunta o más o un prom o más es text vinch 003 bien Así que en este caso fíjense que lo que voy a poner es gpt3 generate sí no como aquí que directamente le ponía la pregunta sino gpt3 generate y le voy a mandar tres cosas que le voy a pedir a ch alunas pueden ser preguntas a otr pueden ser que me explique algo o me un detalle en el primer caso le pregunto Cuál es el equipo de fútbol más famoso del mundo en el segundo caso le digo que me explique brevemente la ley de la gravedad y en el tercer caso que me describa Cuáles son los tres pasos que yo debería seguir para hacer un dinamis no es son tres pasos más bueno eso le pedí que me lo haga tres sí en este caso insisto uso el método generate porque le estoy mandando tres proms y no uno y recuerden estoy usando el modelo text vin que es el que soporta eso lo ejecutamos y voy a tener ahora las respuestas en la variable de respuestas y la var de respuestas va a ser justamente una Ray con tres respuestas ya que le he hecho t entonces Si miro la primera respuesta 00 me va a decir que el equipo más famoso del mundo es el Real Madrid y bueno si quiero ver las tres voy a hacer un for y voy a recorrer en lugar de la 00 la i0 cambiándole el I de cer hasta el tercer punto que sería el número dos Sí así que hago el for y voy a ver en este caso la respuesta o las tres respuestas el equipo de fútbol más famoso del mundo Real Madrid la ley de la gravedad una ley física y me da los tres pasos de cómo hacer un tiramizu bien hasta aquí llegamos con lo que hemos usado como modelos de tipo llm ahora vamos a usar otro tipo de modelo que son los modelos de tipo chat por eso 1. modelos chat modelos de tipo chat perd Aquí vamos a usar lch esquema y L chat models y en el primer caso voy a importar tres elementos para el esquema que sería el Im human y el System Y luego el chat Open que va a ser la librea que voy instanciar para poder hacer esta tarea que me propesto hacer bien ejecutamos esta celda y luego vamos a hacer una instancia de chat Open Ai para colocarlo dentro de la variable chat chat Open Ai con el modelo gpt 3.5 Turbo y una temperatura de 05 y Max token el 1024 vamos a esperar que termine de cargar la librería ahora creamos la instancia y ahora en este antes de pasar al siguiente cela quiero volver a dejar en claro el tema de la el concepto de temperatura en este caso 05 quiere decir una propuesta más conservadora acuérdense que si es mayor a uno habíamos dicho que es una propuesta más creativa no tan ajustada a la mayor probabilidad que de lo que sería la respuesta correcta H estadísticamente correcta para lo que nosotros le pidamos en este caso sería algo más eh Le estoy pidiendo algo más cercano a la realidad a la mayor probabilidad de una respuesta ajustada y si es mayor a uno insisto es algo entre uno y dos que tenga que ver con una respuesta más creativa bien en este caso vamos a usar el el System message y el human message y vamos a ver cómo responde a lo que nosotros hacemos habitualmente con chat gpt si nosotros muchas veces le pedimos que nos de una respuesta marcándole un contexto y es lo que estamos haciendo aquí fíjense que le decimos con sistem mesis eres un experto en educación y luego con human mesis el pedido concreto bien Por ende esos dos elementos los vamos a poner dentro de una Ray messages y messages es lo que le voy a mandar a chat para que me dé la respuesta Así que lo ejecutamos y vamos a imprimir luego el resultado con RT chat. content que es obviamente donde va a estar alojada la respuesta esto que estoy pidiéndole Aquí bien allí terminó y ahora vamos a imprimir el contenido para ver justamente qué es lo que me generó y aquí me dice Cuáles son las cinco opciones que considera excelentes para incorporar la ia como una herramienta de enseñanza en el colegio y me pasa Bueno un un detalle de esa respuesta bien bien con esto tenemos entonces un introducción hacia lo que es el uso de los modelos de llm y de los modelos de chat que me ofrece Open en la segunda parte de esta clase vamos a ver los otros componentes de l change o que ofrece justamente l change hasta aquí llegamos con la primera parte de esta clase nos vemos en la segunda parte i