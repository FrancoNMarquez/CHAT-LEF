 Titulo: Clase 29 (parte 2) Curso Inteligencia Artificial 
 URL https://youtu.be/Ehw9F3Mi9QI  
 1930 segundos de duracion 
 Esta es la segunda parte de la clase número 29 te invito a empezar con    ella  bien aquí estamos entonces para continuar con lo que hicimos en la primera parte de esta clase en esta segunda parte de la clase componentes principales de lch Par para continuar con lo que estábamos haciendo dado que son dos colap diferentes vamos a tener que repetir algunos pasos de preconfigured esta clase Por eso tenemos que importar las librerías como lo hicimos antes Tenemos que montar el Drive como lo hicimos antes y tenemos que hacer todas las configuraciones de entorno hasta levantar la piqui como lo hicimos antes a partir de allí ya empezamos entonces con el primer tema de eh esta segunda parte y volvemos a este gráfico inicial para justamente entender en este contexto este gráfico que lo que vamos a abordar es otro concepto importante de lanch que son las plantillas de prom bien volvemos aquí el entorno de colap y Por ende vamos a empezar por importar prom template de l Chain que es justamente la librea que vamos a usar en este caso en el caso del template básicamente es una plantilla que me va a permitir darle un prom pero con algunas variables por eso se llama un template de proms eh voy a escribir un template poniéndole una frase que es lo que yo le quiero pedir a gpt pero poniéndole una dos tres la cantidad de variables que yo quiera poner en este caso quiero que chpt me escriba un mensaje de felicitación para alguien de acuerdo a un evento Pero considerando la posibilidad de que ese alguien sea un elemento variable y que el evento también u ocasión sea un elemento variable Por eso yo pongo en el template entre comillas escribe un mensaje de felicitación para Y con estas llaves la palabra nombre que sería el nombre de esa variable de el nombre de la variable nombre abundancia en su y entre llaves nuevamente el nombre de la otra variable que sería ocasión bien con lo cual este template va a tener dos variables Por ende lo ejecutamos para que quede cargada esta variable voy a crear otra variable prom en la que en la cual voy a poner prom template que es lo que yo aquí importé aquí arriba y ahí lo que voy a manejar son dos parámetros en principio input variables Cuáles son las variables de input que van a entrar dentro de ese prom nombre y ón obviamente tiene que llamarse igual a como yo las definí aquí arriba y luego decirle bueno fantástico Esas son las dos variables Pero cuál es el template el template es template Es decir es esta variable y creamos aquí lo que yo pongo aquí bien entonces con esto creo la variable prom Ya tengo la variable template y la variable prom que usó a esa variable template bien Ahora voy a Frontline Chain el lms importar open luego creo una instancia de Open Ai poniéndole al nombre de la variable gb3 se puede llamar como quieran ustedes s con un model name texta V 003 Una temperatura de 07 y la cantidad de tokens de que propio de gpt sí acá dejo dos opciones más para que ustedes puedan cambiar sí en este caso todos las tres opciones siguen el mismo formato respuesta igual a gpt3 y dentro de ello le pongo prom format y dentro de PR format le tengo que poner el nombre de la variable tal cual la definí arriba y un texto que tenga que ver como valor que yo quiero de input para esa variable en el primer caso le pongo nombre Juan ocasión casamiento en el segundo caso Laura ocasión bautismo de su hijo Lucas y en el tercer caso Perdón Laura ocasión ingreso a la empresa presa saa bien Vamos a arrancar con el primero y vamos a ver qué nos responde en la Val la respuesta chpt sí Y nos dice lo siguiente felicidades Laura estamos muy contentos de tenerte con nosotros empresa s estamos seguros de que tu trabajo aquí será un gran éxito bienvenida a la familia bueno si queremos seguir con esto vamos a descomentar la primera y vamos a ver la ocasión de Juan para el casamiento para el casamiento de Juan no bien generamos la respuesta la imprimimos y vemos que ahora dice Felicidades Juan y nombre de la pareja podríamos haberle puesto en este caso una var pero bueno est mu cito la opción de casamiento Que obviamente en losotros Casos no hay una segunda persona en este gran día estamos tan contentos por vosotros dos y deseamos que este sea el principio de una vida de amor bueno etcétera etcétera etcétera Sí y Bueno podemos ver el último caso que es el del bautismo pero digamos no escapa a lo que pasa habitualmente cuando nosotros escribimos algo solamente que en este caso esto lo podría poner en una función y directamente darle la las los n valores de las variables y que vaya generando automáticamente como yo lo estoy haciendo aquí pas paso pero en el contexto de una función bien en este caso imprimimos el resultado y me dice felicidades Laura que la vida de tu hijo Lucas est llena de alegría y bendiciones etcétera etcétera bien con esto Terminamos el concepto de planillas de prom volvemos al gráfico y vemos que tenemos otro concepto que tenemos que ver de lch cadenas justamente el Chain de l Chain es decir las cadenas bien volvemos aquí el cola y vamos a importar toda esta cantidad de librerías HM y Eh bueno lo que vamos a hacer es crear modelos que van a estar Encadenados por eso el concepto de cadena Sí bueno Qué quiere decir esto el modelo de encadenado esto muchas veces nos pasa que yo le pido algo a chat gpt y luego le pido una ampliación una aclaración o algo que tenga que ver con lo que me generó antes sí es esta conversación esta cuestión conversacional que tengo con chat PT por lo tanto vamos a crear un modelo uno en base a Open como lo venimos haciendo y el model name seguimos usando davin bueno Esto es Exactamente igual a lo que vimos hace un rato y voy a escribir un template como lo hicimos hace un rato también poniéndole como variable tema es decir Escríbame los puntos más importantes para un tema x que lo definiré yo a la hora de ejecutar esto luego como hicimos recién también hoy vamos a hacer el prom template le vamos a poner prom 1 donde le pongo que la variable el input variable es tema y el template es template un o sea nada diferente a lo que hicimos aquí arriba sí Solamente que ahora lo vamos a encadenar esa es la gran diferencia Sí con lo cual a cree el modelo uno y voy a crear a partir de esto la cadena uno como con llm change donde le digo Mira esta cadena la vas a armar con un modelo que llama modelo uno y un prom que se llama prom está bien Es decir no me lanzo a hacer esto directamente aquí porque esto terminaba en esta instancia acá es una cadena va a ser una parte de la cadena con lo cual simplemente lo defino con el mismo criterio luego hago lo propio para la segunda parte de la cadena el segundo eslabón de la cadena donde el proceso es exactamente el mismo solamente que tengo que tener en cuenta que el template que yo escriba aquí tiene que tener relación con el template de la cadena anterior Entonces le digo Necesito que me amplíes la explicación sobre el primero de los puntos de puntos esto d va a ser o va a recoger la respuesta de la primer cadena entonces este texto tiene que tener sentido con lo anterior que es exactamente lo mismo que nosotros hacemos en vivo digamos o in situ con chat gpt o sea si yo le pido una respuesta de algo lo que le escribo después le manifiesto de alguna manera que tiene que tener referencia con lo anterior si no va a tener no va a tener base para resolver eso Si Entonces le digo resuelvo de los puntos de lo que me mostró recién una de las consideraciones que o amplíe tal concepto que usted aquí me muestra de manera sintética A qué se refiere con tal cosa Bueno lo que fuere entonces la expresión de Esto va a tener que ver y puntos en este caso que es un nombre Val que voy poner cualquier cosa Va a tener que ver justamente con la respuesta de la cadena un y me va a dar una segunda respuesta en base a lo que yo le escriba acá que necesito que me digamos este Explore o aonde sobre lo que me dio en la cadena anterior obviamente Aquí tengo dos eslabones una cadena cortita le puedo poner todas las cadenas que yo quiera s es decir que esta cuestión de el modelo un el modelo dos puede ha hasta el modelo n para lo cual finalmente voy a con simple secuencia change ponerle con el parámetro change todas las cadenas que formen parte de esta lógica que yo armé en este caso son dos Entonces le pongo entre corchet cadena uno cadena dos y punto si con verbo true acuérdense que siempre lo que hago es tratar de que me muestre el resultado de cada una de las cosas que está haciendo si le pongo false no me va a mostrar esto es bueno para ir seguiendo un poco la lógica de lo que va haciendo bien todo esto lo voy a poner dentro de la variable que le voy a poner cadena completa variable que se puede llamar insisto como ustedes quieran y luego la respuesta la voy a obtener Llamando al método ram de la variable cadena completa y le voy a mandar adentro Qué cosa lo que va a ser el valor de la primera variable es en este caso de tema con lo cual en este caso le digo una campaña de marke de marketing perdón exitosa Cómo se lee Esto escribe los puntos más importantes para una campaña de marketing exitosa se entiende bien Entonces creamos el modelo un Perdón no había cargado las librerías Ahora sí Ahora creamos el modelo un ahora creamos el modelo dos el modelo y la cadena uno el modelo y la cadena dos creamos la cadena completa y ya teniendo esto Busco la respuesta fíjense que la primer parte de la respuesta me la dan un color y la segunda la voy a ver en otro color Aquí están los puntos de lo que le pedí una campaña de marketing exitosa y le pedí luego que me amplíe el primero de los puntos este que dice definir el objetivo de la campaña de marketing sobre eso tiene que versar esta respuesta que está buscando ahora en la segunda cadena bien aquí tien Entonces otro color Está bueno Esto justamente tiene que ver con el verbos que recién estábamos hablando si no solamente me mostraría esta parte de amarillo dice el primer punto que es definir el objetivo de la campaña de marketing es fundamental para que tenga éxito etcétera etcétera etcétera Finish Chain Sí ahí se terminó la cadena Entonces como yo le puse verb true me va a mostrar cada una de las partes si le hubiera puesto insisto verbor frast lo único que me va a mostrar es la última parte que es lo que queda alojado en respuesta bien hasta allí el tema de las cadenas ahora también hay otro concepto muy importante que volvemos al gráfico que tenemos aquí en donde me habla de almacenar los vectores los vectores ustedes saben que son proceso de hacer uno en vez son resultado de hacer un embedding que ya lo hemos hecho mucho en los eh labs anteriores Así que lo que vamos a hacer ahora es lo mismo que hicimos lo que vinimos haciendo en las clases anteriores o sea tomo un texto lo separo lo splite se acuerdan y luego lo que hago es con cada párrafo aún env lo que pasa que antes lo que hacíamos era esto mismo y lo usábamos de inmediato Ahora qué pasa si yo quiero recurrir mañana a eso bueno tenía que grabar el modelo Sí y después volver a a levantarlo no en este caso lo que vamos a hacer es grabar o guardar o almacenar los en vings Entonces de esa manera yo con un modelo que ya no es mío voy a usar el modelo de chat gpt sí voy a usar si los embed que son míos los vectores que son míos y con la vinculación de ambas cosas voy a volver a recuperar lo mismo que vene haciendo hasta ahora sin tener que hacer los pasos previos es decir vuelvo a traer los eddings sí de ese almacén cenamiento y vuelvo a utilizar el modelo de chask PT con mi base de datos representada por mis vectores sí Entonces lo primero que vamos a hacer después vamos a ver cómo recuperamos los vectores es generar estos vectores a partir de separar textos hacerlos en vez y guardarlo En dónde en la otra appi que creamos la otra aplicación de la cual hablamos que es pincon que justamente es una base de datos para vectores bien manos a la Entonces lo primero que tengo que hacer es separar textos para la cual voy a eh volver a configurar el entorno bueno Esto Obviamente si ya vengo de lo anterior no sería necesario lo volvemos a repetir para que quede claro que obviamente es como voy a usar pyon tengo que tener de nuevo conectado el tema de del entorno pero si lo hice antes como entiendo que ya lo hemos hecho aquí arriba si aquí arriba no sería necesario en este caso bien eh luego lo que vamos a hacer es Llamar a eh recursive chac text splitter de l Chain text splitter sí acuerdense que split es el tema de separar Sí ya vamos a ver de qué se A qué se refiere este concepto de recursive charter a esa librería le voy a poner rc porque obiamente es un nombre muy largo entonces me manejo mejor con un alias que va a ser rc lo que voy a hacer voy a abrir un archivo que ya lo usamos antes que es chat gpt txt que es el quea de la historia de chat gpt que lo usamos en clases anteriores para no inventar Nada nuevo con lo cual voy a eh luego de haber eh sumado esta librería voy a abrir este archivo chat gpt txt ya lo tengo abierto lo imprimimos para recordar un poquito de qué se trataba Esto bueno se acuerdan que yo se lo había pedido esto al propio chat gpt que me contara Cómo era la historia de chat gpt y lo pegué en un archivo de tipo txt para empezar a usar bien Ahora lo que voy a crear es una variable text splitter que es una instancia de rc acuérdense que rc es lo que vimos aquí arriba que es recurso char qué es lo que le voy a poner como información primero el chun size Qué quiere decir esto cuando vaya a splitear que lo haga de a 200 caracteres Sí pero también voy a manejar el concepto de chang overlap que le doy un valor 20 que es esta cuestión de que yo no voy a separar todo el texto en 200 de una manera totalmente excluyente los 200 primero van a estar totalmente parado de los 200 segundos sino que lo que va a hacer esta separación es cuando genere el segundo va a tomar los últimos 20 caracteres del primero cuando tome el tercero va a tomar los últimos 20 caracteres del segundo y así sucesivamente Por qué Porque cuando cortemos un texto por una cifra fija es muy probable que perdamos el contexto Qué pasa si ese corte eh ocurrió en el medio de una expresión sí que no había una coma ni un punto Sí hay una cifra fija acá no estamos hablando de una separación por punto ni por coma sino de un valor fijo entonces para que no pierda contexto el siguiente párrafo el siguiente chun lo voy a empezar con algo de lo que venía en el chun anterior Entonces de esa manera queda más enganchado con lo anterior y no queda como dos cosas totalmente separadas que en realidad puede ser la mitad de una frase bien entonces creo el text splitter teniendo en cuenta eso y luego lo que voy a hacer es el splite con Tex expit create documents sobre texto recuerdan que texto es todo este texto este txt que ha hablado de la historia de chas Bueno lo ejecutamos y veo que tengo 218 párrafos con print l de texto tengo 18 sí muestro alguno como suelo hacer habitualmente para que ustedes lo vean agarro el primero textos 1 page content chat gpt es un hito en la evolución etcétera etcétera etcétera textos dos lo mismo m fíjense aquí ven avance de la tecnología y la inteligencia está bien avance de la tecnología y la inteligencia No termina la frase aquí porque en realidad es avance de la tecnología y la Inteligencia artificial fíjense Cómo empieza el segundo con y la Inteligencia artificial se entiende Entonces de esa manera ven que la primer palabra hubiese sido artificial de este segundo Chan pero me trae y la inteligencia Entonces de esa manera lo que yo hago es justamente recuperar parte de lo anterior y no perder tanto contexto bien eh puesto esto como ejemplo lo que vamos a hacer ahora esaro de lo que hablamos recién que es el tema de evaluar Los costos sí bien en este caso hay una función que está creada aquí que hemos creado aquí pero en realidad pues pueden hacerlo con el código sin que esté en el marco una función pero el hecho que est am no funcion es más práctico en el cual voy a usar a tik token que se acuerdan que al principio yo les dije que tiene que ver con esto de poder precalculo de lo que yo voy a hacer en este caso del embedding y voy a usar justamente tick token punto encoding from model Con qué librería de chat gpt voy a usar para hacer los embedding text embedding Ada se acuerdan que Ho cuando vimos el la página web donde aparecían los precios estaba Este modelo de Ada aquí está para que lo recuerden en vez de models Ada Sí y va a valer 0.01 cada 1000 tokens bien entonces ahora lo que hacemos Es ver eh el en o sea lo que voy a hacer este como código HM por cada página de cada uno de los elementos del texto Sí por cada page de cada texto sí y voy a meder el len la cantidad el largo de cada uno para calcular el total de tokens sí de cada una de las páginas de este texto en realidad acuérdense que estos no son páginas sino que son todos estos split que tengo acá sí o sea va iriendo por cada uno de los párrafos Sí en realidad más que paste podría ser eh for este split Pero bueno no importa Este Pace aquí acuérdense que es el nombre de una variable Así que se pueden poner como ustedes quieran y luego voy a hacer un print diciendo Bueno tengo a lo largo de este texto chat.txt la cantidad de 8181 tokens y vamos a ver cuál es el precio entonces lo que hago es llamar esta función print eding cost de textos Si en este caso textos acuérdase que ese archivo que tenemos aquí es esto textos es esto los textos piteados que lo voy a mandar a el evaluador de costo de embedding ejecut Perdón No cargué primero la función Ahora sí lo ejecutamos y tengo que voy a tener como dijimos recién 81 81 tokens y me van a salir 0.0818 o sea muy muy barato ni mucho muchísimo menos que $ sí así que bueno una vez que sé cuál es el precio y lo veo para tenerlo en consideración lo que hago es crear los embeddings O sea que llamo a Open Y embedding sí les dejo aquí un comentario porque justamente lanch no es una biblioteca que solamente va a trabajar con Open Ai hay otra otro tipo de modelo de modelo largo de gran modelo de lenguaje s o seao un llm que se llama justamente haciendo juego este juego de palabra llama como el animal llama es decir que esto que está escrito acá me permitiría usar el modelo liama y no el modelo openi si esto para que tengan presente que no es l change algo que sirva solamente para un uno de los grandes modelos de lenguaje sino que puede ser por más de uno bueno independientemente de eso seguimos nosotros usando Open Ey Así que ejecuto esto y luego voy a crear la variable embeddings haciendo una instancia de Open e y luego voy a vectorizar Sí una una página para que lo vean como ejemplo sí que sería Esto entonces hago embedding query de textos uno o sea no la primer página insisto el primer párrafo s Por decirlo de alguna manera textos un se acuerdan que qué era Era esto que teníamos acá esto si chat gpt unito Bueno esto es texto todo este texto en realidad lo voy a con este con en ve in query voy a transformar en un vector simplemente para que lo veamos s entonces lo que hago es hacer un plint de qué largo tiene ese vector 1536 por 156 esto ser an porque es como yo defino Este modelo cuando lo creo con opening Ese es el valor por defecto que tien los vectores de Open y luego si los valores cuando de vector me muestra los 1536 valores del vector que representa a a el primer párrafo a este que está AC este párrafo que está acá está representado por todo este vector que está acá por justamente con eding y eding es una instancia de Open bien hecho esto lo que vamos a ver ahora cómo voy a insertar todos los en de todos los split de mi texto dentro de pyon Así que vamos al punto 43 que es insertar en en p para eso voy a importar os voy a importar el pycon y voy a importar pycon de Lan Chain vector Store se de nuevo Lan Chain vector Store porque se especifica python porque no es l change una aplicación que solamente va a poder usar un tipo de almacenamiento de vectores hay varios nosotros vamos aar pycon Sí así que bueno importamos estas librerías inicializo python fíjense con python apique y python m que son los elementos que te llan el archivo punto m H que os antes así que inicializo pyon lo que voy a hacer ahora es ver si hay algún índice dentro de Pon y me dice que hay un índice que se llama talum es esta que yo les mostrado hoy que le dije que hicieran caso omiso Esto bueno es una lista que ya está creada es un índice Perdón que ya está creado Sí entonces vuelvo al colap y lo que voy a hacer es borrar ese índice sí Entonces como lo borro en realidad está preparado para borrar todos los índices Sí bueno ejecuto este código que dice Bueno voy a recorrer todos los índices y cada uno de ellos lo voy a hacer un delete entonces ejecuto acá y bueno habré borrado todos los índices sí cosa que puedo corroborar yendo a la aplicación de pyon Ven aquí ya me dice que no tengo ningún índice desapareció el que estaba antes si vuelvo a cola veo que aquí también me dice lo mismo me muestra las las llaves digamos vacías bien Ahora lo que voy a hacer voy a volver a crear un índice sí Y en este caso le voy a poner índice chat gpt Bueno lo ejecutamos y ahí ya me lo de haber creado voy a pycon a ver si me lo creó y allí vemos que me lo ha creado si entro voy a ver que en este caso sí eh No tengo absolutamente todavía ningún vector vector con cero pero ya sé que la dimensión de los vectores que van a entrar aquí van a ser de Dimensión 15 porque provienen de eh lo que es openi bien Ahora vamos a hacer justamente el embedding de todos los vectores de todos los split de mi texto chat gpt txt como con p con Front document diciéndole Qué texto quiero eh vectorizar con cuál eh variable que me referencia en este caso a la que yo he instanciado de aquí arriba de Open a lo voy a hacer con un embedding de Open a y finalmente En qué índice de python lo voy a meter en el índice índice que índice es justamente lo que yo he puesto aquí como nombre de variable podría poner literalmente gpt Pero bueno lo pongo una variable para que sea más Mane bueno Esto va a tomar un tiempito Así que ahora dentro de vector van a estar todos los vectores de todas las partes del texto de ch bueno terminado esto van a ver la siguiente imagen que está aquí que esto es una imagen pegada al colap pero vamos al pyon en la web y veo que aquí esto no es una imagen pegada en el colap sino que es la realidad tengo 18 218 vectores Por qué Porque es justamente la cantidad de vectores en el cual fue splite el texto chat gpt text vamos a buscarlo para salir de Aquí está de acuerdan 218 vectores fue la división que yo hice justamente de ese texto bien entonces con esto ya tenemos Sí nuestra nuestros vectores dentro de esa base de datos con lo cual ahora voy a poder hacer lo que dice aquí el punto 4.4 Perdón que es preguntas de similitud viejo tema que venimos trabajando de las últimas clases pero queremos de alguna manera reflotar aquí teniendo en cuenta que ya no no lo estoy haciendo con eddings que están en memoria sino con embeddings que están en una base de datos para eso se llama pycon bien Vamos con preguntas de similitud esto ya lo hemos visto en muchos lados anteriores en este caso la pregunta cuál es la evolución de chp la voy a poner dentro de una variable pregunta y luego con the vector Store el método similarity Search le voy a poner justamente dentro la pregunta para que me dé la respuesta en respuesta Recuerden que el vector Store es esto que genera aquí es donde están todos los vectores que generé con embeddings y que guardé en python con lo cual ahora esa ese elemento me va a servir justamente para hacer una búsqueda de similitud y la voy a poner en respuesta y luego de eso voy a ver las respuestas Y veo en realidad más que respuestas en donde cuestiones similares o que encuentran similitud con este tipo de preguntas Este es el concepto raíz para empezar a buscar la respuesta fíjense que lo que eh está escrito aquí digamos es indicar En qué partes de todo este texto de estas páginas que en realidad no son páginas son splits sí puede estar la respuesta esa pregunta simplemente una búsqueda de similitud no es la respuesta concretamente como deje recién la respuesta la vamos a encontrar aquí usando el large Language model por eso vamos a utilizar eh vamos a importar perdón retrial qa y chat Open ea como ya lo hemos venido haciendo antes y vamos a crear en principio un large la Wi model con chat opena tomando el modelo gp4 cambiamos un poquito a un modelo mejor más caro y con una temperatura de una luego vamos a crear un retriever el retriever es lo que me va a permitir indagar esa búsqueda en el contexto de la base de datos de vectores de pycon Recuerden que todos esos vectores siguen estando dentro de esta variable vector Store y ese retriever va a tener determinadas configuraciones una de ellas es decirle Qué tipo de búsqueda quiero que haga de similitud y con searchs lo que hace es indicarle que justamente voy a buscar los k3 es decir las tres mejores respuestas y de ellas me voy a quedar con la mejor de todas sí bien eh o mejor dicho hecho modo voy a buscar acuérdense que el K es el el concepto de vecino cercano sí algo que me determina de todo el contexto los tres que están más cerca Qué cantidad de cercas voy a buscar los tres que estén más cerca y de los tres que estén más cerca obviamente me voy a quedar con el mejor vector que va a ser la mejor respuesta para esa pregunta todo eso lo configuro con reter para que después justamente creo un Chain que va a ser lo que la cadena que me va a ejecutar la búsqueda que eh justamente va a llamar al método Front Chain type diciéndole de qué modelo que es este que crea acá en llm y con qué retriever es con el cual voy a hacer esa búsqueda a través de este objeto chine Esto es lo que voy a hacer a continuación no me acuerdo si cargué las librerías las ejecuto todas nuevamente por las dudas para seguir el orden y ahora con Chain ron poniéndole adentro de los paréntesis la pregunta que en este caso lo he hecho de una manera muy prolija creando una variable para algar la pregunta y lo de la pregunta pero esto que está aquí cuándo se lanzó gpt lo podría escribir directamente aquí y voy a poner la respuesta en una var respuesta H lo ejecuto y vamos a ver el contenido de la vara respuesta y me dice que gpt3 se lanzó en junio del 2020 Esto sí ven que es una respuesta deir no es como lo que me pasó antes que me lanzó un montón de valores que representaban los espacios de similitud respecto de eh esta otra pregunta que obviamente era otra pregunta diferente a la de recién en cuanto Cuál eran los vectores que estaban más similares más llegados a eh esa pregunta que yo había hecho aquí aquí lo armó completamente solo determinó automáticamente de eh respecto de esta pregunta Cuál eran los vectores que estaban más cerca eligí eligió tres perdón porque yo le indiqué que elija los tres mejores y de los tres mejores se quedó con el mejor de todos y la mejor respuesta para esa pregunta fue gpt3 se lanzó en junio del 2020 fíjense que en este caso no se olviden de lo que estamos hablando aquí la change a través de gpt me está dando una respuesta No desde la base de datos de chat gpt o de gpt sino desde mi documento Es decir de este texto que está aquí es decir uso chat gpt con mi propia base de datos tema que vamos a profundizar con un caso bien complejo desde la clase que viene así que sin más por esta clase nos vemos en la clase que vi Hemos llegado al final de esta clase nos vemos en la próxima  clase