 Titulo: Clase5 (parte2) Curso de Inteligencia Artificial 
 URL https://youtu.be/SOvyzc_pwoI  
 1681 segundos de duracion 
 Hola [Música] bienvenidos Esta es la segunda parte de la clase número 5 del curso de Inteligencia artificial de ifes en ella veremos el último tema de análisis de datos el web scrapping empecemos [Música] bueno y ahora vamos con el último tema de toda esta serie de clases vinculadas análisis de datos que es web scrapping que es web scrapping bueno todo lo que hemos visto hasta ahora tiene que ver con Data sets que bueno venían de algún origen que estaba a nuestro alcance algo que tiene que ver con datos que provienen de Nuestra Empresa de nuestro proyecto datos que provienen de sitios públicos que nos dan la posibilidad Como cada árbol por ejemplo de brindarnos Data hechos que nos permiten entrenar algunos modelos y empezar a ver también cómo adaptarlos a la necesidad nuestra vimos todo tipo de operaciones que podíamos hacer con ellos para que tengan la forma que nosotros queremos que tengan Pero hay otra situación que es la posibilidad de aprovechar la gran cantidad de sitios web que manejan un cúmulo de información muy importante para nosotros es fundamentalmente que tienen un alto impacto en la comunidad por ejemplo los sitios de venta de cualquier tipo de artículos Como por ejemplo MercadoLibre bueno tipo de sitios tienen una información muy importante que nosotros no podemos tenerla en un formato de un archivo csv salvo que alguien lo haya hecho por nosotros pero digamos en primera intención ese tipo de páginas no nos dan un Data hacer porque es información Privada de ellas por supuesto Pero hay técnicas hay metodologías y hay librerías de python que justamente nos permiten Esta técnica de web scrapping tomar información de su sitio web y poder bueno lograr tener un formato de información que sea más amigable sí o más adaptable a nuestras necesidades en virtud de lograr un modelo bien Esta técnica la vamos a empezar a ver tomando como ejemplo justamente el sitio de MercadoLibre vamos a él y voy a poner aquí por ejemplo la búsqueda de zapatillas Sí bueno como siempre como cualquiera nosotros hace habitualmente pongo la palabra hago buscar y vamos a mirar aquí arriba Cuál es la url que escribe para esto sí Más allá de que aparece obviamente la búsqueda de las zapatillas veo que lo que escribe acá arriba es la denominación oficial del sitio más la palabra de búsqueda que yo puse zapatillas un numeral una letra de mayúscula y luego entre corchetes y luego de una y dos puntos vuelve a repetir la palabra de búsqueda que yo puse vamos a complicar un poquito El ejemplo Y en lugar de poner una palabra vamos a poner dos palabras Te voy a poner zapatillas deportivas y vamos a ver qué pasa con esa URL la URL ahora lo que hace es poner la expresión que yo puse Donde antes ponía solamente zapatillas pone la expresión pero como está conformado por dos palabras no por una pone un guión en el medio es decir que reemplaza este espacio en blanco por un guión y luego aquí en la otra parte donde repetía la palabra de búsqueda hace lo mismo pero lo hace con digamos deja el elemento natural que es el separador pero lo reemplazan por un porcentaje 20 en realidad esto si yo me tomase el trabajo de pararme aquí y Borrar esos elementos y poner la descripción en el formato natural que yo puse en la llave de búsqueda ven que está el espacio aquí en el medio le doy enter y fíjense que el porcentaje de 20 me lo pone solo automáticamente Bueno ya tenemos un primer este elemento importante para empezar a ahora desde el código poder ver cómo puedo acceder esa información por lo tanto me vuelvo al Cola y lo primero que voy a ver Es que voy a usar aquí la librería request que es una librería de python que me permite tomar información de un sitio web y cuando me refiero a tomar información me refiero a tomar la información que tiene que ver con el diseño del sitio web con diseño de la página con el código con el cual yo veo esto es decir qué código es lo que me muestra todo esto bueno eso lo puedo acceder con request y luego la librería beautiful supp que es una de las tantas librerías que existen una de las más famosas de hecho para poder hacer web scrapping Entonces lo primero que hago aquí una vez que bueno escribo el código vinculado a estas importaciones ejecutarlas como siempre hacemos entonces empiezo por eso ya es tan importadas rico es y beautiful bien Ahora vamos a acceder a todos los elementos de la primer página lo vamos a hacer aquí poniendo un input para que nosotros podamos escribir en el contexto de este Notebook el texto que deseamos Buscar como recién escribimos zapatillas zapatillas deportivas por eso creo una variable Buscar a la que le pongo un input que quiere buscar bueno Esto es básico no bien luego lo que voy a hacer es a través de request get que es request como decíamos recién la librería request que acabamos de importar aquí arriba me permite a través del método que tomar todo el contenido el texto con el cual fue escrita la página de cualquier página poniéndole simplemente en la URL ahora cómo voy a escribir la URL la URL voy a escribir igual que como la tenía aquí solamente que voy a usar un pequeño truco que es donde yo debería poner los elementos de queda si se acuerdan después de la barra Sí aquí voy a poner dos llaves y lo mismo voy a hacer después del a dos puntos donde volvía a repetir el texto de búsqueda y lo que se hace en este caso son como comodines que luego con el método format se pone la expresión que quiero que vaya allí la expresión que quiero que vaya así es la variable Buscar es decir este Buscar va a ocupar este lugar y lo mismo va a ocupar este otro lugar eso lo hago con punto fortnite solamente que en el primer caso yo tengo recuerden la situación de que el espacio lo rellena con un guión por lo tanto lo que debería hacer sería poner una expresión en este caso la variable Buscar punto replace que es un método de python que lo que hace o lo que me permite hacer es reemplazar todos los elementos de un tipo en este caso este elemento vacío por un guión no un símbolo igual como puse aquí es un guión por un guión y luego Obviamente el otro Buscar lo dejamos como está porque como ya dijimos recién Por más que yo lo ponga con espacio en blanco lo va a reemplazar automáticamente al escribir la URL por un porcentaje y el 20 bien con todo esto tengo como rearmada la expresión de la página web pero no ya con una expresión fija aquí como dice zapatillas deportivas y está expresada de este modo sino con dos elementos variables que van a depender pero que yo escriba aquí en este input si escribo zapatillas deportivo va a ser esa búsqueda y si no la búsqueda que corresponde luego lo que hago es acceder a todo el contenido de la página a través de qué a través de r.content porque r.conted porque justamente el request este que hice acá lo puse dentro de una variable que bien Llamar R con r.content traigo todo el contenido y lo como se dice en informática lo parseo Sí con html parcer que es poder acceder a la estructura en cómo está Armada esta página web Que obviamente está Armada con elementos de html y javascript a mí lo que me interesa en este caso es Ver todas las estructuras html que me van a permitir acceder a los datos que estoy visualizando aquí entre ellos por ejemplo la denominación del producto y el precio para ello vamos a recurrir a un truco que probablemente los que están acostumbrados al desarrollo web manejando código html estén acostumbrados y bueno el que no lo sepa quizás ahora puede aprender algo nuevo más que es darle clic aquí con el botón derecho y acceder a la opción inspeccionar con inspeccionar lo que me muestra a mí es el código con el que está hecho esta página web Sí para probar esto vamos a hacer lo siguiente fíjense Que aquí hay un icono que si me paro encima me dice que con esto Una vez que opciono por esta herramienta puedo seleccionar un elemento de la página para inspeccionar que es esto que me muestra aquí la derecha Cuál es el código con el cual está construido fíjese que me voy a parar por ejemplo sobre Esta zapatilla y me muestra ven acá a la derecha el link al que me lleva cuando clic en esa imagen más allá de que me muestra referencias respecto a la imagen como el tamaño si me voy aquí abajo de que se que me muestra viene a la derecha el nombre que estoy viendo aquí en la página web topper coreo hombre adultos lo mismo con la unidad de al lado clic sobre la imagen no es clic es para nosotros la imagen Sí y veo la información relativa cómo está construida esa esa estructura que estoy viendo allí con la imagen y con el link que tiene asociado y lo mismo aquí abajo lo que tengo que ver ahora a través del código es donde está la estructura de referencia que me va a permitir seleccionar cada uno de estos elementos en el contexto de esta página para ello vamos a hacer lo siguiente vamos a recorrer esta estructura y vamos a descubrir que hay una sección con un dip que es una de las estructuras clásicas html cuya clase que es lo que identifica a la estructura justamente de ese dip se llama andes Card Esta es la primera referencia que voy a tener a partir del cual todo lo que esté dentro de esta estructura van a ser justamente cada uno de los artículos sobre los cuales Yo quiero extraer información estos datos son fundamentales Deep y and the scart porque justamente van a ser la referencia que yo voy a tomar para que desde el código pueda acceder a esa información me voy al colap y justamente veo que ahora solo el objeto sup que es el objeto suv el que tiene como vimos en esta línea anterior todo el contenido de la página voy a hacer un find all Buscar todo Buscar todo que buscar todos los VIP cuya clase sea and descare con esto lo que voy a estar haciendo es Buscar cada una de estas divisiones estos dips se refiere a División Sí y dentro de ello justamente Buscar todos los que tienen el estilo and desgard porque porque hay divisiones que no responden a esto estos iconos que están aquí arriba esta información que está al costado Yo solamente quiero la información de los productos sí Entonces le digo que me find all busque todos los elementos de que de suv que suv el contenido de la página completo y allí que quiero que busque todos los dips cuya clase Se han descargado una vez que tenga eso voy a pasar al siguiente paso el siguiente paso va a ser crear un array vacío como está aquí donde voy a depositar todos los productos y voy a hacer un foro de nuevo la estructura Ford para que para recorrer a través de la variable ítems nombre de variable puede ser cualquiera y yt el que ustedes se le ocurra in deeps Esto sí es importante que es dips deeps contiene aquí arriba lo que dijimos recién toda la cantidad de dips que hay dentro de la página de nuevo esto es un nombre variable le puse dips por una cuestión lógica le pueden poner como quiera for item in deeps O sea recorro sí cada uno de los dips en cada caso lo que voy a hacer va a servir a un diccionario aquí estoy creando Data donde voy a poner dentro de ese diccionario dos elementos un nombre de artículo y un precio Sí ese nombre de artículo a su vez está en una parte de El div y ese precio también está en una parte del dip Cómo sabemos Qué información ponerle para acceder esa información de nuevo tengo que usar la opción de inspeccionar la página web para ver en qué parte Guarda esa información dentro del código html para ello la página y vuelvo a la parte de inspección recuerdan que nosotros teníamos si veníamos de esta estructura de andes Card y voy a volver a hacer lo mismo marco este icono de aquí y voy a marcar la parte que me interesa ahora mirar que está de aquí abajo cuando está el nombre del producto y el precio Sí bueno al hacer clic acá veo que aparece h2 h2 es un header de nivel 2 que es otra estructura clásica html en sh2 tengo el nombre del producto topper Drive hombre adultos que es lo que está aquí y si yo sigo con la misma lógica buscando es información y bajo puedo ver aquí bajo veo que ya en la medida que voy bajando me voy parando sobre estas partes me va ubicando Ya ven el precio Sí pero está dentro de estructuras hasta llegar a la que concretamente tiene el precio que es esta última mil Perdón 14.816 es una estructura de tipo spam insisto otra estructura clásica de html pero yo tengo una información que me hacía falta tengo la información de que el precio está dentro de una estructura de tipo spam y tengo la información de que el nombre está dentro de una estructura de tipo h2 Por ende me voy ahora si al código y justamente lo que hago ahora es hacer un ítem punto fine porque ítem recuerden ítem De dónde viene es cada uno de los dears O sea yo con ítem Estoy parado en uno de los dips dentro de uno de los dips por ejemplo el primero el de la zapatillas que estamos mirando recién En esta topper si le voy a pedir que me busque que me fine si me busque un h2 de clase we Search item que es justamente lo que demuestra aquí ven y que allí me tome el texto lo mismo con el precio donde voy a poner sobre ítem find Búscame una estructura de tipo spam de clase price tag Mount que es esta estructura que veíamos recién aquí debajo Price price sí que es el spam que tiene o que contiene el valor entonces una vez que y siempre tomo el texto Perdón una vez que tengo el título y el precio lo pongo dentro de uno de los elementos de este diccionario que Acabo de crear qué diccionario va a tener el nombre del artículo y el precio de que de cada uno de los ítems Es decir de cada una de las divisiones de la página que acabo de visualizar una vez que tengo eso hago una pen de ese diccionario Dentro de este array que Acabo de crear Sí y hago un print para esto bueno de alguna manera ir mostrando El Avance y el recorrido de todos los elementos Sí ya tengo todo lo que necesitaba con lo cual lo que voy a hacer ahora es ejecutarlo y lo que me va a pedir es que objeto Quiero buscar y le pongo zapatillas deportivas vean y me va a mostrar cada uno de los productos de la página de MercadoLibre sí bien no siempre estos elementos van a aparecer en el mismo orden que ustedes lo van a visualizar Aquí vamos a cerrar esta parte porque bueno tampoco ustedes Cuando entren muchas veces a hacer búsquedas van a encontrar los elementos del mismo modo esto tiene que ver con una cuestión de competencia Obviamente si estuviesen los productos algo que esté destacado primero obviamente ese producto sería favorecido en la hora de elegir por parte del usuario Bueno pero lo concreto que aquí tenemos lo que queremos que es el dato de el nombre del producto y su precio lo tenemos en un array que tenemos que hacerlo pasarlo a un Data frame eso ya lo hemos visto en clases pasadas Así que lo podemos hacer perfectamente Y a partir de tener el Data frame puedo empezar a trabajarlo bueno haciendo o buscando un modelo de lo que yo necesite hacer justamente porque ya tengo La Estructura de datos similar a como la tenía antes Obviamente con un trabajo mucho más llevadero pero finalmente lograr el mismo objetivo pero resulta que me falta una parte todavía de la historia porque porque yo tengo como dije al principio aquí la información de los elementos de la primera página no de todas las páginas ustedes ven que esta búsqueda arrojó y lo ven aquí debajo de la página un número de 42 páginas está simplemente la primera las cuales voy a visualizando haciendo clic en siguiente pero fíjense que cuando yo voy haciendo clic en siguiente la URL cambia ya no es como la que teníamos antes y fíjese que tiene una estructura que dice que va desde un número en adelante desde un número no Index true donde Esto va a ir cambiando conforme yo vaya avanzando de página fíjese que ahora dice desde 97 voy a la siguiente ahora dice de 145 es decir va haciendo un ciclo un ciclo que desde 97 145 me da la Pauta que tengo 48 elementos por cada una de las 42 páginas eso es lo que voy a trabajar ahora Y por eso voy a crear otro código tomando este como base haciéndole algunas modificaciones que tienen que ver con el formato de este la página web de la URL de cada una de las páginas que va mostrando conforme yo vaya pasando a las siguientes páginas de los productos y después ver cómo voy tomando eso para que justamente vaya a parar también a un array como fue la primera página Pero ahora con todas bien con esto lo que voy a hacer es arrancar la primera parte con el mismo código que tenía antes sí eso no cambia demasiado y luego lo que voy a hacer va a ser escribir un código para obtener un número importante que cuál es este dato que está aquí por qué Porque yo ahora voy a tener que no hacer un Ford para recorrer todos los elementos de una página sino antes que se hacer otro fuerte recorra todas las páginas y dentro de cada página todos los elementos de cada una de ellas por eso acá en el código Yo ya voy a ir viendo que tengo dos foros el que tenía antes y el que tengo ahora que me va a permitir recorrer como dije recién todas las páginas Entonces lo primero que hago es Con este código tratar de averiguar justamente Cuál es el dato de la página tengo que buscarlo a través con fine de Sub como lo dice antes sí se acuerdan lo que habíamos usado acá find en este caso de ítem Porque recorría todos los ítem este caso es find porque estoy todavía parado en todo el contenido de la primer página Buscar ese número pero ubicándolo siempre la estructura de html por lo tanto tengo que buscar ese elemento En qué tipo de estructura está voy a si lo lo dejo como tarea de ustedes si hago una inspección voy a ver que es una estructura de tipo lee como fue antes que detecte una estructura de tipo h2 una estructura de tipo spam ahora es una lectura de tipo Los invito a poder chequearlo y justamente hay una clase que es andes pagination pass code donde voy a tomar ese texto ese texto no es Ni más ni menos que esto que está aquí de 42 Qué pasa a mí me interesaba el 42 entonces lo que voy a hacer es hacer un Ink de las page que es el valor que estoy recogiendo este text que estoy recogiendo que dice de 42 las page replace de espacio con nada Es decir reemplazar de e y el espacio pero igual 42 por nada con lo cual me queda nada más que el 42 sí Y entonces ya en la variable tengo el elemento 42 esta estructura trae SEP que es obviamente una estructura para validar errores la pongo justamente para eso por qué Porque puede que una búsqueda que no arroje varias páginas se haga una búsqueda muy restrictiva me va a dar una sola página y en el caso que haya una sola página este valor obviamente no va a estar bien entonces por eso hago un Trade Excel para que si esto no es exitoso si no hagas búsqueda porque no va a tener sentido bien luego también vuelvo a crear pros como antes el array se acuerda que tenía aquí arriba antes eray plots y lo que hago es como dije antes sí antes de hacer el Ford que teníamos para recorrer todos los dips de una página hacerlo concerniente para ir tomando cada una de las páginas dado que son más de una entonces hago un Ford variable cualquiera le llamo page in rage que va de 0 a las page Es decir desde la página 0 hasta la 41 acuérdense que el Range cuando yo pongo 42 que en este caso es el valor que tiene las Face pasaría 41 y a partir de allí lo que hago es bueno una referencia simplemente que ponemos para que nos aparezca el valor lo que hago es trabajar ahora con esa URL también dinámica pero con este cambio ya no es la url que tenía antes esta que estaba aquí sino está con el nuevo Index tal cual lo vimos recién acá entonces luego lo que tengo que hacer es volver a poner aquí así como puse antes los textos de búsqueda lo que tengo que poner aquí es el número este que va a ir variando conforme vayan avanzando las partes cómo logro ese valor Bueno lo logró multiplicando a page que va a arrancar de cero por 48 + 1 es decir que page por 48 + 1 en el primer caso que me va a dar Sí entonces de allí en más va a ir escroleando todo el resto para lograr el siguiente número el siguiente número page va a ser uno por 48 va a ser 48 más 149 que es si vuelvo aquí es este valor que está acá bien entonces una vez que tengo eso lo que hago bueno estos print insisto son más que nada para que ustedes vayan viendo El Avance dentro del código no son necesarios de que de que sí o sí los tengan que poner pero bueno está bueno cuando lo vayan probando que van a verlos aquí que justamente el efecto que se busca es ese bueno y ahora tengo el request como habíamos hecho antes enriquez pues de la página la primera página voy a hacer lo mismo ahora para lo que son cada una de las urls que voy a ir formando conforme vaya avanzando cada una de la selección de las páginas luego lo que hago es parcial el contenido le digo que me dé todos los dips esto ya es parecido a lo que veníamos haciendo en el caso anterior se acuerdan de estas dos líneas Perdón esta línea de acá lo mismo aquí ahora lo hago para todas y cada una de las páginas que voy ciclando y luego el resto del texto es Exactamente igual a lo que veníamos trabajando insisto cómo lo hacía antes yo antes tenía una sola página esta y bueno tomaba todos los elementos parciaba tomaba todos los elementos de allí pedía que me identificara todos los deeps y los recorría y cada vez que los recorría iba tomando cada uno de los elementos aparte ahora es exactamente lo mismo estas dos líneas son las mismas lo que cambia es que en este caso estas dos líneas digo dos porque los primos obviamente no cuentan lo que hacen es ir dándome las páginas una por una dado que antes lo hice con la primera y ahora lo quiero hacer con cada una de ellas el resto es Exactamente igual con lo cual lo vamos a ejecutar pero pero vamos a hacer un pequeño cambio aquí porque los invito a ustedes se lo quieren probar Pero obviamente Esto va a ser extremadamente pesado porque va a tener que mostrarme 42 páginas por 48 elementos y va a ser muy largo vamos a poner una búsqueda mucho más restrictiva Sí vamos a poner a ver si hacemos esta búsqueda que no sea tan restrictiva como que no nos arroje ninguna página más que una bueno evidentemente acá voy a tener tres páginas una una buena búsqueda y es posible que me salga un resultado interesante Sí bien entonces lo que hice aquí es poner camisetas de chacarita para que se copia y pego sea más rápido para ejecutar esto así que ejecutamos el código no voy a pegar acá Así también trato de no equivocarme no en la escritura Obviamente si el filtro que pongo diferente resultado no va a ser el mismo así que eso trato de evitarlo de esta manera bueno acá fíjense que me pone 0 y ya me pone el primer la primer URL y después de allí me da ven uno la página 1 la página 1 y la URL la segunda URL que toma y todos los valores la página 2 la URL de la página 2 y hasta donde llega son 103 productos sí los que me muestran en tres páginas sí evidentemente yo recorro acá voy a ver que la tercera página obviamente no debe estar completa segunda página tercera página ven tiene menos productos sí tiene siete por eso que el número final me da 103 bien lo que tenemos entonces con esos print es la posibilidad de ver esto En qué número de página voy y cómo me va formando la url para el primer caso para el segundo caso y para el tercer caso luego de esto insisto tengo toda esta información dentro de un array y la puedo convertir tranquilamente un csv y empezar a operar Bueno hasta aquí llegamos con esta explicación de lo que es el web scrapping es algo interesante es bueno para que puedan probar Obviamente el que no salga html puede que le cueste un poquito más pero bueno tampoco es algo extremadamente complejo quien quiera empezar a tener conocimiento html poder este hacerlo con cualquier este recurso público y el que está al alcance de la mano en redes sociales para poder verlo por lo menos los conceptos básicos que son los que hemos tratado aquí atentos a poder identificar las partes de una página y poder tomar allí la información Bueno hasta aquí como dijimos recién estaba en clase y Bueno nos vemos en la próxima hasta aquí llegamos con la clase número 5 y con la misma también terminamos con el módulo de análisis de datos de este curso ahora estamos capacitados para darle forma a nuestro datasette y con ello poder desde el próximo módulo comenzar a desarrollar los mejores modelos de Machine learning nos vemos en la clase 6 para empezar con ello